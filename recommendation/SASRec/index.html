<!-- build time:Tue Aug 13 2024 22:42:58 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Enjun Du" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Enjun Du" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Enjun Du" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter,code,recommendation"><link rel="canonical" href="https://enjundu.github.io/recommendation/SASRec/"><title>SASrec - 推荐算法相关search | 蓝天の网站 = Enjun Du</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">SASrec</h1><div class="meta"><span class="item" title="Created: 2024-07-04 09:41:31"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-04T09:41:31+08:00">2024-07-04</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>61k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>56 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/03/2CIcORrG8hxpSnD.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/6vserUNHJbOxI4y.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/19H8wehu2ExKaic.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/flquHABaRmV2onx.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/sTHU7wL5qkSiloC.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/NDKVsh3T5XY8lnp.gif"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/recommendation/" itemprop="item" rel="index" title="In 推荐算法相关search"><span itemprop="name">推荐算法相关search</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/recommendation/SASRec/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Enjun Du"></span><div class="body md" itemprop="articleBody"><h1 id="self-attentive-sequential-recommendation"><a class="anchor" href="#self-attentive-sequential-recommendation">#</a> Self-Attentive Sequential Recommendation</h1><h2 id="马尔科夫链mc"><a class="anchor" href="#马尔科夫链mc">#</a> 马尔科夫链（mc）</h2><p>马尔科夫链（Markov Chain）是一种数学模型，用于描述一个系统从一个状态转移到另一个状态的过程。这种模型特别适用于分析随机过程，其中每个状态的转移仅依赖于当前状态，而与之前的状态无关。这种特性被称为 “马尔科夫性” 或 “无记忆性”。</p><h3 id="基本概念"><a class="anchor" href="#基本概念">#</a> 基本概念</h3><ul><li><strong>状态空间（State Space）</strong>: 马尔科夫链中的所有可能状态的集合。状态空间可以是有限的，也可以是无限的。</li><li><strong>转移概率（Transition Probability）</strong>: 从一个状态转移到另一个状态的概率，通常表示为 $P (X_{n+1}=j\mid X_{n}=i) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo separator="true">,</mo><mtext>其中</mtext></mrow><annotation encoding="application/x-tex">,其中</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord cjk_fallback">其</span><span class="mord cjk_fallback">中</span></span></span></span> X_n<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>表示在时间</mtext></mrow><annotation encoding="application/x-tex">表示在时间</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">示</span><span class="mord cjk_fallback">在</span><span class="mord cjk_fallback">时</span><span class="mord cjk_fallback">间</span></span></span></span> n$ 的状态</li><li><strong>转移矩阵（Transition Matrix）</strong>: 描述所有状态之间的转移概率的矩阵。对于一个有限状态空间的马尔科夫链，转移矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span></span></span></span> 的每个元素<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 表示从状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 转移到状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 的概率</li><li><strong>初始分布（Initial Distribution）</strong>: 系统在初始时刻的状态分布，通常表示为一个向量。</li></ul><h3 id="类型"><a class="anchor" href="#类型">#</a> 类型</h3><ul><li><strong>离散时间马尔科夫链（DTMC）</strong>: 时间步长是离散的，每个时间步系统转移一次。</li><li><strong>连续时间马尔科夫链（CTMC）</strong>: 时间是连续的，系统可以在任意时刻发生状态转移。</li></ul><h3 id="马尔科夫链的性质"><a class="anchor" href="#马尔科夫链的性质">#</a> 马尔科夫链的性质</h3><ol><li><p><strong>稳态分布（Steady-State Distribution）</strong>: 在长期运行中，马尔科夫链可能会达到一个稳定的状态分布，即各状态的概率不再随时间变化。这种分布可以通过求解<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi>P</mi><mo>=</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi P=\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span> 来获得，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span> 是稳态概率向量。</p></li><li><p><strong>回归性（Recurrence）</strong>: 如果一个状态从任意其他状态出发，总有一定的概率返回到该状态，则称这个状态是回归的。反之，如果返回概率为零，则称为瞬时的。</p></li><li><p><strong>不可约性（Irreducibility）</strong>: 如果系统的任意两个状态之间都可以通过若干步转移相互到达，则称这个马尔科夫链是不可约的。</p></li><li><p><strong>周期性（Periodicity）</strong>: 一个状态的周期定义为从该状态回到自身所需步数的最大公约数。如果这个周期为 1，则称该状态是非周期的。</p></li><li><p><strong>稳态概率向量（Steady-State Probability Vector）</strong>，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span>，是马尔科夫链中一个重要的概念。它描述了在长期运行中，系统各个状态的概率分布。当一个马尔科夫链达到稳态时，各个状态的概率将不再随时间变化。具体来说，如果一个马尔科夫链在某一时刻达到了稳态，那么无论经过多少次状态转移，系统各状态的概率将保持不变。</p><ul><li><p><strong>不变形</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi>P</mi><mo>=</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi P=\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span> , 这里的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span> 是一个行向量，表示各状态的稳态概率，P 是转移矩阵，描述各状态之间的转移概率。</p></li><li><p><strong>归一化条件</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>π</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum_i\pi_i=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-.29971000000000003em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16195399999999993em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 即稳态概率向量的各个元素之和为 1，表示系统必定处于某个状态。</p></li><li><p><strong>求解方法</strong>：要找到马尔科夫链的稳态概率向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span></span>，通常需要解以下线性方程组：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>π</mi><mi>P</mi><mo>=</mo><mi>π</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>π</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\begin{cases}\pi P=\pi\\\sum_i\pi_i=1\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">π</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16195399999999993em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p></li></ul></li></ol><h3 id="一阶马尔科夫链"><a class="anchor" href="#一阶马尔科夫链">#</a> 一阶马尔科夫链</h3><ul><li>一阶马尔可夫链假设系统的下一个状态只依赖于当前状态。这在序列推荐系统中意味着，用户的下一次操作只取决于他们的最近一次操作。</li><li>** 状态表示：** 将用户的每一个操作视为一个状态。例如，用户购买的商品或浏览的网页。</li><li>** 转移概率矩阵：** 创建一个矩阵，表示从一个状态转移到另一个状态的概率。矩阵中的每个元素<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 表示从状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 转移到状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 的概率。</li><li><strong>概率计算</strong>：通过统计历史数据，计算从每个状态转移到其他状态的频率。例如，如果用户最近购买了商品 A，那么我们统计他们接下来购买商品 B 的频率来估计转移概率。</li><li><strong>预测下一状态</strong>：根据当前状态（用户的最近一次操作），利用转移概率矩阵预测用户的下一次操作。例如，如果当前状态是商品 A，查看矩阵中与商品 A 对应的行，选择转移概率最高的商品作为预测结果。</li></ul><h3 id="高阶马尔科夫链"><a class="anchor" href="#高阶马尔科夫链">#</a> 高阶马尔科夫链</h3><ul><li>** 功能：** 将用户的每一个操作视为一个状态，并将一系列连续的操作视为一个组合状态。例如，用户最近连续购买了商品 A、B 和 C，这个组合状态可以表示为 (A, B, C)。高阶马尔可夫链假设系统的下一个状态不仅依赖于当前状态，还依赖于前几个状态。这在序列推荐系统中意味着，用户的下一次操作取决于他们的多个最近操作。</li><li><strong>状态表示</strong>：将用户的每一个操作视为一个状态，并将一系列连续的操作视为一个组合状态。例如，用户最近连续购买了商品 A、B 和 C，这个组合状态可以表示为 (A, B, C)。</li><li><strong>转移概率矩阵</strong>：创建一个更复杂的转移概率矩阵，表示从一个组合状态转移到下一个状态的概率。矩阵中的每个元素<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{ijk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 表示从状态组合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mclose">)</span></span></span></span> 转移到状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 的概率</li><li><strong>概率计算</strong>：通过统计历史数据，计算从每个组合状态转移到其他状态的频率。例如，如果用户最近购买了商品 A 和 B，那么我们统计他们接下来购买商品 C 的频率来估计转移概率。</li><li><strong>预测下一状态</strong>：根据当前组合状态（用户的最近几次操作），利用转移概率矩阵预测用户的下一次操作。例如，如果当前组合状态是 (A, B)，查看矩阵中与 (A, B) 对应的行，选择转移概率最高的商品作为预测结果。</li></ul><h2 id="递归神经网络recurrent-neural-network-rnn"><a class="anchor" href="#递归神经网络recurrent-neural-network-rnn">#</a> 递归神经网络（Recurrent Neural Network, RNN）</h2><p>递归神经网络（Recurrent Neural Network, RNN）是一类用于处理序列数据的神经网络。与传统的前馈神经网络不同，RNN 具有记忆能力，可以处理和分析时间序列数据，捕捉数据中的时间依赖关系和顺序信息。RNN 在自然语言处理、语音识别、时间序列预测等领域有广泛的应用。</p><h3 id="基本结构"><a class="anchor" href="#基本结构">#</a> 基本结构</h3><p>RNN 的基本结构包括输入层、隐藏层和输出层。与传统神经网络不同的是，RNN 的隐藏层不仅接收当前时间步的输入，还接收前一个时间步的隐藏状态。具体来说：</p><ul><li><p><strong>输入层</strong>：接收序列数据的当前时间步输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>。</p></li><li><p><strong>隐藏层</strong>：计算当前时间步的隐藏状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，同时考虑当前输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和前一个时间步的隐藏状态 $ h_{t-1}$</p></li><li><p><strong>输出层</strong>：根据当前隐藏状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 计算输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></p></li><li><p>隐藏状态的更新公式如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h_t=\sigma(W_{xh}x_t+W_{hh}h_{t-1}+b_h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.902771em;vertical-align:-.208331em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{xh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是权重矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">b_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是偏置向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span></span></span></span> 是激活函数（如 tanh 或 ReLU）</p></li></ul><h3 id="优势"><a class="anchor" href="#优势">#</a> 优势</h3><ol><li><strong>捕捉时间依赖</strong>：RNN 能够处理序列数据，捕捉其中的时间依赖关系，使其在处理时间序列数据和自然语言处理任务中表现良好。</li><li><strong>参数共享</strong>：RNN 的权重在每个时间步共享，减少了模型参数的数量，使其在处理长序列数据时更加高效。</li></ol><h3 id="局限性"><a class="anchor" href="#局限性">#</a> 局限性</h3><ol><li><strong>梯度消失和梯度爆炸</strong>：在处理长序列数据时，RNN 可能会遇到梯度消失或梯度爆炸的问题，使得模型难以训练。</li><li><strong>长时间依赖捕捉困难</strong>：标准 RNN 在处理长时间依赖关系时表现不佳。</li></ol><h2 id="顺序推荐"><a class="anchor" href="#顺序推荐">#</a> 顺序推荐</h2><h3 id="目标"><a class="anchor" href="#目标">#</a> 目标</h3><p>将用户行为的个性化模型（基于历史活动）与用户最近行为的 “上下文” 概念结合起来进行推荐。</p><h3 id="前人方式"><a class="anchor" href="#前人方式">#</a> 前人方式</h3><ul><li><p>马尔科夫链假设下一个动作仅由以前一个动作（或前几个动作）为条件，并已成功地用于表征推荐的短距离项目转换。</p></li><li><p><strong>递归神经网络 RNN</strong>：RNN 是一种用于处理序列数据的神经网络，具有记忆能力，可以捕捉序列数据中的时间依赖关系。RNN 的基本结构包括输入层、隐藏层和输出层，其中隐藏层的状态会根据前一个时间步的隐藏状态和当前时间步的输入来更新</p></li></ul><h2 id="transformer"><a class="anchor" href="#transformer">#</a> Transformer</h2><h3 id="介绍"><a class="anchor" href="#介绍">#</a> 介绍</h3><p>Transformer 是一种用于处理序列数据的深度学习模型，特别擅长于自然语言处理任务，如机器翻译、文本生成等。它由一个编码器（Encoder）和一个解码器（Decoder）组成。</p><h3 id="编码器encoder"><a class="anchor" href="#编码器encoder">#</a> 编码器（Encoder）</h3><p>编码器的任务是接收输入序列（例如，一个句子），并将其转换为一组特征表示。编码器包含多个层，每层都有两个主要部分：</p><ol><li><strong>自注意力层（Self-Attention Layer）</strong>：用于计算每个词与其他词的相关性。</li><li><strong>前馈神经网络层（Feed-Forward Neural Network）</strong>：对自注意力层的输出进行进一步处理。</li></ol><p>每一层都有一个 “残差连接”（Residual Connection）和 “层归一化”（Layer Normalization）来帮助训练更深的网络。</p><h3 id="解码器decoder"><a class="anchor" href="#解码器decoder">#</a> 解码器（Decoder）</h3><p>解码器的任务是根据编码器的输出生成目标序列（例如，翻译后的句子）。解码器也包含多个层，每层与编码器类似，但增加了一个 “编码器 - 解码器注意力层”（Encoder-Decoder Attention Layer），用来关注编码器的输出。</p><h3 id="残差连接residual-connection"><a class="anchor" href="#残差连接residual-connection">#</a> 残差连接（Residual Connection）</h3><h4 id="原理"><a class="anchor" href="#原理">#</a> 原理</h4><p>残差连接是一种深度神经网络的技术，通过在每个层之间引入直接的跳跃连接来帮助训练更深层的网络。具体来说，残差连接将输入直接添加到输出上，即：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mi mathvariant="script">F</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}=\mathcal{F}(\mathbf{x})+\mathbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.63888em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">y</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathcal" style="margin-right:.09931em">F</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">x</span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">x</span></span></span></span></span> 是输入，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">F</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{F}(\mathbf{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathcal" style="margin-right:.09931em">F</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span></span></span></span> 是一个或多个层的非线性变换，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.63888em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">y</span></span></span></span></span> 是输出。</p><h4 id="优点"><a class="anchor" href="#优点">#</a> 优点</h4><ol><li><strong>解决梯度消失问题</strong>：在深层网络中，梯度可能会在传播过程中逐渐消失，使得前面的层无法得到有效更新。残差连接通过直接传递梯度，缓解了这个问题。</li><li><strong>加速训练</strong>：残差连接提供了一条无需学习的捷径，使得网络更容易学习到有效的表示，从而加速训练过程。</li><li><strong>提高准确性</strong>：在很多应用中，使用残差连接的网络（如 ResNet）在准确性上有显著提升。</li></ol><h4 id="应用"><a class="anchor" href="#应用">#</a> 应用</h4><p>残差连接最初在 ResNet（残差网络）中得到应用，后来在 Transformer 等模型中广泛使用，成为深度学习模型中的标准组件。</p><h2 id="自注意力机制self-attention"><a class="anchor" href="#自注意力机制self-attention">#</a> 自注意力机制（Self-Attention）</h2><p>自注意力机制是 Transformer 的核心。它的作用是让模型能够 “关注” 输入序列中不同位置的词之间的关系。这是如何做到的：</p><ol><li><strong>输入嵌入（Input Embeddings）</strong>：<ul><li>首先，将输入序列中的每个词转换为一个高维向量（嵌入向量）。</li></ul></li><li><strong>生成查询（Query）、键（Key）和值（Value）向量</strong>：<ul><li>对每个输入词的嵌入向量，通过不同的线性变换，生成对应的查询、键和值向量。</li></ul></li><li><strong>计算注意力得分（Attention Scores）</strong>：<ul><li>对每个词的查询向量和所有词的键向量进行点积运算，得到注意力得分。这个得分表示当前词与其他词的相关性。</li></ul></li><li><strong>归一化注意力得分</strong>：<ul><li>使用 Softmax 函数对注意力得分进行归一化，得到每个词的注意力权重。</li></ul></li><li><strong>计算加权和</strong>：<ul><li>使用这些注意力权重对所有词的值向量进行加权求和，得到当前词的新的表示。</li></ul></li><li>允许每个词根据其与其他词的相关性进行加权求和，从而捕捉到全局信息。</li></ol><h2 id="sasrec"><a class="anchor" href="#sasrec">#</a> SASRec</h2><h3 id="培训简化图"><a class="anchor" href="#培训简化图">#</a> 培训简化图</h3><p><img data-src="https://s2.loli.net/2024/07/09/4buJp2oYK7MVcZz.png" alt="QQ_1720514487872.png"></p><h3 id="要点"><a class="anchor" href="#要点">#</a> 要点</h3><ul><li>自我注意：发现句子中单词之间的句法和语意模式</li><li>可以并行加速</li></ul><h3 id="符号表"><a class="anchor" href="#符号表">#</a> 符号表</h3><table><thead><tr><th>符号</th><th>描述</th></tr></thead><tbody><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">U</span></span></span></span></td><td>用户和物品集合</td></tr><tr><td>$S^u $</td><td>用户 (u) 的历史交互序列：$(S^u_1, S^u_2, ..., S^u _{</td><td>S^u</td><td>})$</td></tr><tr><td n="">d \in \mathbb</td><td>潜在向量维度</td></tr><tr><td>$n \in \mathbb{N} $</td><td>最大序列长度</td></tr><tr><td n="">b \in \mathbb</td><td>自注意力块的数量</td></tr><tr><td>$\mathbf{M} \in \mathbb{R}^{</td><td>I</td><td>\times d}$</td><td>物品嵌入矩阵</td></tr><tr><td>$\ \mathbf<ruby>P} \in \mathbb{R}<rp>(</rp><rt>{n \times d</rt><rp>)</rp></ruby>$</td><td>位置嵌入矩阵</td></tr><tr><td n="" \times="" d="">\hat{\mathbf{E}} \in \mathbb{R}^</td><td>输入嵌入矩阵</td></tr><tr><td>$\mathbf<ruby>S}<rp>(</rp><rt>{(b)</rt><rp>)</rp></ruby>\in \mathbb<ruby>R}<rp>(</rp><rt>{n \times d</rt><rp>)</rp></ruby>$</td><td>第 (b) 个自注意力层后的物品嵌入</td></tr><tr><td>$\mathbf<ruby>F}<rp>(</rp><rt>{(b)</rt><rp>)</rp></ruby>\in \mathbb<ruby>R}<rp>(</rp><rt>{n \times d</rt><rp>)</rp></ruby>$</td><td>第 (b) 个前馈神经网络层后的物品嵌入</td></tr></tbody></table><h3 id="嵌入层"><a class="anchor" href="#嵌入层">#</a> 嵌入层</h3><p>我们现将序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msubsup><mi>S</mi><mn>1</mn><mi>u</mi></msubsup><mo separator="true">,</mo><msubsup><mi>S</mi><mn>2</mn><mi>u</mi></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msubsup><mi>S</mi><mrow><mi mathvariant="normal">∣</mi><msup><mi>S</mi><mrow><mi>u</mi><mo>−</mo><mn>1</mn></mrow></msup><mi mathvariant="normal">∣</mi></mrow><mi>u</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(S^u_1, S^u_2, ..., S^u _{|S^{u-1}|})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2469999999999999em;vertical-align:-.49699999999999994em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-2.4518920000000004em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24810799999999997em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-2.4518920000000004em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24810799999999997em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6643919999999999em"><span style="top:-2.378em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7463142857142857em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.49699999999999994em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 变换为固定长度的序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>s</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s=(s_1,s_2,...,s_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 n 表示模型可以处理的最大长度，如果序列长度大于 n 则考虑最近的 n 个动作，如果序列长度小于 n，则在左边重复添加一个 ' 填充 ' 项，直到长度为 N 为止 0。其创建了一个项目嵌入矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi mathvariant="normal">∣</mi><mi>I</mi><mi mathvariant="normal">∣</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{M} \in \mathbb{R}^{ |I| \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72521em;vertical-align:-.0391em"></span><span class="mord"><span class="mord mathbf">M</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:.07847em">I</span><span class="mord mtight">∣</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，其中 d 是潜在维数，检索输入嵌入矩阵。</p><h3 id="自注意力缩放点积注意力计算过程"><a class="anchor" href="#自注意力缩放点积注意力计算过程">#</a> 自注意力缩放点积注意力计算过程</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi mathvariant="bold">Q</mi><mo separator="true">,</mo><mi mathvariant="bold">K</mi><mo separator="true">,</mo><mi mathvariant="bold">V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="bold">Q</mi><msup><mi mathvariant="bold">K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(\mathbf{Q},\mathbf{K},\mathbf{V})=\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}\right)\mathbf{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">Q</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathbf">K</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">V</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.468361em;vertical-align:-.95003em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em"><span style="top:-2.17778em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.93222em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord mathnormal">d</span></span></span><span style="top:-2.89222em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.10777999999999999em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">Q</span></span><span class="mord"><span class="mord"><span class="mord mathbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">V</span></span></span></span></span></span></p><h4 id="解释"><a class="anchor" href="#解释">#</a> 解释</h4><ul><li><strong>Q</strong>：查询矩阵</li><li><strong>K</strong>：键矩阵</li><li><strong>V</strong>：值矩阵</li><li><strong>点积计算</strong>：首先查询矩阵 Q 和建矩阵 K 的转置<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">K^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 的点积。这个点积结果表示查询和键之间的相似度</li><li><strong>缩放</strong>：由于点积的结果在维度较大时可能会产生很大的数值，因此我们需要将点积结果除以<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mi>d</mi></msqrt></mrow><annotation encoding="application/x-tex">\sqrt d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-.10777999999999999em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.93222em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="padding-left:.833em">d</span></span><span style="top:-2.89222em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.10777999999999999em"><span></span></span></span></span></span></span></span></span> 进行缩放，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">d</span></span></span></span> 是键向量的维度。这样做的目的是为了避免在计算 softmax 时数值较大，导致梯度消失问题。</li><li><strong>softmax</strong>：通过 softmax 函数将缩放后的点积结果转换为概率分布。softmax 的作用是将每个查询与所有键的相似度转化为权重，这些权重表示每个键对当前查询的重要性。</li><li><strong>加权求和</strong>：最后，将这些权重与值矩阵 V 相乘，得到最终的注意力输出。这一步的目的是根据查询对键的注意力权重，对值进行加权求和，从而得到每个查询对应的加权值。</li></ul><h4 id="softmax-函数"><a class="anchor" href="#softmax-函数">#</a> softmax 函数</h4><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>z</mi><mi>i</mi></msub></msup><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mi>e</mi><msub><mi>z</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mathrm{softmax}(z_i)=\frac{e^{z_i}}{\sum_{j=1}^Ke^{z_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:.07778em">f</span><span class="mord mathrm">t</span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.648441em;vertical-align:-1.3070490000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.341392em"><span style="top:-2.128769em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.981231em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.43581800000000004em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.6064620000000001em"><span style="top:-3.0050700000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.04398em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2818857142857143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:-.04398em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3070490000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是输入向量中的第 $i $ 个元素， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 是向量的维度。</p><h3 id="自注意层"><a class="anchor" href="#自注意层">#</a> 自注意层</h3><ul><li><p><strong>旧方法</strong>：使用相同的对象作为查询、键和值。</p></li><li><p><strong>该论文方法</strong>：将嵌入的 E 作为输入，通过线性投影将其转换为三个矩阵，并且发送到注意层中。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">S</mi><mo>=</mo><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">A</mi></mrow><mo stretchy="false">(</mo><mover accent="true"><mi mathvariant="bold">E</mi><mo stretchy="true">^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">A</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mrow><mo stretchy="false">(</mo><mover accent="true"><mi mathvariant="bold">E</mi><mo stretchy="true">^</mo></mover><msup><mi mathvariant="bold">W</mi><mi>Q</mi></msup><mo separator="true">,</mo><mover accent="true"><mi mathvariant="bold">E</mi><mo stretchy="true">^</mo></mover><msup><mi mathvariant="bold">W</mi><mi>K</mi></msup><mo separator="true">,</mo><mover accent="true"><mi mathvariant="bold">E</mi><mo stretchy="true">^</mo></mover><msup><mi mathvariant="bold">W</mi><mi>V</mi></msup><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathbf{S}=\mathrm{SA}(\widehat{\mathbf{E}})=\mathrm{Attention}(\widehat{\mathbf{E}}\mathbf{W}^Q,\widehat{\mathbf{E}}\mathbf{W}^K,\widehat{\mathbf{E}}\mathbf{W}^V),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">S</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.17611em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">S</span><span class="mord mathrm">A</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92611em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">E</span></span></span></span><span class="svg-align" style="width:calc(100% - .16668em);margin-left:.16668em;top:-3.68611em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.17611em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">A</span><span class="mord mathrm">t</span><span class="mord mathrm">t</span><span class="mord mathrm">e</span><span class="mord mathrm">n</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">o</span><span class="mord mathrm">n</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92611em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">E</span></span></span></span><span class="svg-align" style="width:calc(100% - .16668em);margin-left:.16668em;top:-3.68611em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.891331em"><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92611em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">E</span></span></span></span><span class="svg-align" style="width:calc(100% - .16668em);margin-left:.16668em;top:-3.68611em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92611em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">E</span></span></span></span><span class="svg-align" style="width:calc(100% - .16668em);margin-left:.16668em;top:-3.68611em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></p></li><li><p>投影矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>Q</mi></msup><mo separator="true">,</mo><msup><mi mathvariant="bold">W</mi><mi>K</mi></msup><mo separator="true">,</mo><msup><mi mathvariant="bold">W</mi><mi>V</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{W}^Q,\mathbf{W}^K,\mathbf{W}^V\in\mathbb{R}^{d\times d}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.22222em">V</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span><span class="mord">.</span></span></span></span> 这些预测使得模型更灵活。</p></li></ul><h3 id="因果关系"><a class="anchor" href="#因果关系">#</a> 因果关系</h3><p>模型在预测（t+1）-st 项时只考虑前 t 项，但是自注意层<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">S_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> 个输出包含后续项目的嵌入会让模型不稳定，所以我们通过进制<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">K_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>j</mi><mo>&gt;</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(j&gt;i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span> 直接的所有联系来修改注意力。</p><h3 id="点对点前馈网络"><a class="anchor" href="#点对点前馈网络">#</a> 点对点前馈网络</h3><ul><li><p><strong>问题描述</strong>：虽然自注意力机制可以根据适应性权重聚合所有之前项目的嵌入，但其本质上仍然是线性模型。</p></li><li><p><strong>解决方法</strong>：为了赋予模型非线性，并考虑不同潜在维度之间的交互，为每个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 应用一个点对点两层前馈网络，每个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的计算公式为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">F</mi><mi>i</mi></msub><mo>=</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">N</mi></mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">S</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">S</mi><mi>i</mi></msub><msup><mi mathvariant="bold">W</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">b</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><msup><mi mathvariant="bold">W</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">b</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{F}_i=\mathrm{FFN}(\mathbf{S}_i)=\mathrm{ReLU}(\mathbf{S}_i\mathbf{W}^{(1)}+\mathbf{b}^{(1)})\mathbf{W}^{(2)}+\mathbf{b}^{(2)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83611em;vertical-align:-.15em"></span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">F</span><span class="mord mathrm">F</span><span class="mord mathrm">N</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">R</span><span class="mord mathrm">e</span><span class="mord mathrm">L</span><span class="mord mathrm">U</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord"><span class="mord mathbf">b</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.938em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbf">b</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mtext>和</mtext><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">W^{(1)}和W^{(2)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> 是 d×d 矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mtext>和</mtext><msup><mi>b</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">b^{(1)}和b^{(2)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> 是 d 维向量。并且<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">S_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 之间没有交互</p><h4 id="ffn前馈神经网络"><a class="anchor" href="#ffn前馈神经网络">#</a> FFN（前馈神经网络）</h4><p>FFN（Feed-Forward Neural Network，前馈神经网络）是神经网络的一种基本结构，通常用于对输入数据进行非线性变换。它由一个或多个全连接层（也称为密集层）组成，每个层都包含一组可学习的权重和偏置。</p><h4 id="relu线性修正单元"><a class="anchor" href="#relu线性修正单元">#</a> ReLU（线性修正单元）</h4><p>ReLU（Rectified Linear Unit，线性修正单元）是一种常用的激活函数。它的定义如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{ReLU}(x)=\max(0,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">R</span><span class="mord mathrm">e</span><span class="mord mathrm">L</span><span class="mord mathrm">U</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p><p>ReLU 的作用是：</p><ol><li>对于输入的每个元素，如果该元素小于 0，则输出 0。</li><li>如果该元素大于等于 0，则输出该元素本身。</li></ol></li></ul><h3 id="堆叠自注意力块"><a class="anchor" href="#堆叠自注意力块">#</a> 堆叠自注意力块</h3><ul><li><p><strong>问题描述</strong>：在第一个自注意力快后<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">F_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 本质上就聚合了所有之前项目的嵌入，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>(即</mtext><msub><mover accent="true"><mi>E</mi><mo>^</mo></mover><mi>j</mi></msub><mo separator="true">,</mo><mi>j</mi><mo>≤</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{(即}\hat{E}_{j},j\leq i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.232878em;vertical-align:-.286108em"></span><span class="mord text"><span class="mord">(</span><span class="mord cjk_fallback">即</span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9467699999999999em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">E</span></span></span><span style="top:-3.25233em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.16666em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span>, 但是我们可以以基于 F 的另一个自注意力块来学习更复杂的项目转换。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">S</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mrow><mi mathvariant="bold">S</mi><mi mathvariant="bold">A</mi></mrow><mo stretchy="false">(</mo><msup><mi mathvariant="bold">F</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="bold">Q</mi><msup><mi mathvariant="bold">K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="bold">V</mi><mo separator="true">,</mo><mspace linebreak="newline"></mspace><msubsup><mi mathvariant="bold">F</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">N</mi></mrow><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">S</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo><mspace width="1em"><mi mathvariant="normal">∀</mi><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">}</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathbf{S}^{(b)}=\mathbf{SA}(\mathbf{F}^{(b-1)})=\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}\right)\mathbf{V},\\\mathbf{F}_{i}^{(b)}=\mathrm{FFN}(\mathbf{S}_{i}^{(b)}),\quad\forall i\in\{1,2,\ldots,n\},</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.938em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbf">S</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathbf">S</span><span class="mord mathbf">A</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.468361em;vertical-align:-.95003em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em"><span style="top:-2.17778em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.93222em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord mathnormal">d</span></span></span><span style="top:-2.89222em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.10777999999999999em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">Q</span></span><span class="mord"><span class="mord"><span class="mord mathbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">V</span></span><span class="mpunct">,</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.321664em;vertical-align:-.276864em"></span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231360000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.321664em;vertical-align:-.276864em"></span><span class="mord"><span class="mord mathrm">F</span><span class="mord mathrm">F</span><span class="mord mathrm">N</span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231360000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">∀</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">n</span><span class="mclose">}</span><span class="mpunct">,</span></span></span></span></span></p><p>其中第一块定义为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>S</mi><mtext></mtext><mi>a</mi><mi>n</mi><mi>d</mi><mtext></mtext><msup><mi>F</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>F</mi></mrow><annotation encoding="application/x-tex">S^{(1)}=S \ and \ F^{(1)}=F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8879999999999999em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="mspace"> </span><span class="mord mathnormal">a</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">F</span></span></span></span></p></li><li><p>随着模型深入出现了一些问题，采取的措施为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>g</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>+</mo><mtext>Dropout</mtext><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mtext>LayerNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g&#x27;(x)=x+\text{Dropout}(g(\text{LayerNorm}(x)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.801892em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Dropout</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord text"><span class="mord">LayerNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left right left right" columnspacing="0em 1em 0em 1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mn>1.</mn><mtext>输入</mtext><mi>x</mi><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo separator="true">⋅</mo><mi>x</mi><mtext>是上一层的输出或者当前层的输入。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>2. 层归一化(Layer Normalization):</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∙</mo><mtext>首先对输入</mtext><mi>x</mi><mtext>进行层归一化:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⋅</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>缩放和偏移参数。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>3. 应用函数</mtext><mi>g</mi><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo separator="true">⋅</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>注意力机制</mtext><mo stretchy="false">(</mo><mi>S</mi><mi>A</mi><mo stretchy="false">)</mo><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>g</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>对于</mtext><mi>F</mi><mi>F</mi><mi>N</mi><mo separator="true">,</mo><mtext>函数</mtext><mi>g</mi><mtext>的具体形式为</mtext><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>g</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mi mathvariant="bold">W</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">b</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><msup><mi mathvariant="bold">W</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">b</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>4.Dropout:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo separator="true">⋅</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>在应用函数</mtext><mi>g</mi><mtext>之后,对结果应用Dropout,以防止过拟合:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mrow><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>Dropout的具体操作是在每次训练</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>5. 残差连接(Residual Connection):</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo separator="true">⋅</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>最后,将Dropout的结果与原输入</mtext><mi>x</mi><mtext>相加,实现残差连接</mtext><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msup><mi>g</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>+</mo><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mrow><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} &amp;1.\text{ 输入 }x: \\ &amp;·x是上一层的输出或者当前层的输入。 \\ &amp;\text{2. 层归一化(Layer Normalization):} \\ &amp;\bullet\text{ 首先对输入 }x\text{ 进行层归一化:} \\ &amp;\mathrm{LayerNorm}(x)=\frac{x-\mu}{\sqrt{\sigma^{2}+\epsilon}}\cdot\gamma+\beta \\ &amp;\text{缩放和偏移参数。} \\ &amp;\text{3. 应用函数 }g: \\ &amp;· \\ &amp;注意力机制(SA): \\ &amp;g(\mathrm{LayerNorm}(x)) \\ &amp;对于FFN,函数g的具体形式为: \\ &amp;&amp;&amp;g(\mathrm{LayerNorm}(x))=\mathrm{ReLU}(\mathrm{LayerNorm}(x)\mathbf{W}^{(1)}+\mathbf{b}^{(1)})\mathbf{W}^{(2)}+\mathbf{b}^{(2)} \\ &amp;\text{4.Dropout:} \\ &amp;·&amp;&amp; \text{在应用函数 }g\text{ 之后,对结果应用Dropout,以防止过拟合:} \\ &amp;&amp;&amp;\mathrm{Dropout}(g(\mathrm{LayerNorm}(x))) \\ &amp;&amp;&amp;\text{Dropout的具体操作是在每次训练} \\ &amp; \text{5. 残差连接(Residual Connection):} \\ &amp;·&amp;&amp;&amp; \text{最后,将Dropout的结果与原输入 }x\text{ 相加,实现残差连接}: \\ &amp;&amp;&amp;g&#x27;(x)=x+\mathrm{Dropout}(g(\mathrm{LayerNorm}(x))) \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:29.588330000000003em;vertical-align:-14.544165000000001em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:15.044165000000001em"><span style="top:-17.464495000000003em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-15.964495000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-14.464495em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-12.964495em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-11.044165em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-8.974165em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-7.474164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-5.974164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-4.474164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-2.9741649999999997em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:-1.474164999999998em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:.12383500000000103em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:1.623835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:3.123835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:4.6238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:6.1238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:7.6238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:9.123835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span><span style="top:10.623835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:14.544165000000001em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:15.044165000000001em"><span style="top:-17.464495000000003em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord">1</span><span class="mord">.</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">输入</span><span class="mord"> </span></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span><span style="top:-15.964495000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">上</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">层</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">输</span><span class="mord cjk_fallback">出</span><span class="mord cjk_fallback">或</span><span class="mord cjk_fallback">者</span><span class="mord cjk_fallback">当</span><span class="mord cjk_fallback">前</span><span class="mord cjk_fallback">层</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">输</span><span class="mord cjk_fallback">入</span><span class="mord cjk_fallback">。</span></span></span><span style="top:-14.464495em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">2. </span><span class="mord cjk_fallback">层归一化</span><span class="mord">(Layer Normalization):</span></span></span></span><span style="top:-12.964495em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">首先对输入</span><span class="mord"> </span></span><span class="mord mathnormal">x</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">进行层归一化</span><span class="mord">:</span></span></span></span><span style="top:-11.044165em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em"><span style="top:-2.196611em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.913389em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.873389em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.12661100000000003em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05556em">γ</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05278em">β</span></span></span><span style="top:-8.974165em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">缩放和偏移参数。</span></span></span></span><span style="top:-7.474164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">3. </span><span class="mord cjk_fallback">应用函数</span><span class="mord"> </span></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span><span style="top:-5.974164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mpunct">⋅</span></span></span><span style="top:-4.474164999999999em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord cjk_fallback">注</span><span class="mord cjk_fallback">意</span><span class="mord cjk_fallback">力</span><span class="mord cjk_fallback">机</span><span class="mord cjk_fallback">制</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span><span style="top:-2.9741649999999997em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span><span style="top:-1.474164999999998em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord cjk_fallback">函</span><span class="mord cjk_fallback">数</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">具</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">形</span><span class="mord cjk_fallback">式</span><span class="mord cjk_fallback">为</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span><span style="top:.12383500000000103em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span></span></span><span style="top:1.623835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">4.Dropout:</span></span></span></span><span style="top:3.123835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mpunct">⋅</span></span></span><span style="top:4.6238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span></span></span><span style="top:6.1238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span></span></span><span style="top:7.6238350000000015em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">5. </span><span class="mord cjk_fallback">残差连接</span><span class="mord">(Residual Connection):</span></span></span></span><span style="top:9.123835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span><span class="mpunct">⋅</span></span></span><span style="top:10.623835000000001em"><span class="pstrut" style="height:3.26033em"></span><span class="mord"><span class="mord"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:14.544165000000001em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-2.4461650000000015em"><span style="top:.4461650000000015em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span><span style="top:3.4461650000000015em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span><span style="top:4.9461650000000015em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span><span style="top:6.4461650000000015em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span><span style="top:9.446165em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span><span style="top:10.946165em"><span class="pstrut" style="height:2.9379999999999997em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:14.544165000000001em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-2.4461650000000015em"><span style="top:.3841650000000012em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathrm">R</span><span class="mord mathrm">e</span><span class="mord mathrm">L</span><span class="mord mathrm">U</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord"><span class="mord mathbf">b</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord"><span class="mord mathbf">b</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span><span style="top:3.384165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">在应用函数</span><span class="mord"> </span></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">之后</span><span class="mord">,</span><span class="mord cjk_fallback">对结果应用</span><span class="mord">Dropout,</span><span class="mord cjk_fallback">以防止过拟合</span><span class="mord">:</span></span></span></span><span style="top:4.884165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathrm">D</span><span class="mord mathrm">r</span><span class="mord mathrm">o</span><span class="mord mathrm">p</span><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span><span style="top:6.384165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">Dropout</span><span class="mord cjk_fallback">的具体操作是在每次训练</span></span></span></span><span style="top:9.384165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span></span></span><span style="top:10.884165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.801892em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathrm">D</span><span class="mord mathrm">r</span><span class="mord mathrm">o</span><span class="mord mathrm">p</span><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:14.544165000000001em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-11.544165000000001em"><span style="top:9.384165000000001em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">最后</span><span class="mord">,</span><span class="mord cjk_fallback">将</span><span class="mord">Dropout</span><span class="mord cjk_fallback">的结果与原输入</span><span class="mord"> </span></span><span class="mord mathnormal">x</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">相加</span><span class="mord">,</span><span class="mord cjk_fallback">实现残差连接</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:13.044165000000001em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中 g (x) 表示自注意层或前馈网络。对于每层的 g，我们输入 g 之前都要对 x 进行层归一化，对 g 的输出应用 dropout，并将输入 x 添加到最终输出中。</p></li></ul><h3 id="层归一化"><a class="anchor" href="#层归一化">#</a> 层归一化</h3><p>用于加速和稳定神经网络的训练过程。它通过在每一层对输入进行归一化，解决了在深层神经网络中训练时可能遇到的一些问题，例如梯度消失和梯度爆炸。</p><p>层归一化的基本思想是对每个神经元的输入进行归一化，使得输入的均值为 0，方差为 1。与批量归一化（Batch Normalization）不同，层归一化在计算归一化统计量时，只考虑当前层的输入，而不是一个小批量的数据。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">L</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mo>⊙</mo><mfrac><mrow><mi mathvariant="bold">x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>+</mo><mi>β</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathrm{LayerNorm}(\mathbf{x})=\alpha\odot\frac{\mathbf{x}-\mu}{\sqrt{\sigma^{2}+\epsilon}}+\beta,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">L</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mathrm">N</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.1903300000000003em;vertical-align:-.93em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em"><span style="top:-2.196611em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.913389em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.873389em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.12661100000000003em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05278em">β</span><span class="mpunct">,</span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord">⊙</span></span></span></span> 是元素向乘积，是指对两个相同维度的矩阵或向量进行对应元素的逐个相乘。这个操作不同于矩阵乘法，它不涉及矩阵之间的行列相乘和求和，只是简单地对对应位置的元素进行乘积运算。</p><h4 id="元素向量积的数学表示"><a class="anchor" href="#元素向量积的数学表示">#</a> 元素向量积的数学表示</h4><p>假设有两个相同维度矩阵 A 和 B，元素分别为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">B_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.05017em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span>，则它们的元素向量积 C 可以表示为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>⊙</mo><mi>B</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>其中,</mtext><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>×</mo><msub><mi>B</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mtext>。</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;C=A\odot B\\\\&amp;\text{其中,}C_{ij}=A_{ij}\times B_{ij}。\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.500000000000002em;vertical-align:-2.000000000000001em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5000000000000004em"><span style="top:-4.5em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-3em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-1.4999999999999991em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.000000000000001em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5000000000000004em"><span style="top:-4.66em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span><span style="top:-1.6599999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">其中</span><span class="mord">,</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.05017em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord cjk_fallback">。</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0000000000000004em"><span></span></span></span></span></span></span></span></span></span></span></span></p><h5 id="举个例子"><a class="anchor" href="#举个例子">#</a> 举个例子</h5><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>假设有两个矩阵</mtext><mi>A</mi><mtext>和</mtext><mi>B</mi><mo>:</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>5</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>B</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>7</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>8</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>10</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>11</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>它们的元素向乘积 C 为:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>⊙</mo><mi>B</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>×</mo><mn>7</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn><mo>×</mo><mn>8</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>3</mn><mo>×</mo><mn>9</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>4</mn><mo>×</mo><mn>10</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>5</mn><mo>×</mo><mn>11</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>6</mn><mo>×</mo><mn>12</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>7</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>16</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>27</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>40</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>55</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>72</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} &amp;假设有两个矩阵A和B: \\ &amp;A=\begin{pmatrix}1&amp;2&amp;3\\4&amp;5&amp;6\end{pmatrix} \\ &amp;B=\begin{pmatrix}7&amp;8&amp;9\\10&amp;11&amp;12\end{pmatrix} \\ &amp;\text{它们的元素向乘积 C 为:} \\ &amp;C=A\odot B=\begin{pmatrix}1\times7&amp;2\times8&amp;3\times9\\4\times10&amp;5\times11&amp;6\times12\end{pmatrix}=\begin{pmatrix}7&amp;16&amp;27\\40&amp;55&amp;72\end{pmatrix} \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:11.100090000000002em;vertical-align:-5.300045000000001em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.800045em"><span style="top:-8.410045em"><span class="pstrut" style="height:3.45em"></span><span class="mord"></span></span><span style="top:-6.300044999999999em"><span class="pstrut" style="height:3.45em"></span><span class="mord"></span></span><span style="top:-3.6000149999999995em"><span class="pstrut" style="height:3.45em"></span><span class="mord"></span></span><span style="top:-1.5099849999999995em"><span class="pstrut" style="height:3.45em"></span><span class="mord"></span></span><span style="top:.6000150000000004em"><span class="pstrut" style="height:3.45em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.300045000000001em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.800045em"><span style="top:-8.410045em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"></span><span class="mord cjk_fallback">假</span><span class="mord cjk_fallback">设</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">两</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">矩</span><span class="mord cjk_fallback">阵</span><span class="mord mathnormal">A</span><span class="mord cjk_fallback">和</span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span><span style="top:-6.300044999999999em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-3.6000149999999995em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">7</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">8</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-1.5099849999999995em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">它们的元素向乘积</span><span class="mord"> C </span><span class="mord cjk_fallback">为</span><span class="mord">:</span></span></span></span><span style="top:.6000150000000004em"><span class="pstrut" style="height:3.45em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">7</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">4</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">1</span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">8</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">5</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">1</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">3</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">9</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">6</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">1</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">7</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">4</span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mord">6</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">5</span><span class="mord">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mord">7</span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">7</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.300045000000001em"><span></span></span></span></span></span></span></span></span></span></span></span></p><h3 id="预测层"><a class="anchor" href="#预测层">#</a> 预测层</h3><p>在 b 个自我关注快后根据<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>F</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">F_{t}^{(b)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2905559999999998em;vertical-align:-.24575599999999992em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.454244em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2197999999999998em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24575599999999992em"><span></span></span></span></span></span></span></span></span></span> 来预测下一个项目。具体来说采用 MF 层来预测项目<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 的相关性。</p><ul><li><p>MF 层（Matrix Factorization Layer，矩阵分解层）在推荐系统中是指一种使用矩阵分解技术来预测用户与物品之间的交互评分或相关性的方法。矩阵分解是一种常见的协同过滤技术，通过将用户 - 物品评分矩阵分解为两个低维矩阵来建模用户偏好和物品特征</p></li><li><p>矩阵分解的目标是将一个大矩阵分解为两个更小的矩阵，这两个矩阵的乘积近似于原始矩阵。在推荐系统中，通常有一个用户 - 物品评分矩阵 R，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">R_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.00773em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 表示用户 i 对物品 j 的评分。矩阵分解的目的是将 R 分解为两个地位矩阵 U 和 V。</p></li><li><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>R</mi><mo>≈</mo><mi>U</mi><msup><mi>V</mi><mi>T</mi></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>其中:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∙</mo><mspace width="1em"><mi>U</mi><mtext>是用户矩阵,维度为</mtext><mi>m</mi><mo>×</mo><mi>k</mi><mtext>,每一行对应一个用户的隐向量表示。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∙</mo><mspace width="1em"><mi>V</mi><mtext>是物品矩阵,维度为</mtext><mi>n</mi><mo>×</mo><mi>k</mi><mtext>,每一行对应一个物品的隐向量表示。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∙</mo><mspace width="1em"><mi>k</mi><mtext>是隐向量的维度,也称为潜在特征的数量。</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;R\approx UV^T\\&amp;\text{其中:}\\&amp;\bullet\quad U\text{ 是用户矩阵,维度为 }m\times k\text{,每一行对应一个用户的隐向量表示。}\\&amp;\bullet\quad V\text{ 是物品矩阵,维度为 }n\times k\text{,每一行对应一个物品的隐向量表示。}\\&amp;\bullet\quad k\text{ 是隐向量的维度,也称为潜在特征的数量。}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.551331em;vertical-align:-3.5256654999999997em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.025665500000001em"><span style="top:-6.025665500000001em"><span class="pstrut" style="height:2.891331em"></span><span class="mord"></span></span><span style="top:-4.525665500000001em"><span class="pstrut" style="height:2.891331em"></span><span class="mord"></span></span><span style="top:-3.0256655000000006em"><span class="pstrut" style="height:2.891331em"></span><span class="mord"></span></span><span style="top:-1.5256655000000006em"><span class="pstrut" style="height:2.891331em"></span><span class="mord"></span></span><span style="top:-.025665500000000563em"><span class="pstrut" style="height:2.891331em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.5256654999999997em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.025665500000001em"><span style="top:-6.1343345000000005em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.00773em">R</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.10903em">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span><span style="top:-4.6343345000000005em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">其中</span><span class="mord">:</span></span></span></span><span style="top:-3.1343345000000005em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">U</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">是用户矩阵</span><span class="mord">,</span><span class="mord cjk_fallback">维度为</span><span class="mord"> </span></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mord text"><span class="mord">,</span><span class="mord cjk_fallback">每一行对应一个用户的隐向量表示。</span></span></span></span><span style="top:-1.6343345000000005em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">是物品矩阵</span><span class="mord">,</span><span class="mord cjk_fallback">维度为</span><span class="mord"> </span></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mord text"><span class="mord">,</span><span class="mord cjk_fallback">每一行对应一个物品的隐向量表示。</span></span></span></span><span style="top:-.13433450000000047em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">是隐向量的维度</span><span class="mord">,</span><span class="mord cjk_fallback">也称为潜在特征的数量。</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.5256654999999997em"><span></span></span></span></span></span></span></span></span></span></span></span></p></li><li></li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><msubsup><mi mathvariant="bold">F</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><msubsup><mi mathvariant="bold">N</mi><mi>i</mi><mi>T</mi></msubsup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">r_{i,t}=\mathbf{F}_t^{(b)}\mathbf{N}_i^T,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.2917999999999998em;vertical-align:-.247em"></span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.454244em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24575599999999997em"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf">N</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{i,t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 是物品 i 在时间步 t 被推荐的相关性分数。</li><li>$F_t $ 是用户在时间步 t 的隐向量表示。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">N_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是物品 i 的隐向量表示。</li></ul><p>在这里我们使用单项嵌入 M 的方案，即</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><msubsup><mi mathvariant="bold">F</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><msubsup><mi mathvariant="bold">M</mi><mi>i</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">r_{i,t}=\mathbf{F}_{t}^{(b)}\mathbf{M}_{i}^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.2917999999999998em;vertical-align:-.247em"></span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.454244em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24575599999999997em"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf">M</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span></span></span></p><p>在此矩阵中嵌入矩阵 M 是一个大小为 | I|×d 的矩阵，其中 | I | 是物品总数量，d 是嵌入向量的维度。</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>F</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">F_{t}^{(b)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2905559999999998em;vertical-align:-.24575599999999992em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.454244em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2197999999999998em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24575599999999992em"><span></span></span></span></span></span></span></span></span></span> 可以表示为取决于项目嵌入 M 的函数，即：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">F</mi><mi>t</mi><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">M</mi><msub><mi>s</mi><mn>1</mn></msub></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">M</mi><msub><mi>s</mi><mn>2</mn></msub></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">M</mi><msub><mi>s</mi><mi>t</mi></msub></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{F}_{t}^{(b)}=f(\mathbf{M}_{s_{1}},\mathbf{M}_{s_{2}},\ldots,\mathbf{M}_{s_{t}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.290556em;vertical-align:-.24575599999999997em"></span><span class="mord"><span class="mord"><span class="mord mathbf">F</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.454244em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24575599999999997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-.2501em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbf">M</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139199999999997em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2501em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathbf">M</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139199999999997em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2501em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathbf">M</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139199999999997em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.29634285714285713em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2501em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>注意：需要实现不对称 ——<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><msub><mi>M</mi><mi>i</mi></msub><mo stretchy="false">)</mo><msubsup><mi>M</mi><mi>j</mi><mi>T</mi></msubsup><mo mathvariant="normal">≠</mo><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><msub><mi>M</mi><mi>j</mi></msub><mo stretchy="false">)</mo><msubsup><mi>M</mi><mi>i</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">FFN(M_i)M_j^T≠FFN(M_j)M_i^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-.394772em"></span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-2.441336em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.394772em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.1274389999999999em;vertical-align:-.286108em"></span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-2.441336em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span></p><p><strong>考虑用户之前的操作，并从访问过的项目的嵌入中得出隐式用户嵌入</strong></p><h3 id="网络层训练"><a class="anchor" href="#网络层训练">#</a> 网络层训练</h3><p>我们将每个用户序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msubsup><mi mathvariant="script">S</mi><mn>1</mn><mi>u</mi></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="script">S</mi><mn>2</mn><mi>u</mi></msubsup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msubsup><mi mathvariant="script">S</mi><mrow><mi mathvariant="normal">∣</mi><msup><mi mathvariant="script">S</mi><mi>u</mi></msup><mi mathvariant="normal">∣</mi><mo>−</mo><mn>1</mn></mrow><mi>u</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathcal{S}_{1}^{u},\mathcal{S}_{2}^{u},\ldots,\mathcal{S}_{|\mathcal{S}^{u}|-1}^{u})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2469999999999999em;vertical-align:-.49699999999999994em"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-2.4518920000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24810799999999997em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-2.4518920000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.24810799999999997em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6643919999999999em"><span style="top:-2.378em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.49699999999999994em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 转换为固定长度的序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">s=\{s_1,s_2,\ldots,s_n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>：我们将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">o_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 定义为时间步 t 的预期输出：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>&lt;pad&gt;</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>如果</mtext><msub><mi>s</mi><mi>t</mi></msub><mtext>是一个填充项</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>≤</mo><mi>t</mi><mo>&lt;</mo><mi>n</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>S</mi><mrow><mi mathvariant="normal">∣</mi><msup><mi>S</mi><mi>u</mi></msup><mi mathvariant="normal">∣</mi></mrow><mi>u</mi></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>t</mi><mo>=</mo><mi>n</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">o_t=\begin{cases}\text{&lt;pad&gt;}&amp;\text{如果 }s_t\text{是一个填充项}\\s_{t+1}&amp;1\leq t&lt;n\\S_{|S^u|}^u&amp;t=n\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:4.385em;vertical-align:-1.9425em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35002em"><span style="top:-2.19999em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.19499em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-2.20499em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-3.15001em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.2950099999999996em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.30501em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.60002em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8500199999999998em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4425em"><span style="top:-4.442500000000001em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">&lt;pad&gt;</span></span></span></span><span style="top:-3.0025em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span></span></span><span style="top:-1.5625em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6643919999999999em"><span style="top:-2.378em;margin-left:-.05764em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span><span class="mord mtight">∣</span></span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.49699999999999994em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9425em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4425em"><span style="top:-4.442500000000001em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">如果</span><span class="mord"> </span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord text"><span class="mord cjk_fallback">是一个填充项</span></span></span></span><span style="top:-3.0025em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">n</span></span></span><span style="top:-1.5625em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9425em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li><p>其中 pad 表示填充项，我们的模型以序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">s</span></span></span></span> 作为输入，响应的序列<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi></mrow><annotation encoding="application/x-tex">o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">o</span></span></span></span> 为预期输出，我们采用二院交叉熵损失作为目标函数</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>−</mo><munder><mo>∑</mo><mrow><msup><mi mathvariant="script">S</mi><mi>u</mi></msup><mo>∈</mo><mi mathvariant="script">S</mi></mrow></munder><munder><mo>∑</mo><mrow><mi>t</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo></mrow></munder><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><msub><mi>o</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>∉</mo><msup><mi mathvariant="script">S</mi><mi>u</mi></msup></mrow></munder><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">-\sum_{\mathcal{S}^u\in\mathcal{S}}\sum_{t\in[1,2,...,n]}\left[\log(\sigma(r_{o_t,t}))+\sum_{j\not\in\mathcal{S}^u}\log(1-\sigma(r_{j,t}))\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6010299999999997em;vertical-align:-1.55002em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.075em">S</span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.808995em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">∈</span><span class="mopen mtight">[</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">]</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em"><span style="top:-2.2500000000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.8099900000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.05101em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em"><span></span></span></span></span></span></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.28055599999999997em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.29634285714285713em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.075em">S</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.438221em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em"><span style="top:-2.2500000000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.8099900000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.05101em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>S</mi><mo>:</mo><mtext>表示所有用户的集合。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msup><mi>S</mi><mi>u</mi></msup><mspace></mspace><mspace width="0.1111111111111111em"><mo lspace="0em" rspace="0.17em"></mo><mtext>⁣</mtext><mo lspace="0em" rspace="0em">:</mo><mspace width="0.3333333333333333em"><mtext>表示用户</mtext><mi>u</mi><mtext>的序列。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>t</mi><mspace></mspace><mspace width="0.1111111111111111em"><mo lspace="0em" rspace="0.17em"></mo><mtext>⁣</mtext><mo lspace="0em" rspace="0em">:</mo><mspace width="0.3333333333333333em"><mtext>表示时间步,取值范围为</mtext><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">}</mo><mtext>。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msub><mi>o</mi><mi>t</mi></msub><mspace></mspace><mspace width="0.1111111111111111em"><mo lspace="0em" rspace="0.17em"></mo><mtext>⁣</mtext><mo lspace="0em" rspace="0em">:</mo><mspace width="0.3333333333333333em"><mtext>在时间步</mtext><mi>t</mi><mtext>的预测输出。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msub><mi>r</mi><mrow><msub><mi>o</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi></mrow></msub><mtext>:在时间步</mtext><mi>t</mi><mtext>预测物品</mtext><msub><mi>o</mi><mi>t</mi></msub><mtext>的相关性分数。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msub><mi>r</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mspace></mspace><mspace width="0.1111111111111111em"><mo lspace="0em" rspace="0.17em"></mo><mtext>⁣</mtext><mo lspace="0em" rspace="0em">:</mo><mspace width="0.3333333333333333em"><mtext>在时间步</mtext><mi>t</mi><mtext>预测物品</mtext><mi>j</mi><mtext>的相关性分数,</mtext><mi>j</mi><mo mathvariant="normal">∉</mo><msup><mi>S</mi><mi>u</mi></msup><mtext>表示不在用户</mtext><mi>u</mi><mtext>的历史</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>交互序列中的物品。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>σ</mi><mo>:</mo><mtext>表示</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mtext>函数。</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} &amp;S:表示所有用户的集合。 \\ &amp;S^{u}\colon\text{表示用户 }u\text{ 的序列。} \\ &amp;t\colon\text{表示时间步,取值范围为 }\{1,2,\ldots,n\}。 \\ &amp;o_{t}\colon\text{在时间步 }t\text{ 的预测输出。} \\ &amp;r_{o_t,t}\text{:在时间步 }t\text{ 预测物品 }o_t\text{ 的相关性分数。} \\ &amp;r_{j,t}\colon\text{ 在时间步 }t\text{ 预测物品 }j\text{ 的相关性分数,}j\notin S^u\text{ 表示不在用户 }u\text{ 的历史} \\ &amp;\text{交互序列中的物品。} \\ &amp;\sigma:表示sigmoid函数。 \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:12.000000000000002em;vertical-align:-5.750000000000001em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.250000000000001em"><span style="top:-8.25em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-6.75em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-5.249999999999999em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-3.749999999999999em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-2.249999999999999em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-.7499999999999987em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:.7500000000000009em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:2.250000000000001em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.750000000000001em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.250000000000001em"><span style="top:-8.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">示</span><span class="mord cjk_fallback">所</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">用</span><span class="mord cjk_fallback">户</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">集</span><span class="mord cjk_fallback">合</span><span class="mord cjk_fallback">。</span></span></span><span style="top:-6.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7143919999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span><span class="mspace nobreak"></span><span class="mspace" style="margin-right:.1111111111111111em"></span><span class="mpunct"></span><span class="mspace" style="margin-right:-.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mrel">:</span></span><span class="mspace" style="margin-right:.3333333333333333em"></span><span class="mord text"><span class="mord cjk_fallback">表示用户</span><span class="mord"> </span></span><span class="mord mathnormal">u</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的序列。</span></span></span></span><span style="top:-5.409999999999999em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal">t</span><span class="mspace nobreak"></span><span class="mspace" style="margin-right:.1111111111111111em"></span><span class="mpunct"></span><span class="mspace" style="margin-right:-.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mrel">:</span></span><span class="mspace" style="margin-right:.3333333333333333em"></span><span class="mord text"><span class="mord cjk_fallback">表示时间步</span><span class="mord">,</span><span class="mord cjk_fallback">取值范围为</span><span class="mord"> </span></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">n</span><span class="mclose">}</span><span class="mord cjk_fallback">。</span></span></span><span style="top:-3.9099999999999993em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace nobreak"></span><span class="mspace" style="margin-right:.1111111111111111em"></span><span class="mpunct"></span><span class="mspace" style="margin-right:-.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mrel">:</span></span><span class="mspace" style="margin-right:.3333333333333333em"></span><span class="mord text"><span class="mord cjk_fallback">在时间步</span><span class="mord"> </span></span><span class="mord mathnormal">t</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的预测输出。</span></span></span></span><span style="top:-2.4099999999999993em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.28055599999999997em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.29634285714285713em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">:</span><span class="mord cjk_fallback">在时间步</span><span class="mord"> </span></span><span class="mord mathnormal">t</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">预测物品</span><span class="mord"> </span></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的相关性分数。</span></span></span></span><span style="top:-.9099999999999988em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace nobreak"></span><span class="mspace" style="margin-right:.1111111111111111em"></span><span class="mpunct"></span><span class="mspace" style="margin-right:-.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mrel">:</span></span><span class="mspace" style="margin-right:.3333333333333333em"></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">在时间步</span><span class="mord"> </span></span><span class="mord mathnormal">t</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">预测物品</span><span class="mord"> </span></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的相关性分数</span><span class="mord">,</span></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel"><span class="mord"><span class="mrel">∈</span></span><span class="mord vbox"><span class="thinbox"><span class="llap"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="inner"><span class="mord"><span class="mord">/</span><span class="mspace" style="margin-right:.05555555555555555em"></span></span></span><span class="fix"></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7143919999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">表示不在用户</span><span class="mord"> </span></span><span class="mord mathnormal">u</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的历史</span></span></span></span><span style="top:.5900000000000007em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">交互序列中的物品。</span></span></span></span><span style="top:2.0900000000000007em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">示</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord cjk_fallback">函</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">。</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.750000000000001em"><span></span></span></span></span></span></span></span></span></span></span></span></p></li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><msub><mi>o</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>:对于时间步</mtext><mi>t</mi><mtext>的正样本</mtext><msub><mi>o</mi><mi>t</mi></msub><mtext>,计算预测相关性分数的对数。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><munder><mo>∑</mo><mrow><mi>j</mi><mo mathvariant="normal">∉</mo><msup><mi>S</mi><mi>n</mi></msup></mrow></munder><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>:对于时间步</mtext><mi>t</mi><mtext>的负样本集合,计算每个负样本</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>的预测相关性分数的对数。</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;\log(\sigma(r_{o_{t},t}))\text{:对于时间步 }t\text{ 的正样本 }o_t\text{,计算预测相关性分数的对数。}\\&amp;\sum_{j\notin S^n}\log(1-\sigma(r_{j,t}))\text{:对于时间步 }t\text{ 的负样本集合,计算每个负样本}\\&amp;\text{的预测相关性分数的对数。}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.866010000000002em;vertical-align:-2.6830050000000014em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.1830050000000005em"><span style="top:-5.39301em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span><span style="top:-3.6830049999999996em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span><span style="top:-1.0269999999999988em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.6830050000000014em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.1830050000000005em"><span style="top:-5.39301em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.28055599999999997em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.29634285714285713em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mord text"><span class="mord">:</span><span class="mord cjk_fallback">对于时间步</span><span class="mord"> </span></span><span class="mord mathnormal">t</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的正样本</span><span class="mord"> </span></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">,</span><span class="mord cjk_fallback">计算预测相关性分数的对数。</span></span></span></span><span style="top:-3.6830049999999996em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.808995em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight"><span class="mord mtight"><span class="mrel mtight">∈</span></span><span class="mord vbox mtight"><span class="thinbox mtight"><span class="llap mtight"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="inner"><span class="mord mtight"><span class="mord mtight">/</span><span class="mspace mtight" style="margin-right:.06505555555555556em"></span></span></span><span class="fix"></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mord text"><span class="mord">:</span><span class="mord cjk_fallback">对于时间步</span><span class="mord"> </span></span><span class="mord mathnormal">t</span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">的负样本集合</span><span class="mord">,</span><span class="mord cjk_fallback">计算每个负样本</span></span></span></span><span style="top:-1.0269999999999988em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">的预测相关性分数的对数。</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.6830050000000014em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>数</mtext><mo separator="true">,</mo><mtext>从而提高正样本的预测概率。</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>负样本损失:通过</mtext><munder><mo>∑</mo><mrow><mi>j</mi><mo mathvariant="normal">∉</mo><msup><mi>S</mi><mi>u</mi></msup></mrow></munder><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>r</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>项,模型希望最小化负样本的预</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>测相关性分数,从而降低负样本的预测概率。</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} &amp;数,从而提高正样本的预测概率。 \\ &amp;\text{负样本损失:通过}\sum_{j\notin S^{u}}\log(1-\sigma(r_{j,t})) \text{项,模型希望最小化负样本的预} \\ &amp;\text{测相关性分数,从而降低负样本的预测概率。} \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.866010000000002em;vertical-align:-2.6830050000000014em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.1830050000000005em"><span style="top:-5.39301em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span><span style="top:-3.6830049999999996em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span><span style="top:-1.0269999999999988em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.6830050000000014em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.1830050000000005em"><span style="top:-5.39301em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mord cjk_fallback">数</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord cjk_fallback">从</span><span class="mord cjk_fallback">而</span><span class="mord cjk_fallback">提</span><span class="mord cjk_fallback">高</span><span class="mord cjk_fallback">正</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">预</span><span class="mord cjk_fallback">测</span><span class="mord cjk_fallback">概</span><span class="mord cjk_fallback">率</span><span class="mord cjk_fallback">。</span></span></span><span style="top:-3.6830049999999996em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">负样本损失</span><span class="mord">:</span><span class="mord cjk_fallback">通过</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.808995em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight"><span class="mord mtight"><span class="mrel mtight">∈</span></span><span class="mord vbox mtight"><span class="thinbox mtight"><span class="llap mtight"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="inner"><span class="mord mtight"><span class="mord mtight">/</span><span class="mspace mtight" style="margin-right:.06505555555555556em"></span></span></span><span class="fix"></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5935428571428571em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mord text"><span class="mord cjk_fallback">项</span><span class="mord">,</span><span class="mord cjk_fallback">模型希望最小化负样本的预</span></span></span></span><span style="top:-1.0269999999999988em"><span class="pstrut" style="height:3.050005em"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord cjk_fallback">测相关性分数</span><span class="mord">,</span><span class="mord cjk_fallback">从而降低负样本的预测概率。</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.6830050000000014em"><span></span></span></span></span></span></span></span></span></span></span></span></p><h3 id="讨论"><a class="anchor" href="#讨论">#</a> 讨论</h3><ul><li><p>因式分解马尔科夫链可得到：FMC 会对一阶项目转移矩阵进行因式分解，并根据上一项目<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 预测下一个项目<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mi mathvariant="normal">∣</mi><mi>i</mi><mo stretchy="false">)</mo><mo>∝</mo><msubsup><mi mathvariant="bold">M</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi mathvariant="bold">N</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">P(j|i)\propto\mathbf{M}_i^T\mathbf{N}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord">∣</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.177439em;vertical-align:-.286108em"></span><span class="mord"><span class="mord"><span class="mord mathbf">M</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913309999999999em"><span style="top:-2.4530000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathbf">N</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mi mathvariant="normal">∣</mi><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(j|i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord">∣</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span> 表示在给定物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 的情况下，推荐物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 的概率</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">M_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 表示物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 的嵌入向量</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">N_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 表示物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 的嵌入向量</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>M</mi><mi>i</mi><mi>j</mi></msubsup></mrow><annotation encoding="application/x-tex">M_i^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-.276864em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.942572em"><span style="top:-2.4231360000000004em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809080000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span></span></span></span> 表示物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 的嵌入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">M_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和物品<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> 的嵌入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">N_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 的内积</li></ul></li></ul><h3 id="实验"><a class="anchor" href="#实验">#</a> 实验</h3><h4 id="问题"><a class="anchor" href="#问题">#</a> 问题</h4><ul><li>SASRec 是否优于最先进的模型（包括基于 CNN/RNN 的方法）？</li><li>SASRec 架构中各个组件的影响是什么？</li><li>SASRec 的训练效率和可扩展性（关于 n）是多少？</li><li>注意力权重是否能够学习与位置或项目属性相关的有意义的模式？</li></ul><h4 id="数据集"><a class="anchor" href="#数据集">#</a> 数据集</h4><ul><li>Amazon：[46] 中引入的一系列数据集，包含从 <span class="exturl" data-url="aHR0cDovL0FtYXpvbi5jb20=">Amazon.com</span> 抓取的大量产品评论语料库。Amazon 上的顶级产品类别被视为单独的数据集。我们考虑两个类别，“美容” 和 “游戏”。该数据集以其高稀疏性和多变性而著称。</li><li>Steam：我们引入了一个从大型在线视频游戏分发平台 Steam 抓取的新数据集。该数据集包含 2,567,538 名用户、15,474 款游戏和 7,793,069 条英文评论，时间跨度为 2010 年 10 月至 2018 年 1 月。 该数据集还包含可能对未来工作有用的丰富信息，例如用户的游戏时间、定价信息、媒体评分、类别、开发者（等）</li><li>MovieLens：一种广泛用于评估协同过滤算法的基准数据集。我们使用包含 100 万用户评分的版本（MovieLens-1M）。</li></ul><p>将评论或评分的存在视为隐式反馈（即用户与商品进行了交互），并使用时间戳来确定操作的顺序。我们丢弃相关操作少于 5 个的用户和商品。为了进行分区，我们将每个用户 u 的历史序列 Su 分成三部分：</p><p |s^u|="">（1）用于测试的最近操作S^u_</p><p |s^u|-1="">（2）用于验证的第二最近操作S^u_</p><p>（3）用于训练的所有剩余操作。请注意，在测试期间，输入序列包含训练操作和验证操作</p><h1 id="代码解析"><a class="anchor" href="#代码解析">#</a> 代码解析</h1><h2 id="modulespy"><a class="anchor" href="#modulespy">#</a> <span class="exturl" data-url="aHR0cDovL21vZHVsZXMucHk=">modules.py</span></h2><p><strong>这个代码实现了 Transformer 模型的一部分，主要包括位置编码、层归一化、嵌入、多头注意力机制和前馈神经网络。</strong></p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">#/usr/bin/python2</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">June 2017 by kyubyong park. </span></span><br><span class="line"><span class="string">kbpark.linguist@gmail.com.</span></span><br><span class="line"><span class="string">https://www.github.com/kyubyong/transformer</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">positional_encoding</span>(<span class="params">dim, sentence_length, dtype=tf.float32</span>):</span><br><span class="line"></span><br><span class="line">    encoded_vec = np.array([pos/np.power(<span class="number">10000</span>, <span class="number">2</span>*i/dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(sentence_length) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dim)])</span><br><span class="line">    encoded_vec[::<span class="number">2</span>] = np.sin(encoded_vec[::<span class="number">2</span>])</span><br><span class="line">    encoded_vec[<span class="number">1</span>::<span class="number">2</span>] = np.cos(encoded_vec[<span class="number">1</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.convert_to_tensor(encoded_vec.reshape([sentence_length, dim]), dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">              epsilon = <span class="number">1e-8</span>,</span></span><br><span class="line"><span class="params">              scope=<span class="string">&quot;ln&quot;</span>,</span></span><br><span class="line"><span class="params">              reuse=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Applies layer normalization.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A tensor with 2 or more dimensions, where the first dimension has</span></span><br><span class="line"><span class="string">        `batch_size`.</span></span><br><span class="line"><span class="string">      epsilon: A floating number. A very small number for preventing ZeroDivision Error.</span></span><br><span class="line"><span class="string">      scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">      reuse: Boolean, whether to reuse the weights of a previous layer</span></span><br><span class="line"><span class="string">        by the same name.</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A tensor with the same shape and data dtype as `inputs`.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line">        inputs_shape = inputs.get_shape()</span><br><span class="line">        params_shape = inputs_shape[-<span class="number">1</span>:]</span><br><span class="line">    </span><br><span class="line">        mean, variance = tf.nn.moments(inputs, [-<span class="number">1</span>], keep_dims=<span class="literal">True</span>)</span><br><span class="line">        beta= tf.Variable(tf.zeros(params_shape))</span><br><span class="line">        gamma = tf.Variable(tf.ones(params_shape))</span><br><span class="line">        normalized = (inputs - mean) / ( (variance + epsilon) ** (<span class="number">.5</span>) )</span><br><span class="line">        outputs = gamma * normalized + beta</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embedding</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">              vocab_size, </span></span><br><span class="line"><span class="params">              num_units, </span></span><br><span class="line"><span class="params">              zero_pad=<span class="literal">True</span>, </span></span><br><span class="line"><span class="params">              scale=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">              l2_reg=<span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">              scope=<span class="string">&quot;embedding&quot;</span>, </span></span><br><span class="line"><span class="params">              with_t=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">              reuse=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Embeds a given tensor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A `Tensor` with type `int32` or `int64` containing the ids</span></span><br><span class="line"><span class="string">         to be looked up in `lookup table`.</span></span><br><span class="line"><span class="string">      vocab_size: An int. Vocabulary size.</span></span><br><span class="line"><span class="string">      num_units: An int. Number of embedding hidden units.</span></span><br><span class="line"><span class="string">      zero_pad: A boolean. If True, all the values of the fist row (id 0)</span></span><br><span class="line"><span class="string">        should be constant zeros.</span></span><br><span class="line"><span class="string">      scale: A boolean. If True. the outputs is multiplied by sqrt num_units.</span></span><br><span class="line"><span class="string">      scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">      reuse: Boolean, whether to reuse the weights of a previous layer</span></span><br><span class="line"><span class="string">        by the same name.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A `Tensor` with one more rank than inputs&#x27;s. The last dimensionality</span></span><br><span class="line"><span class="string">        should be `num_units`.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    For example,</span></span><br><span class="line"><span class="string">    </span></span><br></pre></td></tr></table></figure><br>import tensorflow as tf<p></p><pre><code>inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))
outputs = embedding(inputs, 6, 2, zero_pad=True)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print sess.run(outputs)
&gt;&gt;
[[[ 0.          0.        ]
  [ 0.09754146  0.67385566]
  [ 0.37864095 -0.35689294]]

 [[-1.01329422 -1.09939694]
  [ 0.7521342   0.38203377]
  [-0.04973143 -0.06210355]]]
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">    </span><br></pre></td></tr></table></figure>
import tensorflow as tf

inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))
outputs = embedding(inputs, 6, 2, zero_pad=False)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print sess.run(outputs)
&gt;&gt;
[[[-0.19172323 -0.39159766]
  [-0.43212751 -0.66207761]
  [ 1.03452027 -0.26704335]]

 [[-0.11634696 -0.35983452]
  [ 0.50208133  0.53509563]
  [ 1.22204471 -0.96587461]]]    
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    with tf.variable_scope<span class="params">(scope, <span class="attr">reuse</span>=reuse)</span>:</span><br><span class="line">        lookup_table = tf.get_variable<span class="params">(&#x27;lookup_table&#x27;,</span></span><br><span class="line"><span class="params">                                       <span class="attr">dtype</span>=tf.float32,</span></span><br><span class="line"><span class="params">                                       <span class="attr">shape</span>=[vocab_size, num_units],</span></span><br><span class="line"><span class="params">                                       #<span class="attr">initializer</span>=tf.contrib.layers.xavier_initializer()</span>,</span><br><span class="line">                                       regularizer=tf.contrib.layers.l2_regularizer<span class="params">(l2_reg)</span>)</span><br><span class="line">        <span class="keyword">if</span> zero_pad:</span><br><span class="line">            lookup_table = tf.concat<span class="params">((tf.zeros(<span class="attr">shape</span>=[1, num_units])</span>,</span><br><span class="line">                                      lookup_table[1:, :]), 0)</span><br><span class="line">        outputs = tf.nn.embedding_lookup<span class="params">(lookup_table, inputs)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> scale:</span><br><span class="line">            outputs = outputs * <span class="params">(num_units ** 0.5)</span> </span><br><span class="line">    <span class="keyword">if</span> with_t: return outputs,lookup_table</span><br><span class="line">    else: return outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def multihead_attention<span class="params">(queries, </span></span><br><span class="line"><span class="params">                        keys, </span></span><br><span class="line"><span class="params">                        <span class="attr">num_units</span>=None, </span></span><br><span class="line"><span class="params">                        <span class="attr">num_heads</span>=8, </span></span><br><span class="line"><span class="params">                        <span class="attr">dropout_rate</span>=0,</span></span><br><span class="line"><span class="params">                        <span class="attr">is_training</span>=True,</span></span><br><span class="line"><span class="params">                        <span class="attr">causality</span>=False,</span></span><br><span class="line"><span class="params">                        <span class="attr">scope</span>=&quot;multihead_attention&quot;, </span></span><br><span class="line"><span class="params">                        <span class="attr">reuse</span>=None,</span></span><br><span class="line"><span class="params">                        <span class="attr">with_qk</span>=False)</span>:</span><br><span class="line">    &#x27;&#x27;&#x27;Applies multihead attention.</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">      queries: A 3d tensor with shape of [N, T_q, C_q].</span><br><span class="line">      keys: A 3d tensor with shape of [N, T_k, C_k].</span><br><span class="line">      num_units: A scalar. Attention size.</span><br><span class="line">      dropout_rate: A floating point number.</span><br><span class="line">      is_training: Boolean. Controller of mechanism for dropout.</span><br><span class="line">      causality: Boolean. If <span class="literal">true</span>, units that reference the future are masked. </span><br><span class="line">      num_heads: An int. Number of heads.</span><br><span class="line">      scope: Optional scope for `variable_scope`.</span><br><span class="line">      reuse: Boolean, whether to reuse the weights of a previous layer</span><br><span class="line">        by the same name.</span><br><span class="line">        </span><br><span class="line">    Returns</span><br><span class="line">      A 3d tensor with shape of <span class="params">(N, T_q, C)</span>  </span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    with tf.variable_scope<span class="params">(scope, <span class="attr">reuse</span>=reuse)</span>:</span><br><span class="line">        <span class="comment"># Set the fall back option for num_units</span></span><br><span class="line">        <span class="keyword">if</span> num_units is None:</span><br><span class="line">            num_units = queries.get_shape<span class="params">()</span><span class="string">.as_list</span>[-1]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Linear projections</span></span><br><span class="line">        <span class="comment"># Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu) # (N, T_q, C)</span></span><br><span class="line">        <span class="comment"># K = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)</span></span><br><span class="line">        <span class="comment"># V = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)</span></span><br><span class="line">        Q = tf.layers.dense<span class="params">(queries, num_units, <span class="attr">activation</span>=None)</span> <span class="comment"># (N, T_q, C)</span></span><br><span class="line">        K = tf.layers.dense<span class="params">(keys, num_units, <span class="attr">activation</span>=None)</span> <span class="comment"># (N, T_k, C)</span></span><br><span class="line">        V = tf.layers.dense<span class="params">(keys, num_units, <span class="attr">activation</span>=None)</span> <span class="comment"># (N, T_k, C)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Split and concat</span></span><br><span class="line">        Q_ = tf.concat<span class="params">(tf.split(Q, num_heads, <span class="attr">axis</span>=2)</span>, axis=0) <span class="comment"># (h*N, T_q, C/h) </span></span><br><span class="line">        K_ = tf.concat<span class="params">(tf.split(K, num_heads, <span class="attr">axis</span>=2)</span>, axis=0) <span class="comment"># (h*N, T_k, C/h) </span></span><br><span class="line">        V_ = tf.concat<span class="params">(tf.split(V, num_heads, <span class="attr">axis</span>=2)</span>, axis=0) <span class="comment"># (h*N, T_k, C/h) </span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Multiplication</span></span><br><span class="line">        outputs = tf.matmul<span class="params">(Q_, tf.transpose(K_, [0, 2, 1])</span>) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Scale</span></span><br><span class="line">        outputs = outputs / <span class="params">(K_.get_shape()</span><span class="string">.as_list</span><span class="params">()</span>[-1] ** 0.5)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Key Masking</span></span><br><span class="line">        key_masks = tf.sign<span class="params">(tf.reduce_sum(tf.abs(keys)</span>, axis=-1)) <span class="comment"># (N, T_k)</span></span><br><span class="line">        key_masks = tf.tile<span class="params">(key_masks, [num_heads, 1])</span> <span class="comment"># (h*N, T_k)</span></span><br><span class="line">        key_masks = tf.tile<span class="params">(tf.expand_dims(key_masks, 1)</span>, [1, tf.shape<span class="params">(queries)</span>[1], 1]) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">        </span><br><span class="line">        paddings = tf.ones_like<span class="params">(outputs)</span>*<span class="params">(-2**32+1)</span></span><br><span class="line">        outputs = tf.where<span class="params">(tf.equal(key_masks, 0)</span>, paddings, outputs) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">      </span><br><span class="line">        <span class="comment"># Causality = Future blinding</span></span><br><span class="line">        <span class="keyword">if</span> causality:</span><br><span class="line">            diag_vals = tf.ones_like<span class="params">(outputs[0, :, :])</span> <span class="comment"># (T_q, T_k)</span></span><br><span class="line">            tril = tf.linalg.LinearOperatorLowerTriangular<span class="params">(diag_vals)</span><span class="string">.to_dense</span><span class="params">()</span> <span class="comment"># (T_q, T_k)</span></span><br><span class="line">            masks = tf.tile<span class="params">(tf.expand_dims(tril, 0)</span>, [tf.shape<span class="params">(outputs)</span>[0], 1, 1]) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">       </span><br><span class="line">            paddings = tf.ones_like<span class="params">(masks)</span>*<span class="params">(-2**32+1)</span></span><br><span class="line">            outputs = tf.where<span class="params">(tf.equal(masks, 0)</span>, paddings, outputs) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">      </span><br><span class="line">        <span class="comment"># Activation</span></span><br><span class="line">        outputs = tf.nn.softmax<span class="params">(outputs)</span> <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">         </span><br><span class="line">        <span class="comment"># Query Masking</span></span><br><span class="line">        query_masks = tf.sign<span class="params">(tf.reduce_sum(tf.abs(queries)</span>, axis=-1)) <span class="comment"># (N, T_q)</span></span><br><span class="line">        query_masks = tf.tile<span class="params">(query_masks, [num_heads, 1])</span> <span class="comment"># (h*N, T_q)</span></span><br><span class="line">        query_masks = tf.tile<span class="params">(tf.expand_dims(query_masks, -1)</span>, [1, 1, tf.shape<span class="params">(keys)</span>[1]]) <span class="comment"># (h*N, T_q, T_k)</span></span><br><span class="line">        outputs *= query_masks <span class="comment"># broadcasting. (N, T_q, C)</span></span><br><span class="line">          </span><br><span class="line">        <span class="comment"># Dropouts</span></span><br><span class="line">        outputs = tf.layers.dropout<span class="params">(outputs, <span class="attr">rate</span>=dropout_rate, <span class="attr">training</span>=tf.convert_to_tensor(is_training)</span>)</span><br><span class="line">               </span><br><span class="line">        <span class="comment"># Weighted sum</span></span><br><span class="line">        outputs = tf.matmul<span class="params">(outputs, V_)</span> <span class="comment"># ( h*N, T_q, C/h)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Restore shape</span></span><br><span class="line">        outputs = tf.concat<span class="params">(tf.split(outputs, num_heads, <span class="attr">axis</span>=0)</span>, axis=2 ) <span class="comment"># (N, T_q, C)</span></span><br><span class="line">              </span><br><span class="line">        <span class="comment"># Residual connection</span></span><br><span class="line">        outputs += queries</span><br><span class="line">              </span><br><span class="line">        <span class="comment"># Normalize</span></span><br><span class="line">        <span class="comment">#outputs = normalize(outputs) # (N, T_q, C)</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> with_qk: return Q,K</span><br><span class="line">    else: return outputs</span><br><span class="line"></span><br><span class="line">def feedforward<span class="params">(inputs, </span></span><br><span class="line"><span class="params">                <span class="attr">num_units</span>=[2048, 512],</span></span><br><span class="line"><span class="params">                <span class="attr">scope</span>=&quot;multihead_attention&quot;, </span></span><br><span class="line"><span class="params">                <span class="attr">dropout_rate</span>=0.2,</span></span><br><span class="line"><span class="params">                <span class="attr">is_training</span>=True,</span></span><br><span class="line"><span class="params">                <span class="attr">reuse</span>=None)</span>:</span><br><span class="line">    &#x27;&#x27;&#x27;Point-wise feed forward net.</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">      inputs: A 3d tensor with shape of [N, T, C].</span><br><span class="line">      num_units: A list of two integers.</span><br><span class="line">      scope: Optional scope for `variable_scope`.</span><br><span class="line">      reuse: Boolean, whether to reuse the weights of a previous layer</span><br><span class="line">        by the same name.</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">      A 3d tensor with the same shape and dtype as inputs</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    with tf.variable_scope<span class="params">(scope, <span class="attr">reuse</span>=reuse)</span>:</span><br><span class="line">        <span class="comment"># Inner layer</span></span><br><span class="line">        params = &#123;<span class="string">&quot;inputs&quot;</span>: inputs, <span class="string">&quot;filters&quot;</span>: num_units[0], <span class="string">&quot;kernel_size&quot;</span>: 1,</span><br><span class="line">                  <span class="string">&quot;activation&quot;</span>: tf.nn.relu, <span class="string">&quot;use_bias&quot;</span>: True&#125;</span><br><span class="line">        outputs = tf.layers.conv1d<span class="params">(**params)</span></span><br><span class="line">        outputs = tf.layers.dropout<span class="params">(outputs, <span class="attr">rate</span>=dropout_rate, <span class="attr">training</span>=tf.convert_to_tensor(is_training)</span>)</span><br><span class="line">        <span class="comment"># Readout layer</span></span><br><span class="line">        params = &#123;<span class="string">&quot;inputs&quot;</span>: outputs, <span class="string">&quot;filters&quot;</span>: num_units[1], <span class="string">&quot;kernel_size&quot;</span>: 1,</span><br><span class="line">                  <span class="string">&quot;activation&quot;</span>: None, <span class="string">&quot;use_bias&quot;</span>: True&#125;</span><br><span class="line">        outputs = tf.layers.conv1d<span class="params">(**params)</span></span><br><span class="line">        outputs = tf.layers.dropout<span class="params">(outputs, <span class="attr">rate</span>=dropout_rate, <span class="attr">training</span>=tf.convert_to_tensor(is_training)</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Residual connection</span></span><br><span class="line">        outputs += inputs</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Normalize</span></span><br><span class="line">        <span class="comment">#outputs = normalize(outputs)</span></span><br><span class="line">    </span><br><span class="line">    return outputs</span><br></pre></td></tr></table></figure>
</code></pre><h3 id="位置编码"><a class="anchor" href="#位置编码">#</a> 位置编码</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">positional_encoding</span>(<span class="params">dim, sentence_length, dtype=tf.float32</span>):</span><br><span class="line">    encoded_vec = np.array([pos/np.power(<span class="number">10000</span>, <span class="number">2</span>*i/dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(sentence_length) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dim)])</span><br><span class="line">    encoded_vec[::<span class="number">2</span>] = np.sin(encoded_vec[::<span class="number">2</span>])</span><br><span class="line">    encoded_vec[<span class="number">1</span>::<span class="number">2</span>] = np.cos(encoded_vec[<span class="number">1</span>::<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> tf.convert_to_tensor(encoded_vec.reshape([sentence_length, dim]), dtype=dtype)</span><br></pre></td></tr></table></figure><p></p><ul><li>定义了名为位置编码的函数， <code>dim</code> 表示向量的维度， <code>sentence_length</code> 表示句子的长度， <code>dtype</code> 表示输出张量的数据类型</li><li><code>encoded_vec</code> 使用嵌套列表解析生成一个 1D 的 numpy 数组 <code>encoded_vec</code> 。<ul><li>外层循环 <code>for pos in range(sentence_length)</code> 遍历句子的每个位置。</li><li>内层循环 <code>for i in range(dim)</code> 遍历编码向量的每个维度。</li><li>计算公式 <code>pos/np.power(10000, 2*i/dim)</code> 生成位置编码值。</li></ul></li><li><code>encoded_vec[::2] = np.sin(encoded_vec[::2])</code> : 这一行将编码向量中偶数索引位置的值替换为它们的正弦值，即 <code>encoded_vec</code> 的每隔两个元素（从索引 0 开始）的值。</li><li><code>encoded_vec[1::2] = np.cos(encoded_vec[1::2])</code> : 这一行将编码向量中奇数索引位置的值替换为它们的余弦值，即 <code>encoded_vec</code> 的每隔两个元素（从索引 1 开始）的值。</li><li><code>return</code> : 行将 <code>encoded_vec</code> 重新调整为形状 <code>[sentence_length, dim]</code> ，即将其从 1D 数组重塑为 2D 数组。</li></ul><h3 id="层归一化-2"><a class="anchor" href="#层归一化-2">#</a> 层归一化</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">              epsilon=<span class="number">1e-8</span>,</span></span><br><span class="line"><span class="params">              scope=<span class="string">&quot;ln&quot;</span>,</span></span><br><span class="line"><span class="params">              reuse=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line">        inputs_shape = inputs.get_shape()</span><br><span class="line">        params_shape = inputs_shape[-<span class="number">1</span>:]</span><br><span class="line">        mean, variance = tf.nn.moments(inputs, [-<span class="number">1</span>], keep_dims=<span class="literal">True</span>)</span><br><span class="line">        beta = tf.Variable(tf.zeros(params_shape))</span><br><span class="line">        gamma = tf.Variable(tf.ones(params_shape))</span><br><span class="line">        normalized = (inputs - mean) / ((variance + epsilon) ** <span class="number">0.5</span>)</span><br><span class="line">        outputs = gamma * normalized + beta</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><p></p><h4 id="函数作用域"><a class="anchor" href="#函数作用域">#</a> 函数作用域</h4><ul><li><code>inputs</code> : 输入张量</li><li><code>epsilon</code> : 一个小常数，用于避免除以零的情况，默认值为 <code>1e-8</code> 。</li><li><code>scope</code> : 变量作用域的名称，默认值为 <code>&quot;ln&quot;</code> 。</li><li><code>reuse</code> : 是否重用变量，默认值为 <code>None</code> 。</li></ul><h4 id="变量作用域"><a class="anchor" href="#变量作用域">#</a> 变量作用域</h4><ul><li><code>scope</code> : 变量作用域的名称。</li><li><code>reuse</code> : 是否重用现有的变量。</li></ul><h4 id="获取输入张量的形状"><a class="anchor" href="#获取输入张量的形状">#</a> 获取输入张量的形状</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputs_shape = inputs.get_shape()</span><br><span class="line">params_shape = inputs_shape[-<span class="number">1</span>:]</span><br></pre></td></tr></table></figure><p></p><ul><li><code>inputs_shape</code> : 获取输入张量的形状。</li><li><code>params_shape</code> : 获取最后一个维度的形状，这将用于归一化参数 <code>beta</code> 和 <code>gamma</code> 的形状。</li></ul><h4 id="计算均值和方差"><a class="anchor" href="#计算均值和方差">#</a> 计算均值和方差</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mean, variance = tf.nn.moments(inputs, [-<span class="number">1</span>], keep_dims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li><code>tf.nn.moments(inputs, [-1], keep_dims=True)</code> : 计算输入张量在最后一个维度上的均值和方差，并保持原始维度的形状。</li></ul><h4 id="定义变量"><a class="anchor" href="#定义变量">#</a> 定义变量</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beta = tf.Variable(tf.zeros(params_shape))</span><br><span class="line">gamma = tf.Variable(tf.ones(params_shape))</span><br></pre></td></tr></table></figure><p></p><ul><li><code>beta</code> : 偏移量变量，初始化为零，形状为 <code>params_shape</code> 。</li><li><code>gamma</code> : 缩放量变量，初始化为一，形状为 <code>params_shape</code> 。</li></ul><h4 id="归一化"><a class="anchor" href="#归一化">#</a> 归一化</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normalized = (inputs - mean) / ((variance + epsilon) ** <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li>输入张量减去均值</li><li>然后除以标准差，添加 espsilon 是避免除以零</li></ul><h4 id="应用缩放和偏移"><a class="anchor" href="#应用缩放和偏移">#</a> 应用缩放和偏移</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = gamma * normalized + beta</span><br></pre></td></tr></table></figure><p></p><ul><li><code>gamma * normalized</code> : 对归一化后的张量进行缩放。</li><li><code>gamma * normalized + beta</code> : 对归一化并缩放后的张量进行偏移。</li></ul><ul><li>返回应用了层归一化后的输出张量 <code>outputs</code> 。</li></ul><h3 id="嵌入层-2"><a class="anchor" href="#嵌入层-2">#</a> 嵌入层</h3><p><strong>作用</strong>：将输入的词 ID 映射到对应的嵌入向量。通过嵌入表查找，生成词嵌入矩阵，可以选择是否将 ID 为 0 的词嵌入设为 0，且可以对嵌入进行缩放。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embedding</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">              vocab_size, </span></span><br><span class="line"><span class="params">              num_units, </span></span><br><span class="line"><span class="params">              zero_pad=<span class="literal">True</span>, </span></span><br><span class="line"><span class="params">              scale=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">              l2_reg=<span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">              scope=<span class="string">&quot;embedding&quot;</span>, </span></span><br><span class="line"><span class="params">              with_t=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">              reuse=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line">        lookup_table = tf.get_variable(<span class="string">&#x27;lookup_table&#x27;</span>,</span><br><span class="line">                                       dtype=tf.float32,</span><br><span class="line">                                       shape=[vocab_size, num_units],</span><br><span class="line">                                       regularizer=tf.contrib.layers.l2_regularizer(l2_reg))</span><br><span class="line">        <span class="keyword">if</span> zero_pad:</span><br><span class="line">            lookup_table = tf.concat((tf.zeros(shape=[<span class="number">1</span>, num_units]),</span><br><span class="line">                                      lookup_table[<span class="number">1</span>:, :]), <span class="number">0</span>)</span><br><span class="line">        outputs = tf.nn.embedding_lookup(lookup_table, inputs)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> scale:</span><br><span class="line">            outputs = outputs * (num_units ** <span class="number">0.5</span>) </span><br><span class="line">    <span class="keyword">if</span> with_t: <span class="keyword">return</span> outputs, lookup_table</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><p></p><h4 id="定义函数"><a class="anchor" href="#定义函数">#</a> 定义函数</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embedding</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">              vocab_size, </span></span><br><span class="line"><span class="params">              num_units, </span></span><br><span class="line"><span class="params">              zero_pad=<span class="literal">True</span>, </span></span><br><span class="line"><span class="params">              scale=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">              l2_reg=<span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">              scope=<span class="string">&quot;embedding&quot;</span>, </span></span><br><span class="line"><span class="params">              with_t=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">              reuse=<span class="literal">None</span></span>):</span><br></pre></td></tr></table></figure><p></p><ul><li><code>inputs</code> : 输入张量，通常是词汇的索引。</li><li><code>vocab_size</code> : 词汇表的大小，即词汇的数量。</li><li><code>num_units</code> : 嵌入向量的维度，即每个词汇映射后的向量表示的长度。</li><li><code>zero_pad</code> : 是否将索引为 0 的位置填充为零向量，默认为 <code>True</code> 。</li><li><code>scale</code> : 是否对嵌入向量进行缩放，默认为 <code>True</code> 。</li><li><code>l2_reg</code> : L2 正则化的参数，默认为 <code>0.0</code> 。</li><li><code>scope</code> : 变量作用域的名称，默认为 <code>&quot;embedding&quot;</code> 。</li><li><code>with_t</code> : 是否返回嵌入矩阵，默认为 <code>False</code> 。</li><li><code>reuse</code> : 是否重用变量，默认为 <code>None</code> 。</li></ul><h4 id="变量作用域-2"><a class="anchor" href="#变量作用域-2">#</a> 变量作用域</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br></pre></td></tr></table></figure><p></p><ul><li><code>scope</code> : 变量作用域的名称。</li><li><code>reuse</code> : 是否重用现有的变量。</li></ul><h4 id="创建嵌入矩阵"><a class="anchor" href="#创建嵌入矩阵">#</a> 创建嵌入矩阵</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lookup_table = tf.get_variable(<span class="string">&#x27;lookup_table&#x27;</span>,</span><br><span class="line">                               dtype=tf.float32,</span><br><span class="line">                               shape=[vocab_size, num_units],</span><br><span class="line">                               regularizer=tf.contrib.layers.l2_regularizer(l2_reg))</span><br></pre></td></tr></table></figure><p></p><ul><li><code>lookup_table</code> : 创建嵌入矩阵变量，形状为 <code>[vocab_size, num_units]</code> 。意味着你有 <code>vocab_size</code> 个单词，每个单词都被表示为一个 <code>num_units</code> 维的向量。</li><li><code>dtype=tf.float32</code> : 数据类型为浮点数。</li><li><code>regularizer=tf.contrib.layers.l2_regularizer(l2_reg)</code> : 使用 L2 正则化。</li></ul><h4 id="填充零向量"><a class="anchor" href="#填充零向量">#</a> 填充零向量</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> zero_pad:</span><br><span class="line">    lookup_table = tf.concat((tf.zeros(shape=[<span class="number">1</span>, num_units]),</span><br><span class="line">                              lookup_table[<span class="number">1</span>:, :]), <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li><code>tf.zeros(shape=[1, num_units])</code> : 创建一个零向量，形状为 <code>[1, num_units]</code> 。</li><li><code>tf.concat((tf.zeros(shape=[1, num_units]), lookup_table[1:, :]), 0)</code> : 将零向量与嵌入矩阵的其余部分连接起来，从而使索引为 0 的位置填充为零向量。</li></ul><h4 id="查找嵌入矩阵"><a class="anchor" href="#查找嵌入矩阵">#</a> 查找嵌入矩阵</h4><p></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">outputs</span> = tf.nn.embedding_lookup(lookup_table, inputs)</span><br></pre></td></tr></table></figure><p></p><ul><li><code>tf.nn.embedding_lookup(lookup_table, inputs)</code> : 根据输入张量 <code>inputs</code> 中的索引查找嵌入矩阵 <code>lookup_table</code> 中的向量表示，并返回这些表示。</li></ul><h4 id="对嵌入向量进行缩放"><a class="anchor" href="#对嵌入向量进行缩放">#</a> 对嵌入向量进行缩放</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> scale:</span><br><span class="line">    outputs = outputs * (num_units ** <span class="number">0.5</span>) </span><br></pre></td></tr></table></figure><p></p><ul><li><code>outputs = outputs * (num_units ** 0.5)</code> : 如果 <code>scale</code> 为 <code>True</code> ，则对嵌入向量进行缩放，缩放因子为 <code>num_units</code> 的平方根。</li></ul><h3 id="多头注意力机制-multihead_attention"><a class="anchor" href="#多头注意力机制-multihead_attention">#</a> 多头注意力机制 <code>multihead_attention</code></h3><p><strong>作用</strong>：实现多头自注意力机制。将查询、键和值线性变换为多头形式，计算注意力权重并应用于值，通过多个头并行计算来捕捉不同的注意力模式，最后将输出拼接并添加残差连接.</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multihead_attention</span>(<span class="params">queries, </span></span><br><span class="line"><span class="params">                        keys, </span></span><br><span class="line"><span class="params">                        num_units=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                        num_heads=<span class="number">8</span>, </span></span><br><span class="line"><span class="params">                        dropout_rate=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                        is_training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                        causality=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                        scope=<span class="string">&quot;multihead_attention&quot;</span>, </span></span><br><span class="line"><span class="params">                        reuse=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                        with_qk=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line">        <span class="keyword">if</span> num_units <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            num_units = queries.get_shape().as_list[-<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        Q = tf.layers.dense(queries, num_units, activation=<span class="literal">None</span>)</span><br><span class="line">        K = tf.layers.dense(keys, num_units, activation=<span class="literal">None</span>)</span><br><span class="line">        V = tf.layers.dense(keys, num_units, activation=<span class="literal">None</span>)</span><br><span class="line">        </span><br><span class="line">        Q_ = tf.concat(tf.split(Q, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br><span class="line">        K_ = tf.concat(tf.split(K, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br><span class="line">        V_ = tf.concat(tf.split(V, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        outputs = tf.matmul(Q_, tf.transpose(K_, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]))</span><br><span class="line">        outputs = outputs / (K_.get_shape().as_list()[-<span class="number">1</span>] ** <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        key_masks = tf.sign(tf.reduce_sum(tf.<span class="built_in">abs</span>(keys), axis=-<span class="number">1</span>))</span><br><span class="line">        key_masks = tf.tile(key_masks, [num_heads, <span class="number">1</span>])</span><br><span class="line">        key_masks = tf.tile(tf.expand_dims(key_masks, <span class="number">1</span>), [<span class="number">1</span>, tf.shape(queries)[<span class="number">1</span>], <span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        paddings = tf.ones_like(outputs) * (-<span class="number">2</span>**<span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line">        outputs = tf.where(tf.equal(key_masks, <span class="number">0</span>), paddings, outputs)</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> causality:</span><br><span class="line">            diag_vals = tf.ones_like(outputs[<span class="number">0</span>, :, :])</span><br><span class="line">            tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()</span><br><span class="line">            masks = tf.tile(tf.expand_dims(tril, <span class="number">0</span>), [tf.shape(outputs)[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">            paddings = tf.ones_like(masks) * (-<span class="number">2</span>**<span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line">            outputs = tf.where(tf.equal(masks, <span class="number">0</span>), paddings, outputs)</span><br><span class="line">  </span><br><span class="line">        outputs = tf.nn.softmax(outputs)</span><br><span class="line">         </span><br><span class="line">        query_masks = tf.sign(tf.reduce_sum(tf.<span class="built_in">abs</span>(queries), axis=-<span class="number">1</span>))</span><br><span class="line">        query_masks = tf.tile(query_masks, [num_heads, <span class="number">1</span>])</span><br><span class="line">        query_masks = tf.tile(tf.expand_dims(query_masks, -<span class="number">1</span>), [<span class="number">1</span>, <span class="number">1</span>, tf.shape(keys)[<span class="number">1</span>]])</span><br><span class="line">        outputs *= query_masks</span><br><span class="line">          </span><br><span class="line">        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))</span><br><span class="line">        outputs = tf.matmul(outputs, V_)</span><br><span class="line">        outputs = tf.concat(tf.split(outputs, num_heads, axis=<span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">        outputs += queries</span><br><span class="line">    <span class="keyword">if</span> with_qk: <span class="keyword">return</span> Q, K</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><p></p><h4 id="函数定义"><a class="anchor" href="#函数定义">#</a> 函数定义</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multihead_attention</span>(<span class="params">queries, </span></span><br><span class="line"><span class="params">                        keys, </span></span><br><span class="line"><span class="params">                        num_units=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                        num_heads=<span class="number">8</span>, </span></span><br><span class="line"><span class="params">                        dropout_rate=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                        is_training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                        causality=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                        scope=<span class="string">&quot;multihead_attention&quot;</span>, </span></span><br><span class="line"><span class="params">                        reuse=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                        with_qk=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure><p></p><ul><li><code>queries</code> : 查询张量。</li><li><code>keys</code> : 键张量。</li><li><code>num_units</code> : 注意力机制的维度，默认为 <code>None</code> 。</li><li><code>num_heads</code> : 注意力头的数量，默认为 <code>8</code> 。</li><li><code>dropout_rate</code> : Dropout 的概率，默认为 <code>0</code> 。</li><li><code>is_training</code> : 是否在训练模式，默认为 <code>True</code> 。</li><li><code>causality</code> : 是否应用因果掩码，默认为 <code>False</code> 。</li><li><code>scope</code> : 变量作用域的名称，默认为 <code>&quot;multihead_attention&quot;</code> 。</li><li><code>reuse</code> : 是否重用变量，默认为 <code>None</code> 。</li><li><code>with_qk</code> : 是否返回 <code>Q</code> 和 <code>K</code> 矩阵，默认为 <code>False</code> 。</li></ul><h4 id="变量作用域设置num_units"><a class="anchor" href="#变量作用域设置num_units">#</a> 变量作用域，设置 <code>num_units</code></h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br></pre></td></tr></table></figure><p></p><ul><li>如果 <code>num_units</code> 为 <code>None</code> ，则将其设置为查询张量的最后一个维度。</li></ul><h4 id="线性变换"><a class="anchor" href="#线性变换">#</a> 线性变换</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Q = tf.layers.dense(queries, num_units, activation=<span class="literal">None</span>)</span><br><span class="line">K = tf.layers.dense(keys, num_units, activation=<span class="literal">None</span>)</span><br><span class="line">V = tf.layers.dense(keys, num_units, activation=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li>对 <code>queries</code> 、 <code>keys</code> 和 <code>values</code> 进行线性变换，得到 <code>Q</code> 、 <code>K</code> 和 <code>V</code> 矩阵。</li></ul><h4 id="拆分和拼接"><a class="anchor" href="#拆分和拼接">#</a> 拆分和拼接</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Q_ = tf.concat(tf.split(Q, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br><span class="line">K_ = tf.concat(tf.split(K, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br><span class="line">V_ = tf.concat(tf.split(V, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p></p><p><strong><code>tf.split(Q, num_heads, axis=2)</code> </strong>：</p><ul><li>将 <code>Q</code> 矩阵沿着 <code>axis=2</code> 维度切分成 <code>num_heads</code> 个子矩阵。</li><li>假设 <code>Q</code> 的形状为 <code>[batch_size, sequence_length, num_units]</code> ，那么切分后的每个子矩阵的形状为 <code>[batch_size, sequence_length, num_units / num_heads]</code> 。</li></ul><p><strong><code>tf.concat(..., axis=0)</code> </strong>：</p><ul><li>将上述切分得到的子矩阵在 <code>axis=0</code> 维度上拼接起来。</li><li>假设有 <code>num_heads</code> 个子矩阵，每个子矩阵的形状为 <code>[batch_size, sequence_length, num_units / num_heads]</code> ，那么拼接后的矩阵形状为 <code>[batch_size * num_heads, sequence_length, num_units / num_heads]</code> 。</li></ul><h4 id="计算注意力分数"><a class="anchor" href="#计算注意力分数">#</a> 计算注意力分数</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.matmul(Q_, tf.transpose(K_, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]))</span><br><span class="line">outputs = outputs / (K_.get_shape().as_list()[-<span class="number">1</span>] ** <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li><p><code>Q_</code> ：形状为 <code>[batch_size * num_heads, sequence_length, num_units / num_heads]</code> 的查询矩阵。</p><p><code>K_</code> ：形状为 <code>[batch_size * num_heads, sequence_length, num_units / num_heads]</code> 的键矩阵。</p></li><li><p>首先对 <code>K_</code> 进行转置， <code>tf.transpose(K_, [0, 2, 1])</code></p></li><li><p>然后使用 <code>matmul</code> 对矩阵进行点积</p></li><li><p>然后缩放点积注意力 <code>K_.get_shape().as_list()[-1]</code> ：得到 <code>K_</code> 最后一个维度的大小，即 <code>num_units / num_heads</code> 。</p></li><li><p><code>(K_.get_shape().as_list()[-1] ** 0.5)</code> ：计算其平方根。</p></li><li><p>将 <code>outputs</code> 除以这个平方根，缩放点积的结果：</p></li></ul><h4 id="检验码"><a class="anchor" href="#检验码">#</a> 检验码</h4><p>这段代码的目的是通过对 <code>outputs</code> （即点积注意力得分矩阵）进行掩码（masking）操作，以确保在计算注意力时，填充的位置（padding positions）不会对结果产生影响。让我们逐步分析每一行代码：</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">key_masks = tf.sign(tf.reduce_sum(tf.<span class="built_in">abs</span>(keys), axis=-<span class="number">1</span>))</span><br><span class="line">key_masks = tf.tile(key_masks, [num_heads, <span class="number">1</span>])</span><br><span class="line">key_masks = tf.tile(tf.expand_dims(key_masks, <span class="number">1</span>), [<span class="number">1</span>, tf.shape(queries)[<span class="number">1</span>], <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">paddings = tf.ones_like(outputs) * (-<span class="number">2</span>**<span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line">outputs = tf.where(tf.equal(key_masks, <span class="number">0</span>), paddings, outputs)</span><br></pre></td></tr></table></figure><p></p><ul><li><p><code>tf.abs(keys)</code> ：对 <code>keys</code> 的所有元素取绝对值。</p></li><li><p><code>tf.reduce_sum(tf.abs(keys), axis=-1)</code> ：对 <code>keys</code> 的最后一个维度（即特征维度）求和，结果是一个形状为 <code>[batch_size, sequence_length]</code> 的张量。</p></li><li><p><code>tf.sign(...)</code> ：对求和结果进行符号函数操作，非零值变为 1，零值保持为 0。这用于标记填充值（padding positions）。</p></li><li><p><code>tf.tile(key_masks, [num_heads, 1])</code> ：复制 <code>key_masks</code> ，在第一个维度上复制 <code>num_heads</code> 次，以适应多头注意力的情况。结果形状为 <code>[batch_size * num_heads, sequence_length]</code> 。</p></li><li><p><code>tf.expand_dims(key_masks, 1)</code> ：在 <code>key_masks</code> 的第一个维度添加一个新的维度，结果形状为 <code>[batch_size * num_heads, 1, sequence_length]</code> 。</p><p><code>tf.tile(..., [1, tf.shape(queries)[1], 1])</code> ：在新添加的维度上复制 <code>tf.shape(queries)[1]</code> 次，结果形状为 <code>[batch_size * num_heads, sequence_length, sequence_length]</code> 。</p></li><li><p><code>tf.ones_like(outputs)</code> ：创建一个与 <code>outputs</code> 形状相同的全 1 张量。</p><p><code>* (-2**32 + 1)</code> ：将全 1 张量的所有值乘以一个非常小的负数（近似于负无穷），这个值将用来替换填充位置的注意力得分，使这些位置的注意力得分在 softmax 计算时接近于 0。</p></li><li><p><code>tf.equal(key_masks, 0)</code> ：生成一个布尔张量，指示哪些位置是填充位置（ <code>key_masks</code> 为 0 的位置）。</p><p><code>tf.where(...)</code> ：根据布尔张量选择对应位置的值，如果为真，则选择 <code>paddings</code> 中的值，否则选择 <code>outputs</code> 中的值。这样，填充位置的注意力得分将被设置为一个非常小的负数。</p></li></ul><h4 id="因果掩码"><a class="anchor" href="#因果掩码">#</a> 因果掩码</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> causality:</span><br><span class="line">    diag_vals = tf.ones_like(outputs[<span class="number">0</span>, :, :])</span><br><span class="line">    tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()</span><br><span class="line">    masks = tf.tile(tf.expand_dims(tril, <span class="number">0</span>), [tf.shape(outputs)[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    paddings = tf.ones_like(masks) * (-<span class="number">2</span>**<span class="number">32</span> + <span class="number">1</span>)</span><br><span class="line">    outputs = tf.where(tf.equal(masks, <span class="number">0</span>), paddings, outputs)</span><br></pre></td></tr></table></figure><p></p><p>如果 <code>causality</code> 为 <code>True</code> ，则应用因果掩码，以确保当前时间步之后的信息不会被访问。</p><p>创建下三角矩阵 <code>tril</code> 作为掩码，并将无效位置的分数设置为一个非常小的值（负无穷大）。</p><h4 id="计算注意力权重"><a class="anchor" href="#计算注意力权重">#</a> 计算注意力权重</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.nn.softmax(outputs)</span><br></pre></td></tr></table></figure><p></p><ul><li>对注意力分数应用 Softmax 函数，得到注意力权重。</li></ul><h4 id="查询掩码"><a class="anchor" href="#查询掩码">#</a> 查询掩码</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">query_masks = tf.sign(tf.reduce_sum(tf.<span class="built_in">abs</span>(queries), axis=-<span class="number">1</span>))</span><br><span class="line">query_masks = tf.tile(query_masks, [num_heads, <span class="number">1</span>])</span><br><span class="line">query_masks = tf.tile(tf.expand_dims(query_masks, -<span class="number">1</span>), [<span class="number">1</span>, <span class="number">1</span>, tf.shape(keys)[<span class="number">1</span>]])</span><br><span class="line">outputs *= query_masks</span><br></pre></td></tr></table></figure><p></p><p>计算 <code>query_masks</code> ，用于掩码无效的查询。</p><p>对 <code>query_masks</code> 进行扩展和重复，使其适应多头注意力的形状。</p><p>将无效位置的权重设置为零。</p><h4 id="dropout"><a class="anchor" href="#dropout">#</a> Dropout</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))</span><br></pre></td></tr></table></figure><p></p><ul><li>对注意力权重应用 Dropout，以防止过拟合。</li></ul><h4 id="加权求和"><a class="anchor" href="#加权求和">#</a> 加权求和</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.matmul(outputs, V_)</span><br></pre></td></tr></table></figure><p></p><ul><li>使用注意力权重对 <code>V</code> 进行加权求和，得到最终的输出。</li></ul><h4 id="拼接和残差连接"><a class="anchor" href="#拼接和残差连接">#</a> 拼接和残差连接</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.concat(tf.split(outputs, num_heads, axis=<span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">outputs += queries</span><br></pre></td></tr></table></figure><p></p><h4 id="返回结果"><a class="anchor" href="#返回结果">#</a> 返回结果</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> with_qk: <span class="keyword">return</span> Q, K</span><br><span class="line"><span class="keyword">else</span>: <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><p></p><h3 id="前馈神经网络-feedforward"><a class="anchor" href="#前馈神经网络-feedforward">#</a> 前馈神经网络 <code>feedforward</code></h3><h4 id="函数定义-2"><a class="anchor" href="#函数定义-2">#</a> 函数定义</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">feedforward</span>(<span class="params">inputs, </span></span><br><span class="line"><span class="params">                num_units=[<span class="number">2048</span>, <span class="number">512</span>],</span></span><br><span class="line"><span class="params">                scope=<span class="string">&quot;multihead_attention&quot;</span>, </span></span><br><span class="line"><span class="params">                dropout_rate=<span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                is_training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                reuse=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure><p></p><ul><li><code>inputs</code> : 输入张量。</li><li><code>num_units</code> : 列表，包含两个整数，分别表示第一个和第二个卷积层的输出维度，默认为 <code>[2048, 512]</code> 。</li><li><code>scope</code> : 变量作用域的名称，默认为 <code>&quot;multihead_attention&quot;</code> 。</li><li><code>dropout_rate</code> : Dropout 的概率，默认为 <code>0.2</code> 。</li><li><code>is_training</code> : 是否在训练模式，默认为 <code>True</code> 。</li><li><code>reuse</code> : 是否重用变量，默认为 <code>None</code> 。</li></ul><h4 id="变量作用域-3"><a class="anchor" href="#变量作用域-3">#</a> 变量作用域</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br></pre></td></tr></table></figure><p></p><h4 id="第一个卷积层"><a class="anchor" href="#第一个卷积层">#</a> 第一个卷积层</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&quot;inputs&quot;</span>: inputs, <span class="string">&quot;filters&quot;</span>: num_units[<span class="number">0</span>], <span class="string">&quot;kernel_size&quot;</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="string">&quot;activation&quot;</span>: tf.nn.relu, <span class="string">&quot;use_bias&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">outputs = tf.layers.conv1d(**params)</span><br></pre></td></tr></table></figure><p></p><p><code>params</code> : 一个包含第一个卷积层参数的字典。</p><ul><li><code>inputs</code> : 输入张量。</li><li><code>filters</code> : 卷积层的输出维度，为 <code>num_units[0]</code> （2048）。</li><li><code>kernel_size</code> : 卷积核的大小，设置为 <code>1</code> ，相当于全连接层。</li><li><code>activation</code> : 激活函数，使用 ReLU。</li><li><code>use_bias</code> : 是否使用偏置，设置为 <code>True</code> 。</li></ul><p><code>outputs = tf.layers.conv1d(**params)</code> : 应用 1D 卷积层。</p><h4 id="第一次dropout"><a class="anchor" href="#第一次dropout">#</a> 第一次 Dropout</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))</span><br></pre></td></tr></table></figure><p></p><ul><li>对第一个卷积层的输出应用 Dropout，以防止过拟合。</li><li><code>rate=dropout_rate</code> : Dropout 的概率。</li><li><code>training=tf.convert_to_tensor(is_training)</code> : 是否在训练模式。</li></ul><h4 id="第二个卷积层"><a class="anchor" href="#第二个卷积层">#</a> 第二个卷积层</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&quot;inputs&quot;</span>: outputs, <span class="string">&quot;filters&quot;</span>: num_units[<span class="number">1</span>], <span class="string">&quot;kernel_size&quot;</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="string">&quot;activation&quot;</span>: <span class="literal">None</span>, <span class="string">&quot;use_bias&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">outputs = tf.layers.conv1d(**params)</span><br></pre></td></tr></table></figure><p></p><ul><li><code>params</code> : 一个包含第二个卷积层参数的字典。<ul><li><code>inputs</code> : 第一个卷积层的输出。</li><li><code>filters</code> : 卷积层的输出维度，为 <code>num_units[1]</code> （512）。</li><li><code>kernel_size</code> : 卷积核的大小，设置为 <code>1</code> ，相当于全连接层。</li><li><code>activation</code> : 激活函数，设置为 <code>None</code> （线性激活）。</li><li><code>use_bias</code> : 是否使用偏置，设置为 <code>True</code> 。</li></ul></li><li><code>outputs = tf.layers.conv1d(**params)</code> : 应用第二个 1D 卷积层。</li></ul><h4 id="第二次dropout"><a class="anchor" href="#第二次dropout">#</a> 第二次 Dropout</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))</span><br></pre></td></tr></table></figure><p></p><ul><li>对第二个卷积层的输出应用 Dropout，以防止过拟合。</li><li><code>rate=dropout_rate</code> : Dropout 的概率。</li><li><code>training=tf.convert_to_tensor(is_training)</code> : 是否在训练模式。</li></ul><h4 id="残差连接"><a class="anchor" href="#残差连接">#</a> 残差连接</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs += inputs</span><br></pre></td></tr></table></figure><p></p><ul><li>将原始的输入张量 <code>inputs</code> 加到当前的输出张量上，进行残差连接。这有助于缓解梯度消失问题，并允许梯度在深层网络中更好地传播。</li></ul><h4 id="返回结果-2"><a class="anchor" href="#返回结果-2">#</a> 返回结果</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><p></p><ul><li>返回最终的输出张量 <code>outputs</code> 。</li></ul><p>这个函数实现了一个两层的前馈神经网络，每层之间应用 Dropout，并使用残差连接将输入直接添加到输出。这种结构在 Transformer 模型中非常常见，用于在每个时间步上独立地应用前馈神经网络，从而增强模型的表示能力。</p><p>Dropout 是一种用于防止神经网络过拟合的正则化技术。其核心思想是在每个训练步骤中随机地 “丢弃” 一部分神经元，即暂时忽略它们，并将它们的输出设置为零。这种做法强制神经网络在每次迭代中以不同的方式学习，从而降低对特定神经元或特定路径的依赖性，提高模型的泛化能力。</p><h2 id="modelpy"><a class="anchor" href="#modelpy">#</a> <span class="exturl" data-url="aHR0cDovL21vZGVsLnB5">model.py</span></h2><p>这个代码实现了一个基于自注意力机制的推荐系统模型，主要包括以下几个部分：</p><ol><li><strong>初始化方法</strong>：定义各种占位符和掩码。</li><li><strong>嵌入层</strong>：将输入序列嵌入到高维空间。</li><li><strong>位置编码</strong>：为每个位置添加位置编码。</li><li><strong>Dropout</strong>：对嵌入序列进行 dropout。</li><li><strong>自注意力机制块</strong>：使用多头自注意力机制和前馈神经网络对序列进行建模。</li><li><strong>归一化</strong>：对序列进行归一化处理。</li><li><strong>正负样本嵌入和预测得分</strong>：计算正负样本的嵌入和预测得分。</li><li><strong>损失函数</strong>：计算二元交叉熵损失和正则化损失。</li><li><strong>AUC 和优化器</strong>：定义 AUC 指标和优化器。</li><li><strong>预测函数</strong>：定义用于预测的函数。</li></ol><p>这些部分共同构建了一个推荐系统模型，</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modules <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, usernum, itemnum, args, reuse=<span class="literal">None</span></span>):</span><br><span class="line">        self.is_training = tf.placeholder(tf.<span class="built_in">bool</span>, shape=())</span><br><span class="line">        self.u = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>))</span><br><span class="line">        self.input_seq = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">        self.pos = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">        self.neg = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">        pos = self.pos</span><br><span class="line">        neg = self.neg</span><br><span class="line">        mask = tf.expand_dims(tf.to_float(tf.not_equal(self.input_seq, <span class="number">0</span>)), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;SASRec&quot;</span>, reuse=reuse):</span><br><span class="line">            <span class="comment"># sequence embedding, item embedding table</span></span><br><span class="line">            self.seq, item_emb_table = embedding(self.input_seq,</span><br><span class="line">                                                 vocab_size=itemnum + <span class="number">1</span>,</span><br><span class="line">                                                 num_units=args.hidden_units,</span><br><span class="line">                                                 zero_pad=<span class="literal">True</span>,</span><br><span class="line">                                                 scale=<span class="literal">True</span>,</span><br><span class="line">                                                 l2_reg=args.l2_emb,</span><br><span class="line">                                                 scope=<span class="string">&quot;input_embeddings&quot;</span>,</span><br><span class="line">                                                 with_t=<span class="literal">True</span>,</span><br><span class="line">                                                 reuse=reuse</span><br><span class="line">                                                 )</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Positional Encoding</span></span><br><span class="line">            t, pos_emb_table = embedding(</span><br><span class="line">                tf.tile(tf.expand_dims(tf.<span class="built_in">range</span>(tf.shape(self.input_seq)[<span class="number">1</span>]), <span class="number">0</span>), [tf.shape(self.input_seq)[<span class="number">0</span>], <span class="number">1</span>]),</span><br><span class="line">                vocab_size=args.maxlen,</span><br><span class="line">                num_units=args.hidden_units,</span><br><span class="line">                zero_pad=<span class="literal">False</span>,</span><br><span class="line">                scale=<span class="literal">False</span>,</span><br><span class="line">                l2_reg=args.l2_emb,</span><br><span class="line">                scope=<span class="string">&quot;dec_pos&quot;</span>,</span><br><span class="line">                reuse=reuse,</span><br><span class="line">                with_t=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">            self.seq += t</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Dropout</span></span><br><span class="line">            self.seq = tf.layers.dropout(self.seq,</span><br><span class="line">                                         rate=args.dropout_rate,</span><br><span class="line">                                         training=tf.convert_to_tensor(self.is_training))</span><br><span class="line">            self.seq *= mask</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Build blocks</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.num_blocks):</span><br><span class="line">                <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_blocks_%d&quot;</span> % i):</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Self-attention</span></span><br><span class="line">                    self.seq = multihead_attention(queries=normalize(self.seq),</span><br><span class="line">                                                   keys=self.seq,</span><br><span class="line">                                                   num_units=args.hidden_units,</span><br><span class="line">                                                   num_heads=args.num_heads,</span><br><span class="line">                                                   dropout_rate=args.dropout_rate,</span><br><span class="line">                                                   is_training=self.is_training,</span><br><span class="line">                                                   causality=<span class="literal">True</span>,</span><br><span class="line">                                                   scope=<span class="string">&quot;self_attention&quot;</span>)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Feed forward</span></span><br><span class="line">                    self.seq = feedforward(normalize(self.seq), num_units=[args.hidden_units, args.hidden_units],</span><br><span class="line">                                           dropout_rate=args.dropout_rate, is_training=self.is_training)</span><br><span class="line">                    self.seq *= mask</span><br><span class="line"></span><br><span class="line">            self.seq = normalize(self.seq)</span><br><span class="line"></span><br><span class="line">        pos = tf.reshape(pos, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">        neg = tf.reshape(neg, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">        pos_emb = tf.nn.embedding_lookup(item_emb_table, pos)</span><br><span class="line">        neg_emb = tf.nn.embedding_lookup(item_emb_table, neg)</span><br><span class="line">        seq_emb = tf.reshape(self.seq, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen, args.hidden_units])</span><br><span class="line"></span><br><span class="line">        self.test_item = tf.placeholder(tf.int32, shape=(<span class="number">101</span>))</span><br><span class="line">        test_item_emb = tf.nn.embedding_lookup(item_emb_table, self.test_item)</span><br><span class="line">        self.test_logits = tf.matmul(seq_emb, tf.transpose(test_item_emb))</span><br><span class="line">        self.test_logits = tf.reshape(self.test_logits, [tf.shape(self.input_seq)[<span class="number">0</span>], args.maxlen, <span class="number">101</span>])</span><br><span class="line">        self.test_logits = self.test_logits[:, -<span class="number">1</span>, :]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># prediction layer</span></span><br><span class="line">        self.pos_logits = tf.reduce_sum(pos_emb * seq_emb, -<span class="number">1</span>)</span><br><span class="line">        self.neg_logits = tf.reduce_sum(neg_emb * seq_emb, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ignore padding items (0)</span></span><br><span class="line">        istarget = tf.reshape(tf.to_float(tf.not_equal(pos, <span class="number">0</span>)), [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">        self.loss = tf.reduce_sum(</span><br><span class="line">            - tf.log(tf.sigmoid(self.pos_logits) + <span class="number">1e-24</span>) * istarget -</span><br><span class="line">            tf.log(<span class="number">1</span> - tf.sigmoid(self.neg_logits) + <span class="number">1e-24</span>) * istarget</span><br><span class="line">        ) / tf.reduce_sum(istarget)</span><br><span class="line">        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</span><br><span class="line">        self.loss += <span class="built_in">sum</span>(reg_losses)</span><br><span class="line"></span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;loss&#x27;</span>, self.loss)</span><br><span class="line">        self.auc = tf.reduce_sum(</span><br><span class="line">            ((tf.sign(self.pos_logits - self.neg_logits) + <span class="number">1</span>) / <span class="number">2</span>) * istarget</span><br><span class="line">        ) / tf.reduce_sum(istarget)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> reuse <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            tf.summary.scalar(<span class="string">&#x27;auc&#x27;</span>, self.auc)</span><br><span class="line">            self.global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">&#x27;global_step&#x27;</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">            self.optimizer = tf.train.AdamOptimizer(learning_rate=args.lr, beta2=<span class="number">0.98</span>)</span><br><span class="line">            self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tf.summary.scalar(<span class="string">&#x27;test_auc&#x27;</span>, self.auc)</span><br><span class="line"></span><br><span class="line">        self.merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, sess, u, seq, item_idx</span>):</span><br><span class="line">        <span class="keyword">return</span> sess.run(self.test_logits,</span><br><span class="line">                        &#123;self.u: u, self.input_seq: seq, self.test_item: item_idx, self.is_training: <span class="literal">False</span>&#125;)</span><br></pre></td></tr></table></figure><p></p><h3 id="初始化方法-__init__"><a class="anchor" href="#初始化方法-__init__">#</a> 初始化方法 <code>__init__</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, usernum, itemnum, args, reuse=<span class="literal">None</span></span>):</span><br><span class="line">    self.is_training = tf.placeholder(tf.<span class="built_in">bool</span>, shape=())</span><br><span class="line">    self.u = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>))</span><br><span class="line">    self.input_seq = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">    self.pos = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">    self.neg = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, args.maxlen))</span><br><span class="line">    pos = self.pos</span><br><span class="line">    neg = self.neg</span><br><span class="line">    mask = tf.expand_dims(tf.to_float(tf.not_equal(self.input_seq, <span class="number">0</span>)), -<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li>作用：定义一些占位符，用于接收输入数据。<ul><li><code>self.is_training</code> ：一个布尔型占位符，用于指示是否在训练模式。</li><li><code>self.u</code> ：用户 ID 占位符。</li><li><code>self.input_seq</code> ：输入序列的占位符。</li><li><code>self.pos</code> 和 <code>self.neg</code> ：正样本和负样本的占位符。</li><li><code>mask</code> ：掩码，用于掩盖输入序列中的填充值（0）。</li></ul></li></ul><h3 id="变量域-sasrec-和嵌入层"><a class="anchor" href="#变量域-sasrec-和嵌入层">#</a> 变量域 &quot;SASRec&quot; 和嵌入层</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;SASRec&quot;</span>, reuse=reuse):</span><br><span class="line">    <span class="comment"># sequence embedding, item embedding table</span></span><br><span class="line">    self.seq, item_emb_table = embedding(self.input_seq,</span><br><span class="line">                                         vocab_size=itemnum + <span class="number">1</span>,</span><br><span class="line">                                         num_units=args.hidden_units,</span><br><span class="line">                                         zero_pad=<span class="literal">True</span>,</span><br><span class="line">                                         scale=<span class="literal">True</span>,</span><br><span class="line">                                         l2_reg=args.l2_emb,</span><br><span class="line">                                         scope=<span class="string">&quot;input_embeddings&quot;</span>,</span><br><span class="line">                                         with_t=<span class="literal">True</span>,</span><br><span class="line">                                         reuse=reuse</span><br><span class="line">                                         )</span><br></pre></td></tr></table></figure><p></p><ul><li>作用：将输入序列进行嵌入，生成嵌入矩阵和项目嵌入表。<ul><li><code>embedding</code> 函数：实现输入序列的嵌入，返回嵌入后的序列和嵌入表。</li></ul></li></ul><h3 id="位置编码-2"><a class="anchor" href="#位置编码-2">#</a> 位置编码</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">t, pos_emb_table = embedding(</span><br><span class="line">    tf.tile(tf.expand_dims(tf.<span class="built_in">range</span>(tf.shape(self.input_seq)[<span class="number">1</span>]), <span class="number">0</span>), [tf.shape(self.input_seq)[<span class="number">0</span>], <span class="number">1</span>]),</span><br><span class="line">    vocab_size=args.maxlen,</span><br><span class="line">    num_units=args.hidden_units,</span><br><span class="line">    zero_pad=<span class="literal">False</span>,</span><br><span class="line">    scale=<span class="literal">False</span>,</span><br><span class="line">    l2_reg=args.l2_emb,</span><br><span class="line">    scope=<span class="string">&quot;dec_pos&quot;</span>,</span><br><span class="line">    reuse=reuse,</span><br><span class="line">    with_t=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">self.seq += t</span><br></pre></td></tr></table></figure><p></p><ul><li>作用：对序列进行位置编码，添加位置信息到序列嵌入中。<ul><li><code>embedding</code> 函数：实现位置编码的嵌入，返回位置编码向量和位置嵌入表。</li></ul></li></ul><h3 id="dropout-2"><a class="anchor" href="#dropout-2">#</a> Dropout</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.seq = tf.layers.dropout(self.seq,</span><br><span class="line">                             rate=args.dropout_rate,</span><br><span class="line">                             training=tf.convert_to_tensor(self.is_training))</span><br><span class="line">self.seq *= mask</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：对序列嵌入进行 dropout 操作，并应用掩码。</li></ul><h3 id="构建自注意力机制的块"><a class="anchor" href="#构建自注意力机制的块">#</a> 构建自注意力机制的块</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.num_blocks):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_blocks_%d&quot;</span> % i):</span><br><span class="line">        <span class="comment"># Self-attention</span></span><br><span class="line">        self.seq = multihead_attention(queries=normalize(self.seq),</span><br><span class="line">                                       keys=self.seq,</span><br><span class="line">                                       num_units=args.hidden_units,</span><br><span class="line">                                       num_heads=args.num_heads,</span><br><span class="line">                                       dropout_rate=args.dropout_rate,</span><br><span class="line">                                       is_training=self.is_training,</span><br><span class="line">                                       causality=<span class="literal">True</span>,</span><br><span class="line">                                       scope=<span class="string">&quot;self_attention&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Feed forward</span></span><br><span class="line">        self.seq = feedforward(normalize(self.seq), num_units=[args.hidden_units, args.hidden_units],</span><br><span class="line">                               dropout_rate=args.dropout_rate, is_training=self.is_training)</span><br><span class="line">        self.seq *= mask</span><br></pre></td></tr></table></figure><p></p><ul><li>作用：构建多个自注意力机制块，每个块包括自注意力层和前馈神经网络层。<ul><li><code>multihead_attention</code> 函数：实现多头自注意力机制。</li><li><code>feedforward</code> 函数：实现前馈神经网络层。</li></ul></li></ul><h3 id="归一化-2"><a class="anchor" href="#归一化-2">#</a> 归一化</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.seq = normalize(self.seq)</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：对序列进行归一化处理。</li></ul><h3 id="计算正负样本的嵌入和预测得分"><a class="anchor" href="#计算正负样本的嵌入和预测得分">#</a> 计算正负样本的嵌入和预测得分</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pos = tf.reshape(pos, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">neg = tf.reshape(neg, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">pos_emb = tf.nn.embedding_lookup(item_emb_table, pos)</span><br><span class="line">neg_emb = tf.nn.embedding_lookup(item_emb_table, neg)</span><br><span class="line">seq_emb = tf.reshape(self.seq, [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen, args.hidden_units])</span><br><span class="line"></span><br><span class="line">self.test_item = tf.placeholder(tf.int32, shape=(<span class="number">101</span>))</span><br><span class="line">test_item_emb = tf.nn.embedding_lookup(item_emb_table, self.test_item)</span><br><span class="line">self.test_logits = tf.matmul(seq_emb, tf.transpose(test_item_emb))</span><br><span class="line">self.test_logits = tf.reshape(self.test_logits, [tf.shape(self.input_seq)[<span class="number">0</span>], args.maxlen, <span class="number">101</span>])</span><br><span class="line">self.test_logits = self.test_logits[:, -<span class="number">1</span>, :]</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：计算正样本和负样本的嵌入，并通过矩阵乘法得到预测得分。</li></ul><h3 id="损失函数"><a class="anchor" href="#损失函数">#</a> 损失函数</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">self.pos_logits = tf.reduce_sum(pos_emb * seq_emb, -<span class="number">1</span>)</span><br><span class="line">self.neg_logits = tf.reduce_sum(neg_emb * seq_emb, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">istarget = tf.reshape(tf.to_float(tf.not_equal(pos, <span class="number">0</span>)), [tf.shape(self.input_seq)[<span class="number">0</span>] * args.maxlen])</span><br><span class="line">self.loss = tf.reduce_sum(</span><br><span class="line">    - tf.log(tf.sigmoid(self.pos_logits) + <span class="number">1e-24</span>) * istarget -</span><br><span class="line">    tf.log(<span class="number">1</span> - tf.sigmoid(self.neg_logits) + <span class="number">1e-24</span>) * istarget</span><br><span class="line">) / tf.reduce_sum(istarget)</span><br><span class="line">reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</span><br><span class="line">self.loss += <span class="built_in">sum</span>(reg_losses)</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：计算模型的损失函数，包含正负样本的二元交叉熵损失和正则化损失。</li></ul><h3 id="auc和优化器"><a class="anchor" href="#auc和优化器">#</a> AUC 和优化器</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.scalar(<span class="string">&#x27;loss&#x27;</span>, self.loss)</span><br><span class="line">self.auc = tf.reduce_sum(</span><br><span class="line">    ((tf.sign(self.pos_logits - self.neg_logits) + <span class="number">1</span>) / <span class="number">2</span>) * istarget</span><br><span class="line">) / tf.reduce_sum(istarget)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> reuse <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;auc&#x27;</span>, self.auc)</span><br><span class="line">    self.global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">&#x27;global_step&#x27;</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">    self.optimizer = tf.train.AdamOptimizer(learning_rate=args.lr, beta2=<span class="number">0.98</span>)</span><br><span class="line">    self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;test_auc&#x27;</span>, self.auc)</span><br><span class="line"></span><br><span class="line">self.merged = tf.summary.merge_all()</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：定义 AUC 指标和优化器，如果 reuse 为 None 则初始化训练操作，否则记录测试 AUC。</li></ul><h3 id="预测函数-predict"><a class="anchor" href="#预测函数-predict">#</a> 预测函数 <code>predict</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, sess, u, seq, item_idx</span>):</span><br><span class="line">    <span class="keyword">return</span> sess.run(self.test_logits,</span><br><span class="line">                    &#123;self.u: u, self.input_seq: seq, self.test_item: item_idx, self.is_training: <span class="literal">False</span>&#125;)</span><br></pre></td></tr></table></figure><p></p><ul><li><strong>作用</strong>：定义预测函数，接收会话、用户 ID、输入序列和项目索引，返回预测得分。</li></ul><h2 id="utilpy"><a class="anchor" href="#utilpy">#</a> <span class="exturl" data-url="aHR0cDovL3V0aWwucHk=">util.py</span></h2><p>这个代码包含了数据分割函数和模型评估函数，具体解析如下：</p><ol><li><strong>数据分割函数 <code>data_partition</code> </strong>：读取用户 - 物品交互数据，分割成训练集、验证集和测试集，并计算用户数和物品数。</li><li><strong>模型评估函数 <code>evaluate</code> </strong>：在测试集上评估模型表现，计算 NDCG 和 HT。</li><li><strong>模型评估函数（验证集） <code>evaluate_valid</code> </strong>：在验证集上评估模型表现，计算 NDCG 和 HT。</li></ol><p>这些功能共同构成了一个基本的推荐系统数据处理和评估框架。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_partition</span>(<span class="params">fname</span>):</span><br><span class="line">    usernum = <span class="number">0</span></span><br><span class="line">    itemnum = <span class="number">0</span></span><br><span class="line">    User = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    user_train = &#123;&#125;</span><br><span class="line">    user_valid = &#123;&#125;</span><br><span class="line">    user_test = &#123;&#125;</span><br><span class="line">    <span class="comment"># assume user/item index starting from 1</span></span><br><span class="line">    f = <span class="built_in">open</span>(<span class="string">&#x27;data/%s.txt&#x27;</span> % fname, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        u, i = line.rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        u = <span class="built_in">int</span>(u)</span><br><span class="line">        i = <span class="built_in">int</span>(i)</span><br><span class="line">        usernum = <span class="built_in">max</span>(u, usernum)</span><br><span class="line">        itemnum = <span class="built_in">max</span>(i, itemnum)</span><br><span class="line">        User[u].append(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> User:</span><br><span class="line">        nfeedback = <span class="built_in">len</span>(User[user])</span><br><span class="line">        <span class="keyword">if</span> nfeedback &lt; <span class="number">3</span>:</span><br><span class="line">            user_train[user] = User[user]</span><br><span class="line">            user_valid[user] = []</span><br><span class="line">            user_test[user] = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            user_train[user] = User[user][:-<span class="number">2</span>]</span><br><span class="line">            user_valid[user] = []</span><br><span class="line">            user_valid[user].append(User[user][-<span class="number">2</span>])</span><br><span class="line">            user_test[user] = []</span><br><span class="line">            user_test[user].append(User[user][-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> [user_train, user_valid, user_test, usernum, itemnum]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, dataset, args, sess</span>):</span><br><span class="line">    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)</span><br><span class="line"></span><br><span class="line">    NDCG = <span class="number">0.0</span></span><br><span class="line">    HT = <span class="number">0.0</span></span><br><span class="line">    valid_user = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> usernum&gt;<span class="number">10000</span>:</span><br><span class="line">        users = random.sample(xrange(<span class="number">1</span>, usernum + <span class="number">1</span>), <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        users = xrange(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(train[u]) &lt; <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">len</span>(test[u]) &lt; <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seq = np.zeros([args.maxlen], dtype=np.int32)</span><br><span class="line">        idx = args.maxlen - <span class="number">1</span></span><br><span class="line">        seq[idx] = valid[u][<span class="number">0</span>]</span><br><span class="line">        idx -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(train[u]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">        rated = <span class="built_in">set</span>(train[u])</span><br><span class="line">        rated.add(<span class="number">0</span>)</span><br><span class="line">        item_idx = [test[u][<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">while</span> t <span class="keyword">in</span> rated: t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            item_idx.append(t)</span><br><span class="line"></span><br><span class="line">        predictions = -model.predict(sess, [u], [seq], item_idx)</span><br><span class="line">        predictions = predictions[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        rank = predictions.argsort().argsort()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        valid_user += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rank &lt; <span class="number">10</span>:</span><br><span class="line">            NDCG += <span class="number">1</span> / np.log2(rank + <span class="number">2</span>)</span><br><span class="line">            HT += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> valid_user % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;.&#x27;</span>,</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> NDCG / valid_user, HT / valid_user</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_valid</span>(<span class="params">model, dataset, args, sess</span>):</span><br><span class="line">    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)</span><br><span class="line"></span><br><span class="line">    NDCG = <span class="number">0.0</span></span><br><span class="line">    valid_user = <span class="number">0.0</span></span><br><span class="line">    HT = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">if</span> usernum&gt;<span class="number">10000</span>:</span><br><span class="line">        users = random.sample(xrange(<span class="number">1</span>, usernum + <span class="number">1</span>), <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        users = xrange(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(train[u]) &lt; <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">len</span>(valid[u]) &lt; <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seq = np.zeros([args.maxlen], dtype=np.int32)</span><br><span class="line">        idx = args.maxlen - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(train[u]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        rated = <span class="built_in">set</span>(train[u])</span><br><span class="line">        rated.add(<span class="number">0</span>)</span><br><span class="line">        item_idx = [valid[u][<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">while</span> t <span class="keyword">in</span> rated: t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            item_idx.append(t)</span><br><span class="line"></span><br><span class="line">        predictions = -model.predict(sess, [u], [seq], item_idx)</span><br><span class="line">        predictions = predictions[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        rank = predictions.argsort().argsort()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        valid_user += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rank &lt; <span class="number">10</span>:</span><br><span class="line">            NDCG += <span class="number">1</span> / np.log2(rank + <span class="number">2</span>)</span><br><span class="line">            HT += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> valid_user % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;.&#x27;</span>,</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> NDCG / valid_user, HT / valid_user</span><br></pre></td></tr></table></figure><p></p><h3 id="导入模块"><a class="anchor" href="#导入模块">#</a> 导入模块</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：导入所需的模块，包括系统模块、深拷贝模块、随机数模块、数值计算模块和默认字典模块。</p><h3 id="数据分割函数-data_partition"><a class="anchor" href="#数据分割函数-data_partition">#</a> 数据分割函数 <code>data_partition</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_partition</span>(<span class="params">fname</span>):</span><br><span class="line">    usernum = <span class="number">0</span></span><br><span class="line">    itemnum = <span class="number">0</span></span><br><span class="line">    User = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    user_train = &#123;&#125;</span><br><span class="line">    user_valid = &#123;&#125;</span><br><span class="line">    user_test = &#123;&#125;</span><br><span class="line">    <span class="comment"># assume user/item index starting from 1</span></span><br><span class="line">    f = <span class="built_in">open</span>(<span class="string">&#x27;data/%s.txt&#x27;</span> % fname, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        u, i = line.rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        u = <span class="built_in">int</span>(u)</span><br><span class="line">        i = <span class="built_in">int</span>(i)</span><br><span class="line">        usernum = <span class="built_in">max</span>(u, usernum)</span><br><span class="line">        itemnum = <span class="built_in">max</span>(i, itemnum)</span><br><span class="line">        User[u].append(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> User:</span><br><span class="line">        nfeedback = <span class="built_in">len</span>(User[user])</span><br><span class="line">        <span class="keyword">if</span> nfeedback &lt; <span class="number">3</span>:</span><br><span class="line">            user_train[user] = User[user]</span><br><span class="line">            user_valid[user] = []</span><br><span class="line">            user_test[user] = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            user_train[user] = User[user][:-<span class="number">2</span>]</span><br><span class="line">            user_valid[user] = []</span><br><span class="line">            user_valid[user].append(User[user][-<span class="number">2</span>])</span><br><span class="line">            user_test[user] = []</span><br><span class="line">            user_test[user].append(User[user][-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> [user_train, user_valid, user_test, usernum, itemnum]</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：将数据分成训练集、验证集和测试集，并计算用户数和物品数。</p><ul><li><code>usernum</code> 和 <code>itemnum</code> 初始化为 0，用于记录最大用户 ID 和最大物品 ID。</li><li><code>User</code> ：使用默认字典，记录每个用户的交互物品列表。</li><li><code>user_train</code> 、 <code>user_valid</code> 和 <code>user_test</code> ：分别用于存储每个用户的训练集、验证集和测试集。</li><li>打开文件，读取每一行数据，将用户 ID 和物品 ID 存入 <code>User</code> 字典，并更新 <code>usernum</code> 和 <code>itemnum</code> 。</li><li>对每个用户，根据交互的物品数量进行数据分割：<ul><li>如果交互物品数小于 3，全部放入训练集。</li><li>否则，最后两个物品分别放入验证集和测试集，剩余的放入训练集。</li></ul></li></ul><h3 id="模型评估函数-evaluate"><a class="anchor" href="#模型评估函数-evaluate">#</a> 模型评估函数 <code>evaluate</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, dataset, args, sess</span>):</span><br><span class="line">    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)</span><br><span class="line"></span><br><span class="line">    NDCG = <span class="number">0.0</span></span><br><span class="line">    HT = <span class="number">0.0</span></span><br><span class="line">    valid_user = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> usernum &gt; <span class="number">10000</span>:</span><br><span class="line">        users = random.sample(<span class="built_in">range</span>(<span class="number">1</span>, usernum + <span class="number">1</span>), <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        users = <span class="built_in">range</span>(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(train[u]) &lt; <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">len</span>(test[u]) &lt; <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seq = np.zeros([args.maxlen], dtype=np.int32)</span><br><span class="line">        idx = args.maxlen - <span class="number">1</span></span><br><span class="line">        seq[idx] = valid[u][<span class="number">0</span>]</span><br><span class="line">        idx -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(train[u]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">        rated = <span class="built_in">set</span>(train[u])</span><br><span class="line">        rated.add(<span class="number">0</span>)</span><br><span class="line">        item_idx = [test[u][<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">while</span> t <span class="keyword">in</span> rated: t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            item_idx.append(t)</span><br><span class="line"></span><br><span class="line">        predictions = -model.predict(sess, [u], [seq], item_idx)</span><br><span class="line">        predictions = predictions[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        rank = predictions.argsort().argsort()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        valid_user += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rank &lt; <span class="number">10</span>:</span><br><span class="line">            NDCG += <span class="number">1</span> / np.log2(rank + <span class="number">2</span>)</span><br><span class="line">            HT += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> valid_user % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;.&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> NDCG / valid_user, HT / valid_user</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：评估模型在测试集上的表现，计算 NDCG（归一化折损累积增益）和 HT（命中率）。</p><ul><li>深拷贝数据集，以免修改原始数据。</li><li>初始化 NDCG、HT 和有效用户数。</li><li>随机抽样 10000 个用户进行评估，如果用户总数大于 10000，否则评估所有用户。</li><li>对每个用户，构建输入序列 <code>seq</code> ，包括训练数据和验证数据。</li><li>生成负样本，将其与测试样本一起组成 <code>item_idx</code> 。</li><li>通过模型预测，计算预测得分 <code>predictions</code> ，并对预测结果排序。</li><li>计算排名，更新 NDCG 和 HT，打印进度。</li></ul><h3 id="模型评估函数验证集evaluate_valid"><a class="anchor" href="#模型评估函数验证集evaluate_valid">#</a> 模型评估函数（验证集） <code>evaluate_valid</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_valid</span>(<span class="params">model, dataset, args, sess</span>):</span><br><span class="line">    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)</span><br><span class="line"></span><br><span class="line">    NDCG = <span class="number">0.0</span></span><br><span class="line">    valid_user = <span class="number">0.0</span></span><br><span class="line">    HT = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">if</span> usernum &gt; <span class="number">10000</span>:</span><br><span class="line">        users = random.sample(<span class="built_in">range</span>(<span class="number">1</span>, usernum + <span class="number">1</span>), <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        users = <span class="built_in">range</span>(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(train[u]) &lt; <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">len</span>(valid[u]) &lt; <span class="number">1</span>: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        seq = np.zeros([args.maxlen], dtype=np.int32)</span><br><span class="line">        idx = args.maxlen - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(train[u]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        rated = <span class="built_in">set</span>(train[u])</span><br><span class="line">        rated.add(<span class="number">0</span>)</span><br><span class="line">        item_idx = [valid[u][<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">while</span> t <span class="keyword">in</span> rated: t = np.random.randint(<span class="number">1</span>, itemnum + <span class="number">1</span>)</span><br><span class="line">            item_idx.append(t)</span><br><span class="line"></span><br><span class="line">        predictions = -model.predict(sess, [u], [seq], item_idx)</span><br><span class="line">        predictions = predictions[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        rank = predictions.argsort().argsort()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        valid_user += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rank &lt; <span class="number">10</span>:</span><br><span class="line">            NDCG += <span class="number">1</span> / np.log2(rank + <span class="number">2</span>)</span><br><span class="line">            HT += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> valid_user % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;.&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> NDCG / valid_user, HT / valid_user</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：评估模型在验证集上的表现，计算 NDCG 和 HT。</p><ul><li>代码与 <code>evaluate</code> 类似，不同之处在于这里使用验证集 <code>valid</code> 进行评估，而不是测试集 <code>test</code> 。</li></ul><h2 id="samplerpy"><a class="anchor" href="#samplerpy">#</a> <span class="exturl" data-url="aHR0cDovL3NhbXBsZXIucHk=">sampler.py</span></h2><p>这个代码实现了一个多进程的数据采样器，具体解析如下：</p><ol><li><strong><code>random_neq</code> 函数</strong>：生成不在集合中的随机整数。</li><li><strong><code>sample_function</code> 函数</strong>：在多进程环境下进行数据采样，并将结果放入队列中。</li><li><strong><code>WarpSampler</code> 类</strong>：管理多个数据采样进程，提供获取批量数据的方法。</li></ol><p>这些功能共同构成了一个高效的多进程数据采样器，用于推荐系统中的序列化数据采样。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_neq</span>(<span class="params">l, r, s</span>):</span><br><span class="line">    t = np.random.randint(l, r)</span><br><span class="line">    <span class="keyword">while</span> t <span class="keyword">in</span> s:</span><br><span class="line">        t = np.random.randint(l, r)</span><br><span class="line">    <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_function</span>(<span class="params">user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>():</span><br><span class="line"></span><br><span class="line">        user = np.random.randint(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(user_train[user]) &lt;= <span class="number">1</span>: user = np.random.randint(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        seq = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        pos = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        neg = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        nxt = user_train[user][-<span class="number">1</span>]</span><br><span class="line">        idx = maxlen - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        ts = <span class="built_in">set</span>(user_train[user])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(user_train[user][:-<span class="number">1</span>]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            pos[idx] = nxt</span><br><span class="line">            <span class="keyword">if</span> nxt != <span class="number">0</span>: neg[idx] = random_neq(<span class="number">1</span>, itemnum + <span class="number">1</span>, ts)</span><br><span class="line">            nxt = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (user, seq, pos, neg)</span><br><span class="line"></span><br><span class="line">    np.random.seed(SEED)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        one_batch = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            one_batch.append(sample())</span><br><span class="line"></span><br><span class="line">        result_queue.put(<span class="built_in">zip</span>(*one_batch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WarpSampler</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, User, usernum, itemnum, batch_size=<span class="number">64</span>, maxlen=<span class="number">10</span>, n_workers=<span class="number">1</span></span>):</span><br><span class="line">        self.result_queue = Queue(maxsize=n_workers * <span class="number">10</span>)</span><br><span class="line">        self.processors = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_workers):</span><br><span class="line">            self.processors.append(</span><br><span class="line">                Process(target=sample_function, args=(User,</span><br><span class="line">                                                      usernum,</span><br><span class="line">                                                      itemnum,</span><br><span class="line">                                                      batch_size,</span><br><span class="line">                                                      maxlen,</span><br><span class="line">                                                      self.result_queue,</span><br><span class="line">                                                      np.random.randint(<span class="number">2e9</span>)</span><br><span class="line">                                                      )))</span><br><span class="line">            self.processors[-<span class="number">1</span>].daemon = <span class="literal">True</span></span><br><span class="line">            self.processors[-<span class="number">1</span>].start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_batch</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.result_queue.get()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.processors:</span><br><span class="line">            p.terminate()</span><br><span class="line">            p.join()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h3 id="导入模块-2"><a class="anchor" href="#导入模块-2">#</a> 导入模块</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：导入所需的模块，包括数值计算模块和多进程处理模块。</p><h3 id="随机负样本生成函数-random_neq"><a class="anchor" href="#随机负样本生成函数-random_neq">#</a> 随机负样本生成函数 <code>random_neq</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_neq</span>(<span class="params">l, r, s</span>):</span><br><span class="line">    t = np.random.randint(l, r)</span><br><span class="line">    <span class="keyword">while</span> t <span class="keyword">in</span> s:</span><br><span class="line">        t = np.random.randint(l, r)</span><br><span class="line">    <span class="keyword">return</span> t</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：在区间 <code>[l, r)</code> 内随机生成一个不在集合 <code>s</code> 中的整数。</p><ul><li><code>np.random.randint(l, r)</code> ：生成区间 <code>[l, r)</code> 内的随机整数。</li><li>如果生成的整数 <code>t</code> 在集合 <code>s</code> 中，则重新生成，直到 <code>t</code> 不在集合 <code>s</code> 中为止。</li></ul><h3 id="数据采样函数-sample_function"><a class="anchor" href="#数据采样函数-sample_function">#</a> 数据采样函数 <code>sample_function</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_function</span>(<span class="params">user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>():</span><br><span class="line">        user = np.random.randint(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(user_train[user]) &lt;= <span class="number">1</span>: user = np.random.randint(<span class="number">1</span>, usernum + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        seq = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        pos = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        neg = np.zeros([maxlen], dtype=np.int32)</span><br><span class="line">        nxt = user_train[user][-<span class="number">1</span>]</span><br><span class="line">        idx = maxlen - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        ts = <span class="built_in">set</span>(user_train[user])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(user_train[user][:-<span class="number">1</span>]):</span><br><span class="line">            seq[idx] = i</span><br><span class="line">            pos[idx] = nxt</span><br><span class="line">            <span class="keyword">if</span> nxt != <span class="number">0</span>: neg[idx] = random_neq(<span class="number">1</span>, itemnum + <span class="number">1</span>, ts)</span><br><span class="line">            nxt = i</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx == -<span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (user, seq, pos, neg)</span><br><span class="line"></span><br><span class="line">    np.random.seed(SEED)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        one_batch = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            one_batch.append(sample())</span><br><span class="line"></span><br><span class="line">        result_queue.put(<span class="built_in">zip</span>(*one_batch))</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：在多进程环境下进行数据采样，并将结果放入队列中。</p><ul><li><strong>内部函数 <code>sample</code> </strong>：<ul><li>随机选择一个有交互记录的用户。</li><li>初始化序列 <code>seq</code> 、正样本 <code>pos</code> 和负样本 <code>neg</code> 。</li><li>从用户的交互记录中构建序列和正负样本。</li><li>使用 <code>random_neq</code> 函数生成负样本。</li><li>返回一个包含用户 ID、序列、正样本和负样本的元组。</li></ul></li><li><strong><code>np.random.seed(SEED)</code> </strong>：设置随机种子，以保证多进程中的随机性。</li><li><strong>无限循环</strong>：不断生成批量数据。<ul><li><strong><code>one_batch.append(sample())</code> </strong>：生成一个批量数据，并添加到 <code>one_batch</code> 列表中。</li><li><strong><code>result_queue.put(zip(\*one_batch))</code> </strong>：将批量数据打包并放入结果队列中。</li></ul></li></ul><h3 id="warpsampler-类"><a class="anchor" href="#warpsampler-类">#</a> <code>WarpSampler</code> 类</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WarpSampler</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, User, usernum, itemnum, batch_size=<span class="number">64</span>, maxlen=<span class="number">10</span>, n_workers=<span class="number">1</span></span>):</span><br><span class="line">        self.result_queue = Queue(maxsize=n_workers * <span class="number">10</span>)</span><br><span class="line">        self.processors = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_workers):</span><br><span class="line">            self.processors.append(</span><br><span class="line">                Process(target=sample_function, args=(User,</span><br><span class="line">                                                      usernum,</span><br><span class="line">                                                      itemnum,</span><br><span class="line">                                                      batch_size,</span><br><span class="line">                                                      maxlen,</span><br><span class="line">                                                      self.result_queue,</span><br><span class="line">                                                      np.random.randint(<span class="number">2e9</span>)</span><br><span class="line">                                                      )))</span><br><span class="line">            self.processors[-<span class="number">1</span>].daemon = <span class="literal">True</span></span><br><span class="line">            self.processors[-<span class="number">1</span>].start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_batch</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.result_queue.get()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.processors:</span><br><span class="line">            p.terminate()</span><br><span class="line">            p.join()</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：管理多个数据采样进程，并提供获取批量数据的方法。</p><ul><li><p><strong>初始化方法 <code>__init__</code> </strong>：</p><ul><li><p><strong><code>self.result_queue</code> </strong>：创建一个结果队列，用于存储采样结果。</p></li><li><p><strong><code>self.processors</code> </strong>：初始化一个空列表，用于存储采样进程。</p></li><li><p>循环创建进程</p><p>：</p><ul><li>创建 <code>Process</code> 对象，目标函数为 <code>sample_function</code> ，传入所需参数。</li><li>将进程设为守护进程。</li><li>启动进程并添加到 <code>self.processors</code> 列表中。</li></ul></li></ul></li><li><p><strong><code>next_batch</code> 方法</strong>：</p><ul><li><strong><code>self.result_queue.get()</code> </strong>：从结果队列中获取一个批量数据。</li></ul></li><li><p><strong><code>close</code> 方法</strong>：</p><ul><li><p>循环终止进程</p><p>：</p><ul><li><strong><code>p.terminate()</code> </strong>：终止进程。</li><li><strong><code>p.join()</code> </strong>：等待进程终止。</li></ul></li></ul></li></ul><h2 id="mainpy"><a class="anchor" href="#mainpy">#</a> <span class="exturl" data-url="aHR0cDovL21haW4ucHk=">main.py</span></h2><p>这个代码实现了一个基于 TensorFlow 的推荐系统的训练流程，具体解析如下：</p><ol><li><strong>导入模块</strong>：导入必要的库和模块。</li><li><strong>参数解析</strong>：定义并解析命令行参数。</li><li><strong>创建训练目录</strong>：检查并创建训练目录，保存解析的参数。</li><li><strong>数据分割</strong>：调用数据分割函数获取训练集、验证集和测试集。</li><li><strong>TensorFlow 会话配置</strong>：配置 TensorFlow 会话。</li><li><strong>数据采样器和模型初始化</strong>：初始化数据采样器和模型，并初始化所有变量。</li><li><strong>训练过程</strong>：训练模型并定期评估模型性能。</li><li><strong>异常处理和资源清理</strong>：确保在异常发生或正常结束时关闭采样器和日志文件。</li></ol><p>这些步骤共同构成了一个完整的推荐系统训练流程。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sampler <span class="keyword">import</span> WarpSampler</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str2bool</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">if</span> s <span class="keyword">not</span> <span class="keyword">in</span> &#123;<span class="string">&#x27;False&#x27;</span>, <span class="string">&#x27;True&#x27;</span>&#125;:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Not a valid boolean string&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s == <span class="string">&#x27;True&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train_dir&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">128</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, default=<span class="number">0.001</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--maxlen&#x27;</span>, default=<span class="number">50</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--hidden_units&#x27;</span>, default=<span class="number">50</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_blocks&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_epochs&#x27;</span>, default=<span class="number">201</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_heads&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dropout_rate&#x27;</span>, default=<span class="number">0.5</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--l2_emb&#x27;</span>, default=<span class="number">0.0</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir):</span><br><span class="line">    os.makedirs(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir, <span class="string">&#x27;args.txt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;\n&#x27;</span>.join([<span class="built_in">str</span>(k) + <span class="string">&#x27;,&#x27;</span> + <span class="built_in">str</span>(v) <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(<span class="built_in">vars</span>(args).items(), key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])]))</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">dataset = data_partition(args.dataset)</span><br><span class="line">[user_train, user_valid, user_test, usernum, itemnum] = dataset</span><br><span class="line">num_batch = <span class="built_in">len</span>(user_train) / args.batch_size</span><br><span class="line">cc = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> u <span class="keyword">in</span> user_train:</span><br><span class="line">    cc += <span class="built_in">len</span>(user_train[u])</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;average sequence length: %.2f&#x27;</span> % (cc / <span class="built_in">len</span>(user_train))</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(os.path.join(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir, <span class="string">&#x27;log.txt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">config.allow_soft_placement = <span class="literal">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br><span class="line"></span><br><span class="line">sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=<span class="number">3</span>)</span><br><span class="line">model = Model(usernum, itemnum, args)</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"></span><br><span class="line">T = <span class="number">0.0</span></span><br><span class="line">t0 = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.num_epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(num_batch), total=num_batch, ncols=<span class="number">70</span>, leave=<span class="literal">False</span>, unit=<span class="string">&#x27;b&#x27;</span>):</span><br><span class="line">            u, seq, pos, neg = sampler.next_batch()</span><br><span class="line">            auc, loss, _ = sess.run([model.auc, model.loss, model.train_op],</span><br><span class="line">                                    &#123;model.u: u, model.input_seq: seq, model.pos: pos, model.neg: neg,</span><br><span class="line">                                     model.is_training: <span class="literal">True</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            t1 = time.time() - t0</span><br><span class="line">            T += t1</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;Evaluating&#x27;</span>,</span><br><span class="line">            t_test = evaluate(model, dataset, args, sess)</span><br><span class="line">            t_valid = evaluate_valid(model, dataset, args, sess)</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;epoch:%d, time: %f(s), valid (NDCG@10: %.4f, HR@10: %.4f), test (NDCG@10: %.4f, HR@10: %.4f)&#x27;</span> % (</span><br><span class="line">            epoch, T, t_valid[<span class="number">0</span>], t_valid[<span class="number">1</span>], t_test[<span class="number">0</span>], t_test[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            f.write(<span class="built_in">str</span>(t_valid) + <span class="string">&#x27; &#x27;</span> + <span class="built_in">str</span>(t_test) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            f.flush()</span><br><span class="line">            t0 = time.time()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    sampler.close()</span><br><span class="line">    f.close()</span><br><span class="line">    exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">f.close()</span><br><span class="line">sampler.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h3 id="导入模块-3"><a class="anchor" href="#导入模块-3">#</a> 导入模块</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sampler <span class="keyword">import</span> WarpSampler</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：导入所需的模块，包括系统模块、时间模块、参数解析模块、TensorFlow、数据采样器、模型、进度条显示模块和一些实用函数。</p><h3 id="定义布尔类型的字符串转换函数-str2bool"><a class="anchor" href="#定义布尔类型的字符串转换函数-str2bool">#</a> 定义布尔类型的字符串转换函数 <code>str2bool</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">str2bool</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">if</span> s <span class="keyword">not</span> <span class="keyword">in</span> &#123;<span class="string">&#x27;False&#x27;</span>, <span class="string">&#x27;True&#x27;</span>&#125;:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Not a valid boolean string&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s == <span class="string">&#x27;True&#x27;</span></span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：将字符串转换为布尔值，如果字符串不是 'False' 或 'True'，则抛出异常。</p><h3 id="参数解析器-argparse"><a class="anchor" href="#参数解析器-argparse">#</a> 参数解析器 <code>argparse</code></h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--train_dir&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">128</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, default=<span class="number">0.001</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--maxlen&#x27;</span>, default=<span class="number">50</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--hidden_units&#x27;</span>, default=<span class="number">50</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_blocks&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_epochs&#x27;</span>, default=<span class="number">201</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--num_heads&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dropout_rate&#x27;</span>, default=<span class="number">0.5</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--l2_emb&#x27;</span>, default=<span class="number">0.0</span>, <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：定义并解析命令行参数。</p><ul><li><code>--dataset</code> ：数据集名称，必选。</li><li><code>--train_dir</code> ：训练目录，必选。</li><li>其他参数有默认值，包括批量大小、学习率、最大序列长度、隐藏单元数、块数量、训练轮数、注意力头数量、dropout 率和 L2 正则化参数。</li></ul><h3 id="创建训练目录并保存参数"><a class="anchor" href="#创建训练目录并保存参数">#</a> 创建训练目录并保存参数</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir):</span><br><span class="line">    os.makedirs(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir, <span class="string">&#x27;args.txt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;\n&#x27;</span>.join([<span class="built_in">str</span>(k) + <span class="string">&#x27;,&#x27;</span> + <span class="built_in">str</span>(v) <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(<span class="built_in">vars</span>(args).items(), key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])]))</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：检查并创建训练目录，将解析的参数保存到 <code>args.txt</code> 文件中。</p><h3 id="数据分割"><a class="anchor" href="#数据分割">#</a> 数据分割</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataset = data_partition(args.dataset)</span><br><span class="line">[user_train, user_valid, user_test, usernum, itemnum] = dataset</span><br><span class="line">num_batch = <span class="built_in">len</span>(user_train) / args.batch_size</span><br><span class="line">cc = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> u <span class="keyword">in</span> user_train:</span><br><span class="line">    cc += <span class="built_in">len</span>(user_train[u])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;average sequence length: %.2f&#x27;</span> % (cc / <span class="built_in">len</span>(user_train)))</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：调用数据分割函数 <code>data_partition</code> ，获取训练集、验证集、测试集、用户数量和物品数量。计算并打印平均序列长度。</p><h3 id="tensorflow-会话配置"><a class="anchor" href="#tensorflow-会话配置">#</a> TensorFlow 会话配置</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="built_in">open</span>(os.path.join(args.dataset + <span class="string">&#x27;_&#x27;</span> + args.train_dir, <span class="string">&#x27;log.txt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">config.allow_soft_placement = <span class="literal">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：打开日志文件 <code>log.txt</code> ，配置 TensorFlow 会话以允许 GPU 动态增长和软设备放置，并创建会话。</p><h3 id="数据采样器和模型初始化"><a class="anchor" href="#数据采样器和模型初始化">#</a> 数据采样器和模型初始化</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=<span class="number">3</span>)</span><br><span class="line">model = Model(usernum, itemnum, args)</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：初始化数据采样器 <code>WarpSampler</code> 和模型 <code>Model</code> ，并初始化所有 TensorFlow 变量。</p><h3 id="训练过程"><a class="anchor" href="#训练过程">#</a> 训练过程</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">T = <span class="number">0.0</span></span><br><span class="line">t0 = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.num_epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(num_batch), total=num_batch, ncols=<span class="number">70</span>, leave=<span class="literal">False</span>, unit=<span class="string">&#x27;b&#x27;</span>):</span><br><span class="line">            u, seq, pos, neg = sampler.next_batch()</span><br><span class="line">            auc, loss, _ = sess.run([model.auc, model.loss, model.train_op],</span><br><span class="line">                                    &#123;model.u: u, model.input_seq: seq, model.pos: pos, model.neg: neg,</span><br><span class="line">                                     model.is_training: <span class="literal">True</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            t1 = time.time() - t0</span><br><span class="line">            T += t1</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Evaluating&#x27;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            t_test = evaluate(model, dataset, args, sess)</span><br><span class="line">            t_valid = evaluate_valid(model, dataset, args, sess)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;epoch:%d, time: %f(s), valid (NDCG@10: %.4f, HR@10: %.4f), test (NDCG@10: %.4f, HR@10: %.4f)&#x27;</span> % (</span><br><span class="line">            epoch, T, t_valid[<span class="number">0</span>], t_valid[<span class="number">1</span>], t_test[<span class="number">0</span>], t_test[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">            f.write(<span class="built_in">str</span>(t_valid) + <span class="string">&#x27; &#x27;</span> + <span class="built_in">str</span>(t_test) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            f.flush()</span><br><span class="line">            t0 = time.time()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    sampler.close()</span><br><span class="line">    f.close()</span><br><span class="line">    exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">f.close()</span><br><span class="line">sampler.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done&quot;</span>)</span><br></pre></td></tr></table></figure><p></p><p><strong>作用</strong>：训练模型并在每 20 个 epoch 后评估模型性能。</p><ul><li><p><strong>变量初始化</strong>：</p><ul><li><code>T</code> ：总时间。</li><li><code>t0</code> ：当前时间。</li></ul></li><li><p><strong>训练循环</strong>：</p><ul><li><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token operator">&lt;</span>!<span class="token operator">-</span><span class="token operator">-</span>code￼<span class="token number">69</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">></span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>  ：迭代每个批次，使用</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>  <span class="token operator">&lt;</span>!<span class="token operator">-</span><span class="token operator">-</span>code￼<span class="token number">70</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">></span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>  显示进度条。</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>  <span class="token operator">-</span> 调用`sampler<span class="token punctuation">.</span>next_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>`获取一个批次的数据（用户、序列、正样本、负样本）。</pre></td></tr><tr><td data-num="11"></td><td><pre>  <span class="token operator">-</span> 调用`sess<span class="token punctuation">.</span>run`运行模型的训练操作，并获取AUC和损失值。</pre></td></tr></table></figure></li></ul></li><li><p><strong>评估模型</strong>：</p><ul><li>每 20 个 epoch 进行一次评估。<ul><li>计算评估时间 <code>t1</code> 并累加到总时间 <code>T</code> 。</li><li>调用 <code>evaluate</code> 和 <code>evaluate_valid</code> 函数评估模型在测试集和验证集上的性能。</li><li>打印评估结果并写入日志文件。</li></ul></li></ul></li><li><p><strong>异常处理和资源清理</strong>：</p><ul><li>使用 <code>try-except</code> 块捕捉异常，确保在异常发生时关闭采样器和日志文件。</li><li>正常结束训练时，同样关闭采样器和日志文件，并打印 &quot;Done&quot;。</li></ul></li></ul><h1 id="总结"><a class="anchor" href="#总结">#</a> 总结</h1><h2 id="自注意力序列推荐"><a class="anchor" href="#自注意力序列推荐">#</a> 自注意力序列推荐</h2><h3 id="摘要"><a class="anchor" href="#摘要">#</a> 摘要</h3><ul><li><strong>目标</strong>：在推荐系统中捕捉用户活动的序列动态，平衡马尔可夫链（MCs）和循环神经网络（RNNs）。</li><li><strong>提出的模型</strong>：SASRec（自注意力序列推荐）使用自注意力机制，关注相关的过去行为来预测下一个物品。</li><li><strong>性能</strong>：在稀疏和密集数据集上优于最先进的 MC/CNN/RNN 模型，并且效率更高。</li></ul><h3 id="引言"><a class="anchor" href="#引言">#</a> 引言</h3><ul><li><strong>序列动态</strong>：现代推荐系统中，理解用户最近行为的上下文非常关键。</li><li><strong>MCs vs RNNs</strong>：MCs 在处理稀疏数据时表现良好，但上下文范围有限；RNNs 能捕捉长期依赖，但需要密集数据。</li><li><strong>SASRec</strong>：结合两者的优势，使用自注意力机制考虑相关的过去行为来预测未来行为。</li></ul><h3 id="方法"><a class="anchor" href="#方法">#</a> 方法</h3><h4 id="嵌入层-3"><a class="anchor" href="#嵌入层-3">#</a> 嵌入层</h4><ul><li><strong>输入序列转换</strong>：将用户行为序列转换为固定长度序列，必要时使用填充。</li><li><strong>物品嵌入矩阵</strong>：在潜在空间中表示物品。</li><li><strong>位置嵌入</strong>：为物品嵌入添加位置信息，以考虑行为的顺序。</li></ul><h4 id="自注意力块"><a class="anchor" href="#自注意力块">#</a> 自注意力块</h4><ul><li><strong>注意力机制</strong>：计算所有值的加权和，关注相关的过去行为。</li><li><strong>自注意力层</strong>：使用相同的对象作为查询、键和值来捕捉依赖关系。</li><li><strong>因果性</strong>：确保模型在预测下一个物品时只考虑过去的物品。</li><li><strong>前馈网络</strong>：添加非线性，并考虑潜在维度之间的交互。</li></ul><h4 id="堆叠自注意力块-2"><a class="anchor" href="#堆叠自注意力块-2">#</a> 堆叠自注意力块</h4><ul><li><strong>多块</strong>：堆叠多个自注意力块以捕捉复杂的物品转移。</li><li><strong>残差连接、层归一化和 Dropout</strong>：防止过拟合并稳定训练。</li></ul><h4 id="预测层-2"><a class="anchor" href="#预测层-2">#</a> 预测层</h4><ul><li><strong>MF 层</strong>：使用矩阵分解根据转换后的序列预测物品的相关性。</li><li><strong>共享物品嵌入</strong>：通过使用单一的物品嵌入矩阵减少模型大小并防止过拟合。</li></ul><h4 id="网络训练"><a class="anchor" href="#网络训练">#</a> 网络训练</h4><ul><li><strong>二元交叉熵损失</strong>：使用 Adam 优化器优化模型。</li><li><strong>负采样</strong>：在训练过程中为每个正样本生成负样本。</li></ul><h4 id="复杂度分析"><a class="anchor" href="#复杂度分析">#</a> 复杂度分析</h4><ul><li><strong>空间复杂度</strong>：相对于其他方法适中。</li><li><strong>时间复杂度</strong>：由于自注意力层的可并行化，效率较高。</li></ul><h3 id="实验-2"><a class="anchor" href="#实验-2">#</a> 实验</h3><h4 id="数据集-2"><a class="anchor" href="#数据集-2">#</a> 数据集</h4><ul><li><strong>Amazon、Steam、MovieLens</strong>：数据集在领域、平台和稀疏性方面各不相同。</li></ul><h4 id="比较方法"><a class="anchor" href="#比较方法">#</a> 比较方法</h4><ul><li><strong>通用推荐方法</strong>：PopRec, BPR。</li><li><strong>序列推荐方法</strong>：FMC, FPMC, TransRec。</li><li><strong>基于深度学习的方法</strong>：GRU4Rec, GRU4Rec+, Caser。</li></ul><h4 id="实现细节"><a class="anchor" href="#实现细节">#</a> 实现细节</h4><ul><li><strong>架构</strong>：使用两个自注意力块和共享物品嵌入。</li><li><strong>优化</strong>：Adam 优化器，学习率 0.001，批量大小 128。</li></ul><h4 id="评估指标"><a class="anchor" href="#评估指标">#</a> 评估指标</h4><ul><li><strong>Hit Rate@10 和 NDCG@10</strong>：评估推荐性能的指标。</li></ul><h3 id="结果"><a class="anchor" href="#结果">#</a> 结果</h3><ul><li><strong>性能</strong>：SASRec 在稀疏和密集数据集上优于基线方法。</li><li><strong>消融研究</strong>：分析架构中不同组件的影响。</li><li><strong>训练效率和可扩展性</strong>：展示了更快的训练速度和对更长序列的可扩展性。</li></ul><h3 id="结论"><a class="anchor" href="#结论">#</a> 结论</h3><ul><li><strong>SASRec</strong>：一个新颖的基于自注意力的模型，自适应地考虑用户行为进行预测，在性能和效率上优于最先进的方法。</li><li><strong>未来工作</strong>：结合丰富的上下文信息和处理超长序列。</li></ul><h3 id="原理介绍"><a class="anchor" href="#原理介绍">#</a> 原理介绍</h3><ul><li><strong>自注意力机制</strong>：通过计算查询、键和值之间的加权和，关注输入序列中的相关部分。与传统的 RNN 不同，自注意力机制能够并行处理所有时间步，使得模型能够高效地捕捉序列中的长距离依赖。</li><li><strong>残差连接</strong>：在每个自注意力块中添加输入和输出之间的直接连接，有助于训练更深层的网络。</li><li><strong>层归一化</strong>：对每一层的输出进行归一化处理，防止梯度消失和爆炸，提升模型的训练稳定性。</li><li><strong>前馈网络</strong>：在每个自注意力块后添加一个全连接层，增加模型的非线性表示能力。</li><li><strong>位置嵌入</strong>：为每个序列位置添加位置信息，使模型能够识别行为的顺序关系。</li></ul><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a> <a href="/tags/code/" rel="tag"><i class="ic i-tag"></i> code</a> <a href="/tags/recommendation/" rel="tag"><i class="ic i-tag"></i> recommendation</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-08-09 19:51:17" itemprop="dateModified" datetime="2024-08-09T19:51:17+08:00">2024-08-09</time> </span><span id="recommendation/SASRec/" class="item leancloud_visitors" data-flag-title="SASrec" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Enjun Du</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/recommendation/SASRec/" title="SASrec">https://enjundu.github.io/recommendation/SASRec/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/misc/%E4%BC%8A%E8%97%A4%E5%BE%AE%E7%A7%AF%E5%88%86/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;As6g8SnCP2tGRDm.jpg" title="随机过程——运用伊藤微积分对布朗运动进行分析"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> 闲来无事赚丶米</span><h3>随机过程——运用伊藤微积分对布朗运动进行分析</h3></a></div><div class="item right"><a href="/recommendation/README/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;PwEoecqCVMZg6kp.jpg" title="b_README"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> 推荐算法相关search</span><h3>b_README</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#self-attentive-sequential-recommendation"><span class="toc-number">1.</span> <span class="toc-text">Self-Attentive Sequential Recommendation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BEmc"><span class="toc-number">1.1.</span> <span class="toc-text">马尔科夫链（mc）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">1.1.3.</span> <span class="toc-text">马尔科夫链的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E9%98%B6%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE"><span class="toc-number">1.1.4.</span> <span class="toc-text">一阶马尔科夫链</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E9%98%B6%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE"><span class="toc-number">1.1.5.</span> <span class="toc-text">高阶马尔科夫链</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crecurrent-neural-network-rnn"><span class="toc-number">1.2.</span> <span class="toc-text">递归神经网络（Recurrent Neural Network, RNN）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.1.</span> <span class="toc-text">基本结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF"><span class="toc-number">1.2.2.</span> <span class="toc-text">优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.2.3.</span> <span class="toc-text">局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%BA%E5%BA%8F%E6%8E%A8%E8%8D%90"><span class="toc-number">1.3.</span> <span class="toc-text">顺序推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87"><span class="toc-number">1.3.1.</span> <span class="toc-text">目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E4%BA%BA%E6%96%B9%E5%BC%8F"><span class="toc-number">1.3.2.</span> <span class="toc-text">前人方式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transformer"><span class="toc-number">1.4.</span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.4.1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8encoder"><span class="toc-number">1.4.2.</span> <span class="toc-text">编码器（Encoder）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E5%99%A8decoder"><span class="toc-number">1.4.3.</span> <span class="toc-text">解码器（Decoder）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5residual-connection"><span class="toc-number">1.4.4.</span> <span class="toc-text">残差连接（Residual Connection）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6self-attention"><span class="toc-number">1.5.</span> <span class="toc-text">自注意力机制（Self-Attention）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sasrec"><span class="toc-number">1.6.</span> <span class="toc-text">SASRec</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%B9%E8%AE%AD%E7%AE%80%E5%8C%96%E5%9B%BE"><span class="toc-number">1.6.1.</span> <span class="toc-text">培训简化图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A6%81%E7%82%B9"><span class="toc-number">1.6.2.</span> <span class="toc-text">要点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%A6%E5%8F%B7%E8%A1%A8"><span class="toc-number">1.6.3.</span> <span class="toc-text">符号表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%B1%82"><span class="toc-number">1.6.4.</span> <span class="toc-text">嵌入层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">1.6.5.</span> <span class="toc-text">自注意力缩放点积注意力计算过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A"><span class="toc-number">1.6.5.1.</span> <span class="toc-text">解释</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#softmax-%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.5.2.</span> <span class="toc-text">softmax 函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%B1%82"><span class="toc-number">1.6.6.</span> <span class="toc-text">自注意层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB"><span class="toc-number">1.6.7.</span> <span class="toc-text">因果关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%82%B9%E5%AF%B9%E7%82%B9%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"><span class="toc-number">1.6.8.</span> <span class="toc-text">点对点前馈网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ffn%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.6.8.1.</span> <span class="toc-text">FFN（前馈神经网络）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#relu%E7%BA%BF%E6%80%A7%E4%BF%AE%E6%AD%A3%E5%8D%95%E5%85%83"><span class="toc-number">1.6.8.2.</span> <span class="toc-text">ReLU（线性修正单元）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A0%86%E5%8F%A0%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9D%97"><span class="toc-number">1.6.9.</span> <span class="toc-text">堆叠自注意力块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.6.10.</span> <span class="toc-text">层归一化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%83%E7%B4%A0%E5%90%91%E9%87%8F%E7%A7%AF%E7%9A%84%E6%95%B0%E5%AD%A6%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.6.10.1.</span> <span class="toc-text">元素向量积的数学表示</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-number">1.6.10.1.1.</span> <span class="toc-text">举个例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%B1%82"><span class="toc-number">1.6.11.</span> <span class="toc-text">预测层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E5%B1%82%E8%AE%AD%E7%BB%83"><span class="toc-number">1.6.12.</span> <span class="toc-text">网络层训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A8%E8%AE%BA"><span class="toc-number">1.6.13.</span> <span class="toc-text">讨论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.6.14.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">1.6.14.1.</span> <span class="toc-text">问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.6.14.2.</span> <span class="toc-text">数据集</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#modulespy"><span class="toc-number">2.1.</span> <span class="toc-text">modules.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">2.1.1.</span> <span class="toc-text">位置编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96-2"><span class="toc-number">2.1.2.</span> <span class="toc-text">层归一化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E4%BD%9C%E7%94%A8%E5%9F%9F"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">函数作用域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F"><span class="toc-number">2.1.2.2.</span> <span class="toc-text">变量作用域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E8%BE%93%E5%85%A5%E5%BC%A0%E9%87%8F%E7%9A%84%E5%BD%A2%E7%8A%B6"><span class="toc-number">2.1.2.3.</span> <span class="toc-text">获取输入张量的形状</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE"><span class="toc-number">2.1.2.4.</span> <span class="toc-text">计算均值和方差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.2.5.</span> <span class="toc-text">定义变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">2.1.2.6.</span> <span class="toc-text">归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E7%BC%A9%E6%94%BE%E5%92%8C%E5%81%8F%E7%A7%BB"><span class="toc-number">2.1.2.7.</span> <span class="toc-text">应用缩放和偏移</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%B1%82-2"><span class="toc-number">2.1.3.</span> <span class="toc-text">嵌入层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">定义函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F-2"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">变量作用域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%B5%8C%E5%85%A5%E7%9F%A9%E9%98%B5"><span class="toc-number">2.1.3.3.</span> <span class="toc-text">创建嵌入矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E9%9B%B6%E5%90%91%E9%87%8F"><span class="toc-number">2.1.3.4.</span> <span class="toc-text">填充零向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E5%B5%8C%E5%85%A5%E7%9F%A9%E9%98%B5"><span class="toc-number">2.1.3.5.</span> <span class="toc-text">查找嵌入矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%B5%8C%E5%85%A5%E5%90%91%E9%87%8F%E8%BF%9B%E8%A1%8C%E7%BC%A9%E6%94%BE"><span class="toc-number">2.1.3.6.</span> <span class="toc-text">对嵌入向量进行缩放</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-multihead_attention"><span class="toc-number">2.1.4.</span> <span class="toc-text">多头注意力机制 multihead_attention</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.4.1.</span> <span class="toc-text">函数定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AE%BE%E7%BD%AEnum_units"><span class="toc-number">2.1.4.2.</span> <span class="toc-text">变量作用域，设置 num_units</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="toc-number">2.1.4.3.</span> <span class="toc-text">线性变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%86%E5%88%86%E5%92%8C%E6%8B%BC%E6%8E%A5"><span class="toc-number">2.1.4.4.</span> <span class="toc-text">拆分和拼接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0"><span class="toc-number">2.1.4.5.</span> <span class="toc-text">计算注意力分数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E9%AA%8C%E7%A0%81"><span class="toc-number">2.1.4.6.</span> <span class="toc-text">检验码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%A0%E6%9E%9C%E6%8E%A9%E7%A0%81"><span class="toc-number">2.1.4.7.</span> <span class="toc-text">因果掩码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9D%83%E9%87%8D"><span class="toc-number">2.1.4.8.</span> <span class="toc-text">计算注意力权重</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E6%8E%A9%E7%A0%81"><span class="toc-number">2.1.4.9.</span> <span class="toc-text">查询掩码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dropout"><span class="toc-number">2.1.4.10.</span> <span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E6%B1%82%E5%92%8C"><span class="toc-number">2.1.4.11.</span> <span class="toc-text">加权求和</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A5%E5%92%8C%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.1.4.12.</span> <span class="toc-text">拼接和残差连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C"><span class="toc-number">2.1.4.13.</span> <span class="toc-text">返回结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-feedforward"><span class="toc-number">2.1.5.</span> <span class="toc-text">前馈神经网络 feedforward</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89-2"><span class="toc-number">2.1.5.1.</span> <span class="toc-text">函数定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F-3"><span class="toc-number">2.1.5.2.</span> <span class="toc-text">变量作用域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.1.5.3.</span> <span class="toc-text">第一个卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AC%A1dropout"><span class="toc-number">2.1.5.4.</span> <span class="toc-text">第一次 Dropout</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E4%B8%AA%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.1.5.5.</span> <span class="toc-text">第二个卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AC%A1dropout"><span class="toc-number">2.1.5.6.</span> <span class="toc-text">第二次 Dropout</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.1.5.7.</span> <span class="toc-text">残差连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C-2"><span class="toc-number">2.1.5.8.</span> <span class="toc-text">返回结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#modelpy"><span class="toc-number">2.2.</span> <span class="toc-text">model.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95-__init__"><span class="toc-number">2.2.1.</span> <span class="toc-text">初始化方法 __init__</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E5%9F%9F-sasrec-%E5%92%8C%E5%B5%8C%E5%85%A5%E5%B1%82"><span class="toc-number">2.2.2.</span> <span class="toc-text">变量域 &quot;SASRec&quot; 和嵌入层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81-2"><span class="toc-number">2.2.3.</span> <span class="toc-text">位置编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dropout-2"><span class="toc-number">2.2.4.</span> <span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9D%97"><span class="toc-number">2.2.5.</span> <span class="toc-text">构建自注意力机制的块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96-2"><span class="toc-number">2.2.6.</span> <span class="toc-text">归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%B5%8C%E5%85%A5%E5%92%8C%E9%A2%84%E6%B5%8B%E5%BE%97%E5%88%86"><span class="toc-number">2.2.7.</span> <span class="toc-text">计算正负样本的嵌入和预测得分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.8.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#auc%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.2.9.</span> <span class="toc-text">AUC 和优化器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0-predict"><span class="toc-number">2.2.10.</span> <span class="toc-text">预测函数 predict</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#utilpy"><span class="toc-number">2.3.</span> <span class="toc-text">util.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97"><span class="toc-number">2.3.1.</span> <span class="toc-text">导入模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2%E5%87%BD%E6%95%B0-data_partition"><span class="toc-number">2.3.2.</span> <span class="toc-text">数据分割函数 data_partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0-evaluate"><span class="toc-number">2.3.3.</span> <span class="toc-text">模型评估函数 evaluate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0%E9%AA%8C%E8%AF%81%E9%9B%86evaluate_valid"><span class="toc-number">2.3.4.</span> <span class="toc-text">模型评估函数（验证集） evaluate_valid</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#samplerpy"><span class="toc-number">2.4.</span> <span class="toc-text">sampler.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97-2"><span class="toc-number">2.4.1.</span> <span class="toc-text">导入模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E5%87%BD%E6%95%B0-random_neq"><span class="toc-number">2.4.2.</span> <span class="toc-text">随机负样本生成函数 random_neq</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%87%87%E6%A0%B7%E5%87%BD%E6%95%B0-sample_function"><span class="toc-number">2.4.3.</span> <span class="toc-text">数据采样函数 sample_function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#warpsampler-%E7%B1%BB"><span class="toc-number">2.4.4.</span> <span class="toc-text">WarpSampler 类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mainpy"><span class="toc-number">2.5.</span> <span class="toc-text">main.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97-3"><span class="toc-number">2.5.1.</span> <span class="toc-text">导入模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%B8%83%E5%B0%94%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E5%87%BD%E6%95%B0-str2bool"><span class="toc-number">2.5.2.</span> <span class="toc-text">定义布尔类型的字符串转换函数 str2bool</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%A7%A3%E6%9E%90%E5%99%A8-argparse"><span class="toc-number">2.5.3.</span> <span class="toc-text">参数解析器 argparse</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E7%9B%AE%E5%BD%95%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%8F%82%E6%95%B0"><span class="toc-number">2.5.4.</span> <span class="toc-text">创建训练目录并保存参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2"><span class="toc-number">2.5.5.</span> <span class="toc-text">数据分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensorflow-%E4%BC%9A%E8%AF%9D%E9%85%8D%E7%BD%AE"><span class="toc-number">2.5.6.</span> <span class="toc-text">TensorFlow 会话配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%87%87%E6%A0%B7%E5%99%A8%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.5.7.</span> <span class="toc-text">数据采样器和模型初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">2.5.8.</span> <span class="toc-text">训练过程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90"><span class="toc-number">3.1.</span> <span class="toc-text">自注意力序列推荐</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">3.1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">3.1.2.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.3.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E5%B1%82-3"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">嵌入层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9D%97"><span class="toc-number">3.1.3.2.</span> <span class="toc-text">自注意力块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A0%86%E5%8F%A0%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9D%97-2"><span class="toc-number">3.1.3.3.</span> <span class="toc-text">堆叠自注意力块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%B1%82-2"><span class="toc-number">3.1.3.4.</span> <span class="toc-text">预测层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83"><span class="toc-number">3.1.3.5.</span> <span class="toc-text">网络训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">3.1.3.6.</span> <span class="toc-text">复杂度分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-2"><span class="toc-number">3.1.4.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86-2"><span class="toc-number">3.1.4.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AF%94%E8%BE%83%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.4.2.</span> <span class="toc-text">比较方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-number">3.1.4.3.</span> <span class="toc-text">实现细节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">3.1.4.4.</span> <span class="toc-text">评估指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">3.1.5.</span> <span class="toc-text">结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">3.1.6.</span> <span class="toc-text">结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.1.7.</span> <span class="toc-text">原理介绍</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/recommendation/README/" rel="bookmark" title="b_README">b_README</a></li><li class="active"><a href="/recommendation/SASRec/" rel="bookmark" title="SASrec">SASrec</a></li><li><a href="/recommendation/basic_knowledge/" rel="bookmark" title="basic_knowledge">basic_knowledge</a></li><li><a href="/recommendation/Self-Supervised%20Learning%20for%20Sequential%20Recommendation%20with%20Mutual%20Information%20/" rel="bookmark" title="S3-Rec:Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization">S3-Rec:Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</a></li><li><a href="/recommendation/Contrastive%20Learning%20for%20Sequential%20Recommendation%20%E4%B8%8E%20Self-Supervised%20Learning%20for%20Sequential%20Recommendation%20with%20Mutual%20Information%20Maximization/" rel="bookmark" title="Contrastive Learning for Sequential Recommendation">Contrastive Learning for Sequential Recommendation</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">81</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">12</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">13</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0VuanVuRHU=" title="https:&#x2F;&#x2F;github.com&#x2F;EnjunDu"><i class="ic i-github"></i></span> <a href="/enjundu.cs@gmail.com" title="enjundu.cs@gmail.com" class="item email"><i class="ic i-envelope"></i></a></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/misc/%E4%BC%8A%E8%97%A4%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/recommendation/README/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_7_Transformer/" title="深度学习_7_Transformer">深度学习_7_Transformer</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E8%A5%BF%E6%96%B9%E9%9F%B3%E4%B9%90%E5%8F%B2/" title="迈克尔杰克逊对西方流行文化的多重影响">迈克尔杰克逊对西方流行文化的多重影响</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEA/" title="In 单片机小学期ECEA">单片机小学期ECEA</a></div><span><a href="/ECEA/2%E8%9C%82%E9%B8%A3%E5%99%A8%E6%8A%A5%E6%97%B6/" title="The buzzer reports the time based on the student ID">The buzzer reports the time based on the student ID</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/%E7%94%B5%E5%BD%B1%E7%BD%91%E7%AB%99/" title="电影网站">电影网站</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/README/" title="蓝天の留言">蓝天の留言</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/00_spring_boot/" title="01_spring_boot">01_spring_boot</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/bit/" title="In BIT-study">BIT-study</a></div><span><a href="/bit/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E9%AA%8C/" title="数据结构实验">数据结构实验</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C/" title="a_统计结果">a_统计结果</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/01_conductor-main/" title="01_conductor">01_conductor</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/README_1_KNN/" title="线性分类器_Sanfordcs231n">线性分类器_Sanfordcs231n</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">1.2m words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">17:39</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"recommendation/SASRec/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->