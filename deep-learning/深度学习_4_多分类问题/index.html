<!-- build time:Sat Aug 03 2024 22:56:27 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Hexo" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Hexo" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Hexo" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter,deep_learning"><link rel="canonical" href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><title>深度学习_4_多分类问题 - deep-learning | 蓝天の网站 = Hexo</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">深度学习_4_多分类问题</h1><div class="meta"><span class="item" title="Created: 2024-07-28 14:02:28"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-28T14:02:28+08:00">2024-07-28</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/04/19H8wehu2ExKaic.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/OLqrN6bKDJHW5ek.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/cI2aroK5AZfHs7U.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/6vserUNHJbOxI4y.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/2CIcORrG8hxpSnD.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/PwEoecqCVMZg6kp.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/deep-learning/" itemprop="item" rel="index" title="In deep-learning"><span itemprop="name">deep-learning</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hexo"></span><div class="body md" itemprop="articleBody"><h1 id="如何实现多分类问题"><a class="anchor" href="#如何实现多分类问题">#</a> <strong>如何实现多分类问题？</strong></h1><h2 id="概率分布"><a class="anchor" href="#概率分布">#</a> 概率分布</h2><ul><li>每个可能的输出概率都需要大于等于零</li><li>所有可能分类概率之和为 1</li></ul><h2 id="函数区别"><a class="anchor" href="#函数区别">#</a> 函数区别</h2><p><img data-src="https://s2.loli.net/2024/07/28/KCb31xz96FfecTN.png" alt="QQ_1722164470310.png"></p><ul><li>中间处理过程可以用 Sigmoid 函数</li><li>最终层应该为 Softmax 层</li></ul><h2 id="softmax实现"><a class="anchor" href="#softmax实现">#</a> Softmax 实现</h2><p><img data-src="https://s2.loli.net/2024/07/29/NFLHGVwikJRQhZ2.png" alt="QQ_1722190799779.png"></p><h2 id="one-hot方法"><a class="anchor" href="#one-hot方法">#</a> One-hot 方法</h2><p>One-hot 编码是一种将分类数据转换为二进制向量的方法，通常用于将离散的分类标签转换为机器学习算法可以处理的格式。每个类别用一个独特的二进制向量表示，其中只有一个位置的值为 1，其余位置的值为 0。这样做的好处是可以将分类数据转化为数值数据，方便模型处理。</p><h2 id="损失函数求法"><a class="anchor" href="#损失函数求法">#</a> 损失函数求法</h2><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><mover accent="true"><mi>Y</mi><mo stretchy="true">^</mo></mover><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>Y</mi><mrow><mi>log</mi><mo>⁡</mo><mover accent="true"><mi>Y</mi><mo stretchy="true">^</mo></mover></mrow></mrow><annotation encoding="application/x-tex">Loss(\widehat{Y},Y)=-Y{\log\widehat{Y}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.17333em;vertical-align:-.25em"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92333em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span></span></span><span class="svg-align" style="top:-3.6833299999999998em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.11777em;vertical-align:-.19444em"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="mord"><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.92333em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span></span></span><span class="svg-align" style="top:-3.6833299999999998em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span></span></span></span></span></span></span></span></span></p><p><img data-src="https://s2.loli.net/2024/07/28/l3pPbThCqgz24xJ.png" alt="QQ_1722165173590.png"></p><h2 id="代码实现"><a class="anchor" href="#代码实现">#</a> 代码实现</h2><h3 id="numpy格式"><a class="anchor" href="#numpy格式">#</a> numpy 格式</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义真实标签和预测分数</span></span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">z = np.array([<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算预测概率（Softmax）</span></span><br><span class="line">y_pred = np.exp(z) / np.exp(z).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算交叉熵损失</span></span><br><span class="line">loss = (-y * np.log(y_pred)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><p></p><h3 id="torch实现"><a class="anchor" href="#torch实现">#</a> torch 实现</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义真实标签和预测分数</span></span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>])</span><br><span class="line">z = torch.Tensor([[<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义交叉熵损失函数</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失</span></span><br><span class="line">loss = criterion(z, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><p></p><ul><li>输出的最后一层不要进行激活 —— 即最后一层输出不要进行非线性变换</li><li>损失函数用 <code>CrossEntropyLoss()</code> 库实现</li></ul><h1 id="多分类问题代码"><a class="anchor" href="#多分类问题代码">#</a> 多分类问题代码</h1><h2 id="引用相关库"><a class="anchor" href="#引用相关库">#</a> 引用相关库</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br></pre></td></tr></table></figure><p></p><h2 id="数据处理"><a class="anchor" href="#数据处理">#</a> 数据处理</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p></p><ul std=""><li><code>transforms.ToTensor()</code> : 这个操作将图像从 PIL 图像或者 numpy 数组转换为 PyTorch 张量（Tensor）。在转换过程中，它还会将图像的像素值从 0-255 缩放到 0-1 之间。这个步骤是必要的，因为 PyTorch 模型需要张量格式的数据作为输入。</li><li><code>transforms.Normalize((0.1307,), (0.3081,))</code> : 这个操作对图像进行标准化处理。标准化是通过减去均值并除以标准差来完成的，这样可以使数据具有零均值和单位方差。对于 MNIST 数据集，经验上得出的像素值均值为 0.1307，标准差为 0.3081。这个步骤可以加速模型的训练收敛，并提高模型的泛化能力。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>:</mo><mtext>长、</mtext><mi>H</mi><mo>:</mo><mtext>宽、</mtext><mi>C</mi><mtext>：通道</mtext></mrow><annotation encoding="application/x-tex">W:长、H:宽、C：通道</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord cjk_fallback">长</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord cjk_fallback">宽</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mord cjk_fallback">：</span><span class="mord cjk_fallback">通</span><span class="mord cjk_fallback">道</span></span></span></span> pytorch 中将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">W×H×X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span></span></span></span> 转为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">C×W×H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span>，以便高效运算。</li><li>故此处的 <code>transform</code> 将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">Z</mi><mrow><mn>28</mn><mo>×</mo><mn>28</mn></mrow></msup><mo separator="true">,</mo><mtext>ріхе</mtext><mi>l</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mn>255</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\mathbb{Z}^{28\times28},\text{ріхе}l\in\{0,...,255\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord mathbb">Z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">8</span><span class="mbin mtight">×</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord cyrillic_fallback">ріхе</span></span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mord">5</span><span class="mord">5</span><span class="mclose">}</span></span></span></span> 转换为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>28</mn><mo>×</mo><mn>28</mn></mrow></msup><mo separator="true">,</mo><mi>p</mi><mi>i</mi><mi>x</mi><mi>l</mi><mi>e</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbb{R}^{1\times28\times28},pixle\in[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">×</span><span class="mord mtight">2</span><span class="mord mtight">8</span><span class="mbin mtight">×</span><span class="mord mtight">2</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">i</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>. 其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>28</mn><mo>×</mo><mn>28</mn><mtext>分别为</mtext><mi>C</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">1×28×28分别为C×W×H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">2</span><span class="mord">8</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord">2</span><span class="mord">8</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">别</span><span class="mord cjk_fallback">为</span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span>。</li><li>数据标准化：Pixel_{norm}=\frac{Pixel_{origin}-mean}</li></ul><h2 id="用relu库来预测"><a class="anchor" href="#用relu库来预测">#</a> 用 relu 库来预测</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.l2 = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.l3 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.l4 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.l5 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">        x = F.relu(self.l1(x))</span><br><span class="line">        x = F.relu(self.l2(x))</span><br><span class="line">        x = F.relu(self.l3(x))</span><br><span class="line">        x = F.relu(self.l4(x))</span><br><span class="line">        x = self.l5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line">criterion=torch.nn.CrossEntropyLoss()	<span class="comment">#交叉熵损失</span></span><br><span class="line">optimizer=optim.SGD(model.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.5</span>) <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage:</span></span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><p></p><ul><li><p>在优化器中， <code>momentum</code> 是一个加速梯度下降过程的技术。具体来说， <code>momentum</code> 是用来减少训练过程中震荡的一种方法，可以加快收敛速度。</p></li><li><p>详细解释</p><p>在梯度下降中，更新权重的公式通常是：</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>−</mo><mi>η</mi><mo>⋅</mo><mi mathvariant="normal">∇</mi><mi>J</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w = w - \eta \cdot \nabla J(w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mclose">)</span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02691em">w</span></span></span></span> 是权重。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span> 是学习率。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>J</mi><mo stretchy="false">(</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">\nabla J(w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span></span></span></span>) 是损失函数对权重的梯度。</li></ul><p>引入动量后，权重的更新公式变为：</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><mi>γ</mi><mo>⋅</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>η</mi><mo>⋅</mo><mi mathvariant="normal">∇</mi><mi>J</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">v_t = \gamma \cdot v_{t-1} + \eta \cdot \nabla J(w_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05556em">γ</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.791661em;vertical-align:-.208331em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>t</mi></msub><mo>−</mo><msub><mi>v</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_{t+1}=w_t-v_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.638891em;vertical-align:-.208331em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></p><p>其中：</p><ul><li>是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> 次更新时的动量项。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05556em">γ</span></span></span></span> 是动量系数（通常在 0 到 1 之间，图中为 0.5）。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">v_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.638891em;vertical-align:-.208331em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span></span></span></span> 是前一次更新时的动量项。</li></ul><p>动量的引入使得每次更新不仅依赖当前的梯度，还会考虑前一次更新的方向，从而能够平滑梯度更新的路径，减少梯度下降过程中的震荡。动量项在梯度方向保持一致时，会加快收敛速度，而在梯度方向发生变化时，会起到抑制作用，从而使得更新更加平滑。</p></li><li><p>relu 函数：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">U</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{ReLU}(x)=\max(0,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">R</span><span class="mord mathrm">e</span><span class="mord mathrm">L</span><span class="mord mathrm">U</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p></li></ul><h2 id="完整代码"><a class="anchor" href="#完整代码">#</a> 完整代码</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transform</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.l2 = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.l3 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.l4 = nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.l5 = nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">        x = F.relu(self.l1(x))</span><br><span class="line">        x = F.relu(self.l2(x))</span><br><span class="line">        x = F.relu(self.l3(x))</span><br><span class="line">        x = F.relu(self.l4(x))</span><br><span class="line">        x = self.l5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line">criterion=torch.nn.CrossEntropyLoss()	<span class="comment">#交叉熵损失</span></span><br><span class="line">optimizer=optim.SGD(model.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.5</span>) <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage:</span></span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><p></p><ul><li><code>x = x.view(-1, 784)</code> ：将输入的图像展平成大小为 <code>(-1, 784)</code> 的二维张量（-1 表示自动计算维度大小）。</li><li><code>x = F.relu(self.l1(x))</code> ：将输入传递给第一层，并应用 ReLU 激活函数。</li><li><code>x = self.l5(x)</code> ：将第四层的输出传递给第五层（没有激活函数，因为这是最终输出层）。</li><li>创建一个 <code>Net</code> 类的实例，即初始化神经网络模型。</li><li>定义损失函数为交叉熵损失，用于多分类任务。</li><li>定义优化器为随机梯度下降（SGD），学习率为 0.01，动量为 0.5。</li><li><code>running_loss = 0.0</code> ：初始化累积损失为 0。</li><li><code>for batch_idx, data in enumerate(train_loader, 0)</code> ：遍历训练数据加载器。</li><li><code>inputs, target = data</code> ：将数据分为输入 <code>inputs</code> 和目标 <code>target</code> 。</li><li><code>optimizer.zero_grad()</code> ：清除优化器的梯度。</li><li><code>outputs = model(inputs)</code> ：将输入传入模型，得到输出 <code>outputs</code> 。</li><li><code>loss = criterion(outputs, target)</code> ：计算损失。</li><li><code>loss.backward()</code> ：反向传播，计算梯度。</li><li><code>optimizer.step()</code> ：更新模型参数。</li><li><code>running_loss += loss.item()</code> ：累加损失。</li><li><code>if batch_idx % 300 == 299</code> ：每 300 个批次打印一次平均损失。</li><li><code>print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))</code> ：打印当前轮次和批次的平均损失。</li><li><code>running_loss = 0.0</code> ：重置累积损失。</li></ul><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a> <a href="/tags/deep-learning/" rel="tag"><i class="ic i-tag"></i> deep_learning</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-07-29 02:20:18" itemprop="dateModified" datetime="2024-07-29T02:20:18+08:00">2024-07-29</time> </span><span id="deep-learning/深度学习_4_多分类问题/" class="item leancloud_visitors" data-flag-title="深度学习_4_多分类问题" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Hexo</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" title="深度学习_4_多分类问题">https://enjundu.github.io/deep-learning/深度学习_4_多分类问题/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_5_CNN/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;2CIcORrG8hxpSnD.jpg" title="深度学习_5_CNN"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> deep-learning</span><h3>深度学习_5_CNN</h3></a></div><div class="item right"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;8ONjfHLDzZ4YiCJ.jpg" title="深度学习_6_RNN"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> deep-learning</span><h3>深度学习_6_RNN</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">如何实现多分类问题？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="toc-number">1.1.</span> <span class="toc-text">概率分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%8C%BA%E5%88%AB"><span class="toc-number">1.2.</span> <span class="toc-text">函数区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.3.</span> <span class="toc-text">Softmax 实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#one-hot%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.</span> <span class="toc-text">One-hot 方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%82%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text">损失函数求法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.6.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.6.1.</span> <span class="toc-text">numpy 格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.6.2.</span> <span class="toc-text">torch 实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%BB%A3%E7%A0%81"><span class="toc-number">2.</span> <span class="toc-text">多分类问题代码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E7%94%A8%E7%9B%B8%E5%85%B3%E5%BA%93"><span class="toc-number">2.1.</span> <span class="toc-text">引用相关库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">数据处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8relu%E5%BA%93%E6%9D%A5%E9%A2%84%E6%B5%8B"><span class="toc-number">2.3.</span> <span class="toc-text">用 relu 库来预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">2.4.</span> <span class="toc-text">完整代码</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/deep-learning/README_2_Linear%20Classification/" rel="bookmark" title="k-NN最近分类器_Sanfordcs231n">k-NN最近分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_1_KNN/" rel="bookmark" title="线性分类器_Sanfordcs231n">线性分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_3_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="神经网络_Sanfordcs231n">神经网络_Sanfordcs231n</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="bookmark" title="深度学习_1">深度学习_1</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="bookmark" title="深度学习_1_基础知识">深度学习_1_基础知识</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2_%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="深度学习_2_实战">深度学习_2_实战</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3_%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E5%BA%A6%E8%BE%93%E5%85%A5/" rel="bookmark" title="深度学习_3_多维度输入">深度学习_3_多维度输入</a></li><li class="active"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" rel="bookmark" title="深度学习_4_多分类问题">深度学习_4_多分类问题</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_5_CNN/" rel="bookmark" title="深度学习_5_CNN">深度学习_5_CNN</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/" rel="bookmark" title="深度学习_6_RNN">深度学习_6_RNN</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">70</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">11</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">10</span> <span class="name">tags</span></a></div></nav><div class="social"></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_5_CNN/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/shudian/" title="In 数字逻辑实验">数字逻辑实验</a></div><span><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%80/" title="组合逻辑基础模块">组合逻辑基础模块</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/Personal%20Statement/" title="Personal_Statement">Personal_Statement</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/redis-dict.c%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="DICT.C源码阅读报告">DICT.C源码阅读报告</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/1_PythonProjectTemplate-master/" title="PythonProjectTemplate-master">PythonProjectTemplate-master</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/bit/" title="In BIT-study">BIT-study</a></div><span><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%B4%AA%E6%B0%B4%E9%A2%84%E6%B5%8B/" title="亚太数模——洪水">亚太数模——洪水</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/X_artificial-adversary-master/" title="artificial-adversary">artificial-adversary</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/bit/" title="In BIT-study">BIT-study</a></div><span><a href="/bit/%E7%BE%8E%E8%B5%9B%E2%80%94%E2%80%94%E4%B8%83%E9%B3%83%E9%B3%97/" title="美赛——七鳃鳗">美赛——七鳃鳗</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="深度学习_1">深度学习_1</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEA/" title="In 单片机小学期ECEA">单片机小学期ECEA</a></div><span><a href="/ECEA/5%E4%BA%A7%E7%94%9F%E5%A4%9A%E5%BD%A9%E5%91%BC%E5%90%B8%E7%81%AF/" title="Breathing lamp">Breathing lamp</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/README_2_Linear%20Classification/" title="k-NN最近分类器_Sanfordcs231n">k-NN最近分类器_Sanfordcs231n</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"deep-learning/深度学习_4_多分类问题/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->