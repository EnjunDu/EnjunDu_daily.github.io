<!-- build time:Thu Aug 01 2024 01:29:31 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Hexo" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Hexo" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Hexo" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter,deep_learning"><link rel="canonical" href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/"><title>深度学习_6_RNN - deep-learning | 蓝天の网站 = Hexo</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">深度学习_6_RNN</h1><div class="meta"><span class="item" title="Created: 2024-07-29 15:02:28"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-29T15:02:28+08:00">2024-07-29</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/03/6vserUNHJbOxI4y.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/zAwyEXCNIOpoDLk.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/19H8wehu2ExKaic.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/cI2aroK5AZfHs7U.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/qk7VYGUEtZ2oeyB.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/As6g8SnCP2tGRDm.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/deep-learning/" itemprop="item" rel="index" title="In deep-learning"><span itemprop="name">deep-learning</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hexo"></span><div class="body md" itemprop="articleBody"><ul><li>自然语言→有顺序关系 —— 依赖于词</li></ul><h1 id="循环神经网络recurrent-neural-network"><a class="anchor" href="#循环神经网络recurrent-neural-network">#</a> 循环神经网络：Recurrent Neural Network</h1><p>循环神经网络（Recurrent Neural Network，RNN）是一种特别适合处理序列数据的神经网络模型。RNN 的设计理念是利用网络中的循环结构，使得网络能够记住序列中的前面信息，从而捕捉数据的时间依赖性。</p><h2 id="rnn基本结构"><a class="anchor" href="#rnn基本结构">#</a> RNN 基本结构</h2><p>RNN 的基本单元包含一个隐藏层，该隐藏层的输出不仅依赖于当前输入，还依赖于前一个时刻的隐藏层输出。这种依赖关系可以用以下公式表示：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>y</mi></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;h_{t}=\sigma(W_{hh}h_{t-1}+W_{xh}x_{t}+b_{h})\\&amp;y_{t}=W_{hy}h_t+b_y\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em"><span style="top:-3.75em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span><span style="top:-2.25em"><span class="pstrut" style="height:2.84em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">h_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是时刻 $ t $ 的隐藏状态。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是时刻 $ t$ 的输入。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">y_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是时刻 $ t$ 的输出。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{xh}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{hy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.969438em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 是权重矩阵。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>h</mi></msub></mrow><annotation encoding="application/x-tex">b_h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">b_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.980548em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 是偏置。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span></span></span></span> 是激活函数，如 tanh 或 ReLU。</li></ul><h2 id="rnn的特点"><a class="anchor" href="#rnn的特点">#</a> RNN 的特点</h2><ol><li><strong>处理序列数据</strong>：RNN 可以处理任意长度的序列数据，这使得它特别适合时间序列分析、自然语言处理等任务。</li><li><strong>记忆能力</strong>：通过隐藏层的循环连接，RNN 可以记住前面时刻的信息，并将其用于当前时刻的输出计算。</li><li><strong>参数共享</strong>：RNN 在每个时间步共享相同的参数，这使得模型参数数量不会随着序列长度的增加而增加。</li></ol><h2 id="rnn的运用"><a class="anchor" href="#rnn的运用">#</a> RNN 的运用</h2><p><strong>自然语言处理（NLP）</strong>：</p><ul><li>语言模型：预测句子中的下一个词。</li><li>机器翻译：将一句话从一种语言翻译成另一种语言。</li><li>文本生成：生成与训练数据相似的文本。</li></ul><p><strong>时间序列预测</strong>：</p><ul><li>股价预测：预测未来的股价走势。</li><li>天气预报：基于历史天气数据预测未来天气。</li></ul><p><strong>语音识别</strong>：</p><ul><li>将语音信号转换为文本。</li></ul><h2 id="rnn的局限性"><a class="anchor" href="#rnn的局限性">#</a> RNN 的局限性</h2><ol><li><strong>梯度消失和梯度爆炸问题</strong>：在长序列训练中，标准 RNN 会遇到梯度消失和梯度爆炸的问题，导致模型难以捕捉长时间依赖。</li><li><strong>训练复杂性</strong>：由于循环依赖，RNN 的训练相对复杂，计算开销较大。</li></ol><h1 id="rnn计算过程"><a class="anchor" href="#rnn计算过程">#</a> RNN 计算过程</h1><h2 id="tanh激活函数"><a class="anchor" href="#tanh激活函数">#</a> tanh 激活函数</h2><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.217661em;vertical-align:-.7693300000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.448331em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.590392em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.697331em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.771331em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7693300000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h2 id="流程图"><a class="anchor" href="#流程图">#</a> 流程图</h2><p><img data-src="https://s2.loli.net/2024/07/29/lEXnML36cmH4hq2.png" alt="QQ_1722242360278.png"></p><p><img data-src="https://s2.loli.net/2024/07/29/3qBZIVs7DSdGJmH.png" alt="QQ_1722242466536.png"></p><h1 id="代码设计"><a class="anchor" href="#代码设计">#</a> 代码设计</h1><h3 id="rnn-cell"><a class="anchor" href="#rnn-cell">#</a> RNN Cell</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cell=torch.nn.RNNCell(input_size=input_size,hidden_size=hidden_size)</span><br></pre></td></tr></table></figure><p></p><ul><li>两个值：确定了权重维度和偏置维度</li></ul><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hidden=cell(<span class="built_in">input</span>,hidden)</span><br></pre></td></tr></table></figure><p></p><ul><li>更新 <code>hidden</code> 值</li></ul><h3 id="input"><a class="anchor" href="#input">#</a> input</h3><ul><li><code>input of shape(batch,input_size)</code></li><li><code>hiadden of shape(batch,hidden_size)</code></li></ul><h3 id="output"><a class="anchor" href="#output">#</a> output</h3><ul><li><code>hidden of shape(batch,hidden_size)</code></li></ul><h2 id="假设"><a class="anchor" href="#假设">#</a> 假设</h2><h3 id="假设我们有以下属性的序列"><a class="anchor" href="#假设我们有以下属性的序列">#</a> 假设我们有以下属性的序列：</h3><ul><li><strong>batchSize = 1</strong>：批量大小为 1，表示每次处理一个样本。</li><li><strong>seqLen = 3</strong>：序列长度为 3，表示每个样本有 3 个时间步。</li><li><strong>inputSize = 4</strong>：输入大小为 4，表示每个时间步有 4 个输入特征。</li><li><strong>hiddenSize = 2</strong>：隐藏状态大小为 2，表示 RNN 的隐藏层维度为 2。</li></ul><h3 id="rnncell的输入和输出形状"><a class="anchor" href="#rnncell的输入和输出形状">#</a> RNNCell 的输入和输出形状</h3><ul><li>输入形状<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>（</mtext><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mtext>）</mtext></mrow><annotation encoding="application/x-tex">（input.shape）</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord cjk_fallback">）</span></span></span></span><ul><li>输入的形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>batchSize</mtext><mo separator="true">,</mo><mtext>inputSize</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{batchSize}, \text{inputSize})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">batchSize</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord">inputSize</span></span><span class="mclose">)</span></span></span></span>，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1, 4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span>。</li></ul></li><li>输出形状<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>（</mtext><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mtext>）</mtext></mrow><annotation encoding="application/x-tex">（output.shape）</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord cjk_fallback">）</span></span></span></span><ul><li>输出的形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>batchSize</mtext><mo separator="true">,</mo><mtext>hiddenSize</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{batchSize}, \text{hiddenSize})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">batchSize</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord">hiddenSize</span></span><span class="mclose">)</span></span></span></span>，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1, 2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mclose">)</span></span></span></span>。</li></ul></li></ul><h3 id="序列可以包装在一个张量中形状为"><a class="anchor" href="#序列可以包装在一个张量中形状为">#</a> 序列可以包装在一个张量中，形状为：</h3><ul><li>数据集形状<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>（</mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mtext>）</mtext></mrow><annotation encoding="application/x-tex">（dataset.shape）</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord cjk_fallback">（</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord cjk_fallback">）</span></span></span></span><ul><li>数据集的形状为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>seqLen</mtext><mo separator="true">,</mo><mtext>batchSize</mtext><mo separator="true">,</mo><mtext>inputSize</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{seqLen}, \text{batchSize}, \text{inputSize})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">seqLen</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord">batchSize</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord text"><span class="mord">inputSize</span></span><span class="mclose">)</span></span></span></span>，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(3, 1, 4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span>。</li><li>这个形状表示整个数据集包含 3 个时间步，每个时间步有一个样本，每个样本有 4 个输入特征。</li></ul></li></ul><h3 id="代码实现"><a class="anchor" href="#代码实现">#</a> 代码实现</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (seq, batch, features)</span></span><br><span class="line">dataset = torch.randn(seq_len, batch_size, input_size)</span><br><span class="line">hidden = torch.zeros(batch_size, hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, <span class="built_in">input</span> <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">20</span>, idx, <span class="string">&#x27;=&#x27;</span> * <span class="number">20</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Input size: &#x27;</span>, <span class="built_in">input</span>.shape)</span><br><span class="line">    </span><br><span class="line">    hidden = cell(<span class="built_in">input</span>, hidden)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Outputs size: &#x27;</span>, hidden.shape)</span><br><span class="line">    <span class="built_in">print</span>(hidden)</span><br></pre></td></tr></table></figure><p></p><h2 id="如何使用rnn"><a class="anchor" href="#如何使用rnn">#</a> 如何使用 RNN？</h2><p><img data-src="https://s2.loli.net/2024/07/29/pEZvUjxIlXg6t2N.png" alt="QQ_1722246317088.png"></p><ul><li>输入的时候送<strong>所有序列</strong>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 即可</li></ul><h3 id="代码实现-2"><a class="anchor" href="#代码实现-2">#</a> 代码实现</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line">num_layers = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (seqLen, batchSize, inputSize)</span></span><br><span class="line">inputs = torch.randn(seq_len, batch_size, input_size)</span><br><span class="line">hidden = torch.zeros(num_layers, batch_size, hidden_size)</span><br><span class="line"></span><br><span class="line">out, hidden = cell(inputs, hidden)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output size:&#x27;</span>, out.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>, out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden size:&#x27;</span>, hidden.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hidden:&#x27;</span>, hidden)</span><br></pre></td></tr></table></figure><p></p><h1 id="自然语言处理"><a class="anchor" href="#自然语言处理">#</a> 自然语言处理</h1><h2 id="处理字符"><a class="anchor" href="#处理字符">#</a> 处理字符</h2><ul><li>构建单词表 / 字母表</li><li>构建索引</li></ul><p><img data-src="https://s2.loli.net/2024/07/29/BLApeOyizdmvsbD.png" alt="QQ_1722247061496.png"></p><p>input_size=4</p><p><img data-src="https://s2.loli.net/2024/07/29/KUAZqNaBwGjEgs5.png" alt="QQ_1722247146678.png"></p><p><img data-src="https://s2.loli.net/2024/07/29/5fO63vyeHBtaEMZ.png" alt="QQ_1722247299337.png"></p><h2 id="代码设计-2"><a class="anchor" href="#代码设计-2">#</a> 代码设计</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">idx2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line">x_data = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">one_hot_lookup = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">x_one_hot = [one_hot_lookup[x] <span class="keyword">for</span> x <span class="keyword">in</span> x_data]</span><br><span class="line"></span><br><span class="line">inputs = torch.Tensor(x_one_hot).view(-<span class="number">1</span>, batch_size, input_size)</span><br><span class="line">labels = torch.LongTensor(y_data).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p><h3 id="模型设计"><a class="anchor" href="#模型设计">#</a> 模型设计</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, batch_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.batch_size = batch_size  <span class="comment"># 设置批处理大小</span></span><br><span class="line">        self.input_size = input_size  <span class="comment"># 设置输入大小</span></span><br><span class="line">        self.hidden_size = hidden_size  <span class="comment"># 设置隐藏状态大小</span></span><br><span class="line">        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)  <span class="comment"># 初始化RNN单元</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span><br><span class="line">        hidden = self.rnncell(<span class="built_in">input</span>, hidden)  <span class="comment"># 前向传播，计算新的隐藏状态</span></span><br><span class="line">        <span class="keyword">return</span> hidden  <span class="comment"># 返回隐藏状态</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.zeros(self.batch_size, self.hidden_size)  <span class="comment"># 初始化隐藏状态为零张量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">net = Model(input_size, hidden_size, batch_size)</span><br></pre></td></tr></table></figure><p></p><h3 id="训练"><a class="anchor" href="#训练">#</a> 训练</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">    hidden = net.init_hidden()  <span class="comment"># 初始化隐藏状态</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted string: &#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, label <span class="keyword">in</span> <span class="built_in">zip</span>(inputs, labels):</span><br><span class="line">        hidden = net(<span class="built_in">input</span>, hidden)  <span class="comment"># 前向传播</span></span><br><span class="line">        loss += criterion(hidden, label)  <span class="comment"># 计算损失</span></span><br><span class="line">        </span><br><span class="line">        _, idx = hidden.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(idx2char[idx.item()], end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;, Epoch [%d/15] loss=%.4f&#x27;</span> % (epoch+<span class="number">1</span>, loss.item()))</span><br></pre></td></tr></table></figure><p></p><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a> <a href="/tags/deep-learning/" rel="tag"><i class="ic i-tag"></i> deep_learning</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-07-29 18:12:24" itemprop="dateModified" datetime="2024-07-29T18:12:24+08:00">2024-07-29</time> </span><span id="deep-learning/深度学习_6_GNN/" class="item leancloud_visitors" data-flag-title="深度学习_6_RNN" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Hexo</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/" title="深度学习_6_RNN">https://enjundu.github.io/deep-learning/深度学习_6_GNN/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;PwEoecqCVMZg6kp.jpg" title="深度学习_4_多分类问题"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> deep-learning</span><h3>深度学习_4_多分类问题</h3></a></div><div class="item right"><a href="/recommendation/Self-Supervised%20Learning%20for%20Sequential%20Recommendation%20with%20Mutual%20Information%20/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;d8I9raJDhEUebpV.jpg" title="S^3-Rec:Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> 推荐算法相关search</span><h3>S^3-Rec:Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crecurrent-neural-network"><span class="toc-number">1.</span> <span class="toc-text">循环神经网络：Recurrent Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">RNN 基本结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E7%9A%84%E7%89%B9%E7%82%B9"><span class="toc-number">1.2.</span> <span class="toc-text">RNN 的特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E7%9A%84%E8%BF%90%E7%94%A8"><span class="toc-number">1.3.</span> <span class="toc-text">RNN 的运用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.4.</span> <span class="toc-text">RNN 的局限性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#rnn%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">RNN 计算过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#tanh%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">2.1.</span> <span class="toc-text">tanh 激活函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-number">2.2.</span> <span class="toc-text">流程图</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1"><span class="toc-number">3.</span> <span class="toc-text">代码设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rnn-cell"><span class="toc-number">3.0.1.</span> <span class="toc-text">RNN Cell</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#input"><span class="toc-number">3.0.2.</span> <span class="toc-text">input</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#output"><span class="toc-number">3.0.3.</span> <span class="toc-text">output</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%81%87%E8%AE%BE"><span class="toc-number">3.1.</span> <span class="toc-text">假设</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%87%E8%AE%BE%E6%88%91%E4%BB%AC%E6%9C%89%E4%BB%A5%E4%B8%8B%E5%B1%9E%E6%80%A7%E7%9A%84%E5%BA%8F%E5%88%97"><span class="toc-number">3.1.1.</span> <span class="toc-text">假设我们有以下属性的序列：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rnncell%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%E5%BD%A2%E7%8A%B6"><span class="toc-number">3.1.2.</span> <span class="toc-text">RNNCell 的输入和输出形状</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%8F%E5%88%97%E5%8F%AF%E4%BB%A5%E5%8C%85%E8%A3%85%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%BC%A0%E9%87%8F%E4%B8%AD%E5%BD%A2%E7%8A%B6%E4%B8%BA"><span class="toc-number">3.1.3.</span> <span class="toc-text">序列可以包装在一个张量中，形状为：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.4.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8rnn"><span class="toc-number">3.2.</span> <span class="toc-text">如何使用 RNN？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">3.2.1.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">4.</span> <span class="toc-text">自然语言处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E5%AD%97%E7%AC%A6"><span class="toc-number">4.1.</span> <span class="toc-text">处理字符</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1-2"><span class="toc-number">4.2.</span> <span class="toc-text">代码设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.2.1.</span> <span class="toc-text">模型设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">4.2.2.</span> <span class="toc-text">训练</span></a></li></ol></li></ol></li></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/deep-learning/README_2_Linear%20Classification/" rel="bookmark" title="k-NN最近分类器_Sanfordcs231n">k-NN最近分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_1_KNN/" rel="bookmark" title="线性分类器_Sanfordcs231n">线性分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_3_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="神经网络_Sanfordcs231n">神经网络_Sanfordcs231n</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="bookmark" title="深度学习_1">深度学习_1</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="bookmark" title="深度学习_1_基础知识">深度学习_1_基础知识</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2_%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="深度学习_2_实战">深度学习_2_实战</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3_%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E5%BA%A6%E8%BE%93%E5%85%A5/" rel="bookmark" title="深度学习_3_多维度输入">深度学习_3_多维度输入</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" rel="bookmark" title="深度学习_4_多分类问题">深度学习_4_多分类问题</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_5_CNN/" rel="bookmark" title="深度学习_5_CNN">深度学习_5_CNN</a></li><li class="active"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_GNN/" rel="bookmark" title="深度学习_6_RNN">深度学习_6_RNN</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">64</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">10</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">8</span> <span class="name">tags</span></a></div></nav><div class="social"></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/recommendation/Self-Supervised%20Learning%20for%20Sequential%20Recommendation%20with%20Mutual%20Information%20/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" title="深度学习_4_多分类问题">深度学习_4_多分类问题</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/IntroductiontoNetSecurityLab/" title="In 网安导论实验">网安导论实验</a></div><span><a href="/IntroductiontoNetSecurityLab/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E5%AE%89%E5%85%A8_%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" title="人工智能的后门攻击">人工智能的后门攻击</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/redis-dict.c%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="DICT.C源码阅读报告">DICT.C源码阅读报告</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C/" title="a_统计结果">a_统计结果</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E4%BC%8A%E8%97%A4%E5%BE%AE%E7%A7%AF%E5%88%86/" title="随机过程——运用伊藤微积分对布朗运动进行分析">随机过程——运用伊藤微积分对布朗运动进行分析</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/1_spring-boot-main_Java/" title="1_Java_spring-boot-main">1_Java_spring-boot-main</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/Request%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/" title="Request阅读报告">Request阅读报告</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/1/" title="研究方法">研究方法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEA/" title="In 单片机小学期ECEA">单片机小学期ECEA</a></div><span><a href="/ECEA/4%E4%BA%A7%E7%94%9F%E4%B8%83%E8%89%B2%E7%81%AF/" title="Generate colorful lights">Generate colorful lights</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/shudian/" title="In 数字逻辑实验">数字逻辑实验</a></div><span><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%80/" title="组合逻辑基础模块">组合逻辑基础模块</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"deep-learning/深度学习_6_GNN/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->