<!-- build time:Fri Oct 11 2024 13:06:50 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Enjun Du" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Enjun Du" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Enjun Du" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter"><link rel="canonical" href="https://enjundu.github.io/deep-learning/README_1_KNN/"><title>线性分类器_Sanfordcs231n - deep-learning | 蓝天の网站 = Enjun Du</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">线性分类器_Sanfordcs231n</h1><div class="meta"><span class="item" title="Created: 2024-07-04 14:02:28"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-04T14:02:28+08:00">2024-07-04</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>7.8k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>7 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/03/sTHU7wL5qkSiloC.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/qk7VYGUEtZ2oeyB.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/flquHABaRmV2onx.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/6vserUNHJbOxI4y.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/d8I9raJDhEUebpV.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/pVXxd2rsZPS3RLj.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/deep-learning/" itemprop="item" rel="index" title="In deep-learning"><span itemprop="name">deep-learning</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/deep-learning/README_1_KNN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Enjun Du"></span><div class="body md" itemprop="articleBody"><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NearestNeighbor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></span><br><span class="line">        self.Xtr = X</span><br><span class="line">        self.ytr = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># lets make sure that the output type matches the input type</span></span><br><span class="line">        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># loop over all test rows</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">            <span class="comment"># find the nearest training image to the i&#x27;th test image</span></span><br><span class="line">            <span class="comment"># using the L1 distance (sum of absolute value differences)</span></span><br><span class="line">            distances = np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(self.Xtr - X[i,:]), axis=<span class="number">1</span>)</span><br><span class="line">            min_index = np.argmin(distances)  <span class="comment"># get the index with smallest distance</span></span><br><span class="line">            Ypred[i] = self.ytr[min_index]    <span class="comment"># predict the label of the nearest example</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Ypred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建一些示例数据</span></span><br><span class="line">    Xtr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])  <span class="comment"># 训练数据</span></span><br><span class="line">    ytr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])  <span class="comment"># 训练标签</span></span><br><span class="line"></span><br><span class="line">    Xte = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">7</span>, <span class="number">9</span>]])  <span class="comment"># 测试数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化和训练分类器</span></span><br><span class="line">    nn = NearestNeighbor()</span><br><span class="line">    nn.train(Xtr, ytr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测测试数据的标签</span></span><br><span class="line">    Yte_predict = nn.predict(Xte)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted labels:&#x27;</span>, Yte_predict)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h1 id="本项目参考学习文档为斯坦福计算机深度学习课程用于视觉识别的-cs231n-卷积神经网络"><a class="anchor" href="#本项目参考学习文档为斯坦福计算机深度学习课程用于视觉识别的-cs231n-卷积神经网络">#</a> 本项目参考学习文档为<span class="exturl" data-url="aHR0cHM6Ly9jczIzMW4uZ2l0aHViLmlvL2NsYXNzaWZpY2F0aW9uLw==">斯坦福计算机深度学习课程 —— 用于视觉识别的 CS231n 卷积神经网络</span></h1><p>​	曼哈顿距离：<img data-src="https://s2.loli.net/2024/07/03/4K7NUeW85QBCabV.png" alt="image.png">，其中 I1 和 I2 是两幅图像，I1P 和 I2P 分别是 I1 和 I2 在位置 P 的像素值。差异矩阵也是像素点依次相减。通过衡量图像像素点的绝对值差之和差异性来</p><p>​	对于该预测方法还有 L2 距离，其定义为：<img data-src="https://s2.loli.net/2024/07/03/fovI3tCNOXrB8aQ.png" alt="image.png"></p><p>​	最近临分类器：<br>​	（1）训练：将训练数据存储在实际变量中。<br>​	（2）预测：对每一个测试样本，计算其与训练样本 L1 的距离，找到距离最近的训练样本，将该训练样本的标签作为测试样本的预测标签。<br>​	*<em> 训练方法</em> <em>：def train (self, X, y): X（训练数据，形状为 N</em>D，每一行都是一个样本）和 y（训练标签，大小为 N 的一维数组）, 然后存储在 self 类中。</p><p>​ <code>self.Xtr = X</code></p><p>​ <code>self.ytr = y</code></p><p><strong>预测方法</strong></p><p>predict 方法接受一个参数 x*(测试数据，形状为 N*D，每一行都是一个需要预测的样本)*</p><p>num_test 表示测试样本的数量</p><p>Ypred 初始化为零数组 <code>np.zeros(num_test,dtype=self.ytr.dtype)</code> , 前者表示数组的长度，即为包含元素的个数；后者是一个关键词参数，指定数组中的数据类型设置为与 self.ytr 数组的数据类型相同。dtype 是数据类型的缩写。</p><p>对于每个测试样本，计算它与所有训练样本的 L1 距离：</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distances = np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(self.Xtr - X[i,:]), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p><ul><li>通过取绝对值差的和计算 L1 距离。</li><li><code>self.Xtr - X[i,:]</code> 计算每个训练样本与第 <code>i</code> 个测试样本的差值。(这里 <code>self.Xtr</code> 是一个矩阵， <code>X[i,:]</code> 是一个向量 <code>X[i,:]</code> 表示矩阵 <code>X</code> 的第 <code>i</code> 行)</li><li><code>self.Xtr - X[i,:]</code> 计算的是矩阵 <code>self.Xtr</code> 中的每一行向量减去向量 <code>X[i,:]</code> 的结果。</li><li><code>np.abs(self.Xtr - X[i,:])</code> ：对上述差值矩阵中的每个元素取绝对值，得到一个与 <code>self.Xtr</code> 形状相同的矩阵。</li><li><code>np.sum(..., axis=1)</code> 对每个样本的所有特征求和，得到每个训练样本与该测试样本的距离。</li><li>通过 <code>min_index = np.argmin(distances)</code> 找到距离最小的样本 (<em>np.argmin: 返回最小距离对应的索引</em>)</li></ul><p><strong>Q: With N examples, how fast are training and prediction?</strong></p><ul><li>问题：对于 N 个样本，训练和预测的速度（效率）是多少？</li></ul><p><strong>A: Train O(1), predictO(N)</strong></p><ul><li><p>回答：训练时间复杂度是 O (1)，预测时间复杂度是 O (N)。</p></li><li><p><strong>训练时间复杂度 O (1)</strong>：训练阶段只需记住所有训练数据，不需要复杂计算，所以训练时间是常数时间，即与训练样本的数量 N 无关。</p></li><li><p><strong>预测时间复杂度 O (N)</strong>：预测阶段，对于每个测试样本，需要计算其与所有训练样本的距离，并找到最近的那个训练样本。因此，预测时间与训练样本的数量 N 成正比。</p></li></ul><p><strong>Q:This is bad: we want classifiers that are fast at prediction; slow for training is ok</strong></p><ul><li>为什么这是不好的设计？</li></ul><p><strong>A: 这是不好的设计：我们希望分类器在预测时速度快；在训练时速度慢是可以接受的。</strong></p><ul><li>在实际应用中，预测阶段通常比训练阶段更频繁。例如，一个已经训练好的分类器可能需要处理大量的实时预测请求。如果预测速度很慢，会严重影响系统的性能和用户体验。</li><li>训练阶段可以相对较慢，因为训练通常是一个离线过程，可以在后台完成，不直接影响用户体验。</li></ul><h2 id="总结"><a class="anchor" href="#总结">#</a> 总结</h2><p>​	最近邻分类器的一个主要缺点是它的预测阶段计算量大，对于每个测试样本需要计算其与所有训练样本的距离，因此预测速度较慢。这在需要快速响应的应用中是一个很大的问题，而对于训练阶段的速度要求则相对宽松。因此，更理想的分类器设计是训练阶段可以慢一些，但预测阶段必须非常快。</p><h2 id="k-最近临法"><a class="anchor" href="#k-最近临法">#</a> K - 最近临法</h2><p><img data-src="https://s2.loli.net/2024/07/03/UIrCatE1Zfu5Wib.png" alt="image.png"></p><p>​	图中展示的是 K - 最近邻（K-Nearest Neighbors, K-NN）分类器的基本原理和效果。K-NN 分类器是一个简单但非常有效的分类算法，它的核心思想是根据一个样本的 K 个最近邻居来确定其类别。具体来说，这里通过 K 个最近邻居的多数投票来决定样本的分类。</p><p><strong>白色区域：这个区域没有进行 k - 最近投票</strong></p><p><strong>k=1：</strong></p><ul><li>当 K=1 时，分类器仅考虑与样本最近的一个邻居。这个邻居的类别直接决定了样本的类别。虽然这种方法非常直接和简单，但它容易受噪声和孤立点的影响，导致分类效果不稳定。</li></ul><p><strong>k=3：</strong></p><ul><li>当 K=3 时，分类器考虑与样本最近的三个邻居。样本的类别由这三个邻居的多数投票决定。相比于 K=1，这种方法更加鲁棒，能够更好地抵御噪声的影响。但是，它仍然可能受少数几个错误邻居的影响。</li></ul><p><strong>k=5：</strong></p><ul><li>当 K=5 时，分类器考虑与样本最近的五个邻居。样本的类别由这五个邻居的多数投票决定。进一步增加 K 值，分类器变得更加稳定，因为它综合了更多邻居的信息，减少了单个噪声点对分类结果的影响。然而，如果 K 值过大，分类器可能会包含过多不相关的邻居信息，导致分类结果不准确。</li></ul><h3 id="主要思想"><a class="anchor" href="#主要思想">#</a> 主要思想</h3><ul><li><strong>多数投票</strong>：K-NN 分类器的核心思想是 “多数投票”，即根据 K 个最近邻居中出现频率最高的类别来决定样本的类别。</li><li><strong>距离度量</strong>：K-NN 分类器依赖于距离度量来确定最近的 K 个邻居。常用的距离度量方法包括欧氏距离、曼哈顿距离等。</li><li><strong>参数选择</strong>：K 值的选择对分类效果有重要影响。K 值太小容易受噪声影响，K 值太大则可能引入过多无关信息。</li></ul><h2 id="接下来我们以cifar-10数据集的结果来进行代码编写"><a class="anchor" href="#接下来我们以cifar-10数据集的结果来进行代码编写">#</a> 接下来我们以<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MudG9yb250by5lZHUvfmtyaXovY2lmYXIuaHRtbA=="> CIFAR-10 数据集</span>的结果来进行代码编写</h2><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle  <span class="comment">#用于序列化和反序列化 Python 对象的库。在这里用于加载 CIFAR-10 数据集文件</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_CIFAR_batch</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Load a single batch of CIFAR-10 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#以二进制模式(&#x27;rb&#x27;)打开文件</span></span><br><span class="line">        datadict = pickle.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)  <span class="comment">#使用pickle.load(f,encoding=&#x27;latin1&#x27;)反序列化文件内容，读取为字典对象</span></span><br><span class="line">        X = datadict[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">        Y = datadict[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line">    <span class="comment">#将其从平坦形状(10000,3072)重塑为(10000,32,32,3),并且将数据类型转为浮点型。即10000张图</span></span><br><span class="line">    <span class="comment"># 每张图有32*32像素，每个像素有三个颜色通道</span></span><br><span class="line">    <span class="comment">#并且将像素类型转为浮点数</span></span><br><span class="line">        X = X.reshape(<span class="number">10000</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">        Y = np.array(Y)</span><br><span class="line">        <span class="keyword">return</span> X, Y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_CIFAR10</span>(<span class="params">ROOT</span>): <span class="comment">#ROOT表示CIFAR-10数据集根目录的路径</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Load all of CIFAR-10 &quot;&quot;&quot;</span></span><br><span class="line">    xs = [] <span class="comment">#存储每个批次的图像数据</span></span><br><span class="line">    ys = [] <span class="comment">#存储每个批次的标签</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>): <span class="comment">#加载五个训练批次</span></span><br><span class="line">        f = os.path.join(ROOT, <span class="string">&#x27;data_batch_%d&#x27;</span> % (b,))  <span class="comment">#依次加载文件里的五个批次</span></span><br><span class="line">        X, Y = load_CIFAR_batch(f)  <span class="comment">#调用load_CIFAR_batch（）函数来加载数据</span></span><br><span class="line">        <span class="comment">#将加载的的图像数据和标签分别添加到列表中</span></span><br><span class="line">        xs.append(X)</span><br><span class="line">        ys.append(Y)</span><br><span class="line">    <span class="comment">#将所有训练批次的数据合并为一个训练集</span></span><br><span class="line">    Xtr = np.concatenate(xs)</span><br><span class="line">    Ytr = np.concatenate(ys)</span><br><span class="line">    <span class="keyword">del</span> X, Y    <span class="comment">#释放内存，删除X和Y</span></span><br><span class="line">    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, <span class="string">&#x27;test_batch&#x27;</span>)) <span class="comment">#加载测试批次的数据</span></span><br><span class="line">    <span class="keyword">return</span> Xtr, Ytr, Xte, Yte</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">Xtr, Ytr, Xte, Yte = load_CIFAR10(<span class="string">r&#x27;D:\desktop\Code_Compiling\cs231n_stanford\example&amp;tests\cifar-10-python\cifar-10-batches-py&#x27;</span>)</span><br><span class="line"><span class="comment"># 将数据拉成向量</span></span><br><span class="line"><span class="comment">#重塑数据：将训练数据 Xtr 和测试数据 Xte 从形状（num_samples, 32, 32, 3）转换为（num_samples, 3072）的向量形式</span></span><br><span class="line"><span class="comment"># 其中 3072 是 32x32 图像的像素总数乘以 3 个颜色通道。</span></span><br><span class="line">Xtr_rows = Xtr.reshape(Xtr.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>)</span><br><span class="line">Xte_rows = Xte.reshape(Xte.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据加载和预处理完成&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NearestNeighbor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>): <span class="comment">#初始化</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):  <span class="comment">#该方法用于训练k-NN模型，将x和y存储为类的属性</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span></span><br><span class="line">        self.Xtr = X    <span class="comment">#X是N*D的矩阵，每行是一个训练样本</span></span><br><span class="line">        self.ytr = y    <span class="comment">#y是一个长度为N的一维数组，对应于每个训练样本的标签</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#预测给定的数据集x的标签,X是N*D的矩阵，每行都是一个测试样本</span></span><br><span class="line">    <span class="comment">#k是要考虑的最近邻居的数量，默认为1。distfn是距离度量方式，可以是：L1(曼哈顿距离)也可以是L2(欧几里得距离)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, k=<span class="number">1</span>, distfn=<span class="string">&#x27;L1&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]   <span class="comment">#这是测试集的样本数量</span></span><br><span class="line">        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)    <span class="comment">#初始化为一个零数组，用于存储每个测试样本的预测标签</span></span><br><span class="line">        <span class="comment">#循环处理每个测试样本</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">            <span class="keyword">if</span> distfn == <span class="string">&#x27;L1&#x27;</span>:</span><br><span class="line">                distances = np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(self.Xtr - X[i,:]), axis=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> distfn == <span class="string">&#x27;L2&#x27;</span>:</span><br><span class="line">                distances = np.sqrt(np.<span class="built_in">sum</span>(np.square(self.Xtr - X[i,:]), axis=<span class="number">1</span>))</span><br><span class="line">            min_indices = np.argpartition(distances, k)[:k] <span class="comment">#找到k个最近邻居的索引</span></span><br><span class="line">            closest_y = self.ytr[min_indices]</span><br><span class="line">            <span class="comment">#预测标签</span></span><br><span class="line">            <span class="comment">#使用 np.bincount 统计最近邻居中每个标签的出现次数，并选择出现次数最多的标签作为预测标签。</span></span><br><span class="line">            Ypred[i] = np.bincount(closest_y).argmax()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Ypred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练和评估模型</span></span><br><span class="line">nn = NearestNeighbor()  <span class="comment">#创建 NearestNeighbor 类的实例 nn。</span></span><br><span class="line">nn.train(Xtr_rows, Ytr) <span class="comment">#使用训练数据 Xtr_rows 和标签 Ytr 训练模型。</span></span><br><span class="line">Yte_predict = nn.predict(Xte_rows)  <span class="comment">#使用测试数据 Xte_rows 预测标签。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;accuracy: %f&#x27;</span> % (np.mean(Yte_predict == Yte)))   <span class="comment">#计算并打印预测标签与真实标签的匹配率（准确率）。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建验证集——从训练集中提取前1000个样本作为验证集</span></span><br><span class="line">Xval_rows = Xtr_rows[:<span class="number">1000</span>, :]  <span class="comment">#验证集特征</span></span><br><span class="line">Yval = Ytr[:<span class="number">1000</span>]   <span class="comment">#验证集标签</span></span><br><span class="line">Xtr_rows = Xtr_rows[<span class="number">1000</span>:, :]   <span class="comment">#新训练集特征</span></span><br><span class="line">Ytr = Ytr[<span class="number">1000</span>:]    <span class="comment">#新训练集标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数调优——对于不同的k和距离度量方式进行超参数调优</span></span><br><span class="line">validation_accuracies = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]:</span><br><span class="line">    <span class="keyword">for</span> distfn <span class="keyword">in</span> [<span class="string">&#x27;L1&#x27;</span>, <span class="string">&#x27;L2&#x27;</span>]:</span><br><span class="line">        nn = NearestNeighbor()  <span class="comment">#创建NearestNeighbor实例</span></span><br><span class="line">        nn.train(Xtr_rows, Ytr) <span class="comment">#训练</span></span><br><span class="line">        Yval_predict = nn.predict(Xval_rows, k=k, distfn=distfn)    <span class="comment">#预测</span></span><br><span class="line">        acc = np.mean(Yval_predict == Yval) <span class="comment">#验证</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;accuracy for k=<span class="subst">&#123;k&#125;</span>, distfn=<span class="subst">&#123;distfn&#125;</span>: <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br><span class="line">        validation_accuracies.append((k, distfn, acc))</span><br><span class="line"><span class="comment">#交叉验证函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_validation</span>(<span class="params">X, y, k_choices, distfns</span>):</span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>)  <span class="comment">#将数据集分成五份</span></span><br><span class="line">    validation_accuracies = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> k_choices: <span class="comment">#对每个k和distfns组合进行操作</span></span><br><span class="line">        <span class="keyword">for</span> distfn <span class="keyword">in</span> distfns:</span><br><span class="line">            accs = []   <span class="comment">#初始化一个空列表 accs 用于存储交叉验证的准确率</span></span><br><span class="line">            <span class="keyword">for</span> train_index, val_index <span class="keyword">in</span> kf.split(X):</span><br><span class="line">                X_train, X_val = X[train_index], X[val_index] <span class="comment">#将数据分为训练集和验证集。</span></span><br><span class="line">                y_train, y_val = y[train_index], y[val_index]</span><br><span class="line"></span><br><span class="line">                nn = NearestNeighbor()</span><br><span class="line">                nn.train(X_train, y_train)</span><br><span class="line">                y_val_predict = nn.predict(X_val, k=k, distfn=distfn)</span><br><span class="line">                acc = np.mean(y_val_predict == y_val) <span class="comment">#用验证集进行预测并计算准确率。</span></span><br><span class="line">                accs.append(acc)</span><br><span class="line">            avg_acc = np.mean(accs)<span class="comment">#计算并打印每个 k 和 distfn 组合的平均准确率。</span></span><br><span class="line">            validation_accuracies.append((k, distfn, avg_acc))<span class="comment">#将 k、distfn 和平均准确率保存到 validation_accuracies 列表中。</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Cross-validation accuracy for k=<span class="subst">&#123;k&#125;</span>, distfn=<span class="subst">&#123;distfn&#125;</span>: <span class="subst">&#123;avg_acc&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> validation_accuracies</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用交叉验证</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">distfns = [<span class="string">&#x27;L1&#x27;</span>, <span class="string">&#x27;L2&#x27;</span>]</span><br><span class="line">validation_accuracies = cross_validation(Xtr_rows, Ytr, k_choices, distfns)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><p><strong>k-NN 阶段实现了一个简单的 k 近邻（k-Nearest Neighbors, k-NN）分类器，使用了 L1 距离（曼哈顿距离）和 L2 距离（欧几里得距离）</strong></p><p><strong>代码注释已列与代码中</strong></p><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-08-09 19:50:13" itemprop="dateModified" datetime="2024-08-09T19:50:13+08:00">2024-08-09</time> </span><span id="deep-learning/README_1_KNN/" class="item leancloud_visitors" data-flag-title="线性分类器_Sanfordcs231n" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Enjun Du</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/deep-learning/README_1_KNN/" title="线性分类器_Sanfordcs231n">https://enjundu.github.io/deep-learning/README_1_KNN/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/deep-learning/README_2_Linear%20Classification/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;f5ySCsjMgUO27Yh.jpg" title="k-NN最近分类器_Sanfordcs231n"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> deep-learning</span><h3>k-NN最近分类器_Sanfordcs231n</h3></a></div><div class="item right"><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%80/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;As6g8SnCP2tGRDm.jpg" title="组合逻辑基础模块"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> 数字逻辑实验</span><h3>组合逻辑基础模块</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%AC%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3%E4%B8%BA%E6%96%AF%E5%9D%A6%E7%A6%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%94%A8%E4%BA%8E%E8%A7%86%E8%A7%89%E8%AF%86%E5%88%AB%E7%9A%84-cs231n-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">本项目参考学习文档为斯坦福计算机深度学习课程 —— 用于视觉识别的 CS231n 卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.1.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k-%E6%9C%80%E8%BF%91%E4%B8%B4%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">K - 最近临法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%80%9D%E6%83%B3"><span class="toc-number">1.2.1.</span> <span class="toc-text">主要思想</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A5%E4%B8%8B%E6%9D%A5%E6%88%91%E4%BB%AC%E4%BB%A5cifar-10%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%BB%93%E6%9E%9C%E6%9D%A5%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99"><span class="toc-number">1.3.</span> <span class="toc-text">接下来我们以 CIFAR-10 数据集的结果来进行代码编写</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li class="active"><a href="/deep-learning/README_1_KNN/" rel="bookmark" title="线性分类器_Sanfordcs231n">线性分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_2_Linear%20Classification/" rel="bookmark" title="k-NN最近分类器_Sanfordcs231n">k-NN最近分类器_Sanfordcs231n</a></li><li><a href="/deep-learning/README_3_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="神经网络_Sanfordcs231n">神经网络_Sanfordcs231n</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="bookmark" title="深度学习_1_基础知识">深度学习_1_基础知识</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="bookmark" title="深度学习_1">深度学习_1</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_9_GNN/" rel="bookmark" title="深度学习_9_GNN">深度学习_9_GNN</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_8_%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="深度学习_8_图神经网络">深度学习_8_图神经网络</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2_%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="深度学习_2_实战">深度学习_2_实战</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3_%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E5%BA%A6%E8%BE%93%E5%85%A5/" rel="bookmark" title="深度学习_3_多维度输入">深度学习_3_多维度输入</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_5_CNN/" rel="bookmark" title="深度学习_5_CNN">深度学习_5_CNN</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_4_%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/" rel="bookmark" title="深度学习_4_多分类问题">深度学习_4_多分类问题</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_6_RNN/" rel="bookmark" title="深度学习_6_RNN">深度学习_6_RNN</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_7_Transformer/" rel="bookmark" title="深度学习_7_Transformer">深度学习_7_Transformer</a></li><li><a href="/deep-learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_10_GNN/" rel="bookmark" title="深度学习_10_图神经网络">深度学习_10_图神经网络</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">85</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">12</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">14</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0VuanVuRHU=" title="https:&#x2F;&#x2F;github.com&#x2F;EnjunDu"><i class="ic i-github"></i></span> <a href="/enjundu.cs@gmail.com" title="enjundu.cs@gmail.com" class="item email"><i class="ic i-envelope"></i></a></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/deep-learning/README_2_Linear%20Classification/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%80/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/00_Java_basic_knowledge/" title="0_Java_basic_knowledge">0_Java_basic_knowledge</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E6%95%B0%E5%AD%97%E7%BB%8F%E6%B5%8E%EF%BC%9A%E7%A7%91%E6%8A%80%E5%88%9B%E6%96%B0%E5%92%8C%E4%BC%81%E4%B8%9A%E8%BD%AC%E5%9E%8B_%E9%80%9A%E8%AF%86%E7%BB%93%E8%AF%BE%E8%AE%BA%E6%96%87/" title="数字经济：科技创新和企业转型_通识结课论文">数字经济：科技创新和企业转型_通识结课论文</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/IntroductiontoNetSecurityLab/" title="In 网安导论实验">网安导论实验</a></div><span><a href="/IntroductiontoNetSecurityLab/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/" title="隐私保护">隐私保护</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/nlp/" title="In Nature-Language-Process">Nature-Language-Process</a></div><span><a href="/nlp/01_%E8%AF%BE%E7%A8%8B%E4%BB%8B%E7%BB%8D%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F/" title="01_Introduction to the course and word vectors">01_Introduction to the course and word vectors</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/redis-dict.c%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="DICT.C源码阅读报告">DICT.C源码阅读报告</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEA/" title="In 单片机小学期ECEA">单片机小学期ECEA</a></div><span><a href="/ECEA/1%E7%82%B9%E4%BA%AE%E7%81%AF/" title="LED lighting program">LED lighting program</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/README/" title="a_README">a_README</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/5_giskard-main/" title="Giskard-AI&#x2F;giskard">Giskard-AI/giskard</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/IntroductiontoNetSecurityLab/" title="In 网安导论实验">网安导论实验</a></div><span><a href="/IntroductiontoNetSecurityLab/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E5%AE%89%E5%85%A8_%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" title="人工智能的后门攻击">人工智能的后门攻击</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/8_pytorch-lr-finder-master/" title="pytorch-lr-finder">pytorch-lr-finder</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">1.2m words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">17:49</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"deep-learning/README_1_KNN/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->