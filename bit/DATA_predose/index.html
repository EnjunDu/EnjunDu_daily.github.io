



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Hexo" href="https://enjundu.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Hexo" href="https://enjundu.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="Hexo" href="https://enjundu.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="Hexo,Front Matter,code,recommendation" />


<link rel="canonical" href="https://enjundu.github.io/bit/DATA_predose/">



  <title>
亚太数模 —— 洪水 - BIT-study |
蓝天° = Hexo</title>
<meta name="generator" content="Hexo 7.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">亚太数模 —— 洪水
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2024-07-04 22:49:23">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2024-07-04T22:49:23+08:00">2024-07-04</time>
  </span>
  <span class="item" title="Symbols count in article">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">Symbols count in article</span>
    <span>31k</span>
    <span class="text">words</span>
  </span>
  <span class="item" title="Reading time">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">Reading time</span>
    <span>28 mins.</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">蓝天°</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/04/pVXxd2rsZPS3RLj.jpg"></li>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/04/ArOLs3qhENaXcUV.jpg"></li>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/03/6vserUNHJbOxI4y.gif"></li>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/03/sTHU7wL5qkSiloC.jpg"></li>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/04/cI2aroK5AZfHs7U.jpg"></li>
          <li class="item" data-background-image="https://s2.loli.net/2024/07/03/qk7VYGUEtZ2oeyB.gif"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">Home</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/bit/" itemprop="item" rel="index" title="In BIT-study"><span itemprop="name">BIT-study</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="https://enjundu.github.io/bit/DATA_predose/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/avatar.jpg">
    <meta itemprop="name" content="Jack Du">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Hexo">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h2 id="before-problem-数据传入与预处理全局函数设置"><a class="markdownIt-Anchor" href="#before-problem-数据传入与预处理全局函数设置">#</a> Before Problem – 数据传入与预处理，全局函数设置</h2>
<h3 id="导入必要的库"><a class="markdownIt-Anchor" href="#导入必要的库">#</a> 导入必要的库</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">u&#x27;simHei&#x27;</span>]   <span class="comment"># 显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>      <span class="comment"># 解决负号问题</span></span><br></pre></td></tr></table></figure>
<h3 id="数据读入"><a class="markdownIt-Anchor" href="#数据读入">#</a> 数据读入</h3>
<h4 id="从traincsv读入train数据"><a class="markdownIt-Anchor" href="#从traincsv读入train数据">#</a> 从 train.csv 读入 train 数据</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br></pre></td></tr></table></figure>
<h3 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理">#</a> 数据预处理</h3>
<p>id 列对于数据分析没有用处，直接清洗掉这一列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>经检验，原始数据中不存在缺失值与明显的离群点，因此在这里全部保留<br>
将 ‘洪水概率’ 设置为目标变量，将原始数据划分为 X，y</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br></pre></td></tr></table></figure>
<h3 id="数据相关性简要分析"><a class="markdownIt-Anchor" href="#数据相关性简要分析">#</a> 数据相关性简要分析</h3>
<p>利用不同指标与洪水概率的相关系数来衡量这些指标与洪水概率的关系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">&#x27;洪水概率&#x27;</span>]=y</span><br><span class="line">heat_corr = train_data.corr()[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">heat_corr_sorted=heat_corr.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">heat_corr=heat_corr[:-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>可视化相关系数图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">heat_corr.plot(kind=<span class="string">&#x27;bar&#x27;</span>, color=<span class="string">&#x27;skyblue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;不同因素对洪水概率的影响&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;影响因素&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;corr&#x27;</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="建立三个水平的指标集"><a class="markdownIt-Anchor" href="#建立三个水平的指标集">#</a> 建立三个水平的指标集</h3>
<pre><code>20： 全指标

10：半指标

5：核心指标

划分依据: 相关系数大小
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">heat_corr_sorted=heat_corr_sorted[<span class="number">1</span>:<span class="number">11</span>]</span><br><span class="line">ten_columns=heat_corr_sorted.index.<span class="built_in">str</span>.split().<span class="built_in">str</span>[<span class="number">0</span>]</span><br><span class="line">five_columns=heat_corr_sorted[:<span class="number">5</span>].index.<span class="built_in">str</span>.split().<span class="built_in">str</span>[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h3 id="全局函数设置"><a class="markdownIt-Anchor" href="#全局函数设置">#</a> 全局函数设置</h3>
<p>建立余弦相似度的计算函数<br>
 cosine (a,b)<br>
 input : 向量 A，B</p>
<pre><code>output : 两个向量的余弦相似度 0-1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cosine</span>(<span class="params">a,b</span>):</span><br><span class="line">    dot_product = np.dot(a, b)</span><br><span class="line">    norm_a = np.linalg.norm(a)</span><br><span class="line">    norm_b = np.linalg.norm(b)</span><br><span class="line">    cosine_similarity = dot_product / (norm_a * norm_b) </span><br><span class="line">    <span class="keyword">return</span> cosine_similarity</span><br></pre></td></tr></table></figure>
<h3 id="划分训练集与测试集"><a class="markdownIt-Anchor" href="#划分训练集与测试集">#</a> 划分训练集与测试集</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h2 id="problem-one-全指标集数学模型建立与求解"><a class="markdownIt-Anchor" href="#problem-one-全指标集数学模型建立与求解">#</a> Problem ONE – 全指标集数学模型建立与求解</h2>
<pre><code>利用多种数学模型拟合本问题，并得出不同指标的权重
多元线性回归
梯度提升树
决策树
随机森林模型
</code></pre>
<h3 id="模型一-线性回归"><a class="markdownIt-Anchor" href="#模型一-线性回归">#</a> 模型一 线性回归</h3>
<pre><code>原理：利用标准方程法求解线性方程组
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(model_line,<span class="string">&#x27;../Model/linear.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">8444528508563269</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">0004043169737229802</span></span><br><span class="line">模型的系数为: [<span class="number">0.00560656</span> <span class="number">0.00564613</span> <span class="number">0.00565985</span> <span class="number">0.00567684</span> <span class="number">0.00565284</span> <span class="number">0.0056578</span></span><br><span class="line"> <span class="number">0.00565561</span> <span class="number">0.00564293</span> <span class="number">0.0056437</span>  <span class="number">0.0056492</span>  <span class="number">0.00564238</span> <span class="number">0.0056413</span></span><br><span class="line"> <span class="number">0.005674</span>   <span class="number">0.00564575</span> <span class="number">0.0056467</span>  <span class="number">0.00562068</span> <span class="number">0.00568107</span> <span class="number">0.00563092</span></span><br><span class="line"> <span class="number">0.00561738</span> <span class="number">0.00564302</span>]</span><br><span class="line">模型的截距为: -<span class="number">0</span>.<span class="number">053357024379501294</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9992129608069907</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="模型二-梯度提升树"><a class="markdownIt-Anchor" href="#模型二-梯度提升树">#</a> 模型二 梯度提升树</h3>
<pre><code>原理：递归的决策树，能发现更深层的变量关系
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">n_estimators = <span class="number">1200</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(gb_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances)), feature_importances, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">joblib.dump(gb_model,<span class="string">&#x27;../Model/gb_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">每折交叉验证的评分: [<span class="number">0.84262125</span> <span class="number">0.84055718</span> <span class="number">0.84249464</span> <span class="number">0.84247138</span> <span class="number">0.84228929</span>]</span><br><span class="line">Model Score : <span class="number">0</span>.<span class="number">8414966684722095</span></span><br><span class="line">特征重要性: [<span class="number">0.05053843</span> <span class="number">0.0513698</span>  <span class="number">0.05097438</span> <span class="number">0.04985333</span> <span class="number">0.04968169</span> <span class="number">0.0498542</span></span><br><span class="line"> <span class="number">0.05148326</span> <span class="number">0.05025949</span> <span class="number">0.04944183</span> <span class="number">0.04878379</span> <span class="number">0.04970291</span> <span class="number">0.04908077</span></span><br><span class="line"> <span class="number">0.0490136</span>  <span class="number">0.05042491</span> <span class="number">0.04939282</span> <span class="number">0.05113171</span> <span class="number">0.05085744</span> <span class="number">0.04953673</span></span><br><span class="line"> <span class="number">0.04897519</span> <span class="number">0.04964374</span>]</span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9991979970651009</span></span><br><span class="line">均方误差为<span class="number">0</span>.<span class="number">00041200104072066957</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="模型三-决策树"><a class="markdownIt-Anchor" href="#模型三-决策树">#</a> 模型三 决策树</h3>
<pre><code>原理：利用信息增益实现节点的划分
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(tree_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证评分的平均值:&quot;</span>, np.mean(cv_scores))</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(tree_model,<span class="string">&#x27;../Model/ju_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">每折交叉验证的评分: [<span class="number">0.04694866</span> <span class="number">0.04297524</span> <span class="number">0.0450139</span>  <span class="number">0.04790429</span> <span class="number">0.04502323</span>]</span><br><span class="line">交叉验证评分的平均值: <span class="number">0</span>.<span class="number">045573064737767635</span></span><br><span class="line">Model Score : <span class="number">0</span>.<span class="number">05301513744804842</span></span><br><span class="line">特征重要性: [<span class="number">0.05072873</span> <span class="number">0.04679774</span> <span class="number">0.04822921</span> <span class="number">0.0498514</span>  <span class="number">0.05054892</span> <span class="number">0.05003494</span></span><br><span class="line"> <span class="number">0.04871661</span> <span class="number">0.0509244</span>  <span class="number">0.05185402</span> <span class="number">0.04976417</span> <span class="number">0.04994974</span> <span class="number">0.0515037</span></span><br><span class="line"> <span class="number">0.05054295</span> <span class="number">0.05088047</span> <span class="number">0.04947362</span> <span class="number">0.04914221</span> <span class="number">0.04920693</span> <span class="number">0.0502652</span></span><br><span class="line"> <span class="number">0.05116479</span> <span class="number">0.05042025</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">余弦相似度为0.9952026345820846</span><br><span class="line">均方误差为0.0024615176549126197</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="模型四-随机森林"><a class="markdownIt-Anchor" href="#模型四-随机森林">#</a> 模型四 随机森林</h3>
<pre><code>原理： 抽样决策树并使用投票策略
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>) </span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r2_score(y_test, y_pred))</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(rf,<span class="string">&#x27;../Model/rf_forest.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">6559609909975268</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">000894267826368524</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9982658517029762</span></span><br><span class="line">准确率:</span><br><span class="line"><span class="number">0</span>.<span class="number">6559609909975268</span></span><br><span class="line">特征重要性: [<span class="number">0.05020068</span> <span class="number">0.04813886</span> <span class="number">0.04897409</span> <span class="number">0.05041827</span> <span class="number">0.05079291</span> <span class="number">0.05009829</span></span><br><span class="line"> <span class="number">0.04924856</span> <span class="number">0.050444</span>   <span class="number">0.05074958</span> <span class="number">0.05022871</span> <span class="number">0.04958712</span> <span class="number">0.05085425</span></span><br><span class="line"> <span class="number">0.05060721</span> <span class="number">0.05060514</span> <span class="number">0.04969013</span> <span class="number">0.04885388</span> <span class="number">0.04925186</span> <span class="number">0.05013874</span></span><br><span class="line"> <span class="number">0.0504078</span>  <span class="number">0.05070993</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="problem-two-风险聚类"><a class="markdownIt-Anchor" href="#problem-two-风险聚类">#</a> Problem TWO 风险聚类</h2>
<h3 id="读入数据"><a class="markdownIt-Anchor" href="#读入数据">#</a> 读入数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br></pre></td></tr></table></figure>
<h3 id="聚类算法kmeans"><a class="markdownIt-Anchor" href="#聚类算法kmeans">#</a> 聚类算法：Kmeans</h3>
<pre><code>原理: 利用n维空间距离对初始聚类中心进行学习，得到最终聚类中心
</code></pre>
<h4 id="聚类预测函数"><a class="markdownIt-Anchor" href="#聚类预测函数">#</a> 聚类预测函数</h4>
<pre><code>predict_cluster(kmeans,points)
input: kmeans模型 points需要预测的点集
output: 点集的预测结果
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_cluster</span>(<span class="params">kmeans, points</span>):</span><br><span class="line">    points = np.array(points)</span><br><span class="line">    points = points.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    cluster_label = kmeans.predict(points)</span><br><span class="line">    <span class="keyword">return</span> cluster_label</span><br></pre></td></tr></table></figure>
<h4 id="建立kmeans模型"><a class="markdownIt-Anchor" href="#建立kmeans模型">#</a> 建立 Kmeans 模型</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line"><span class="comment">#y=-np.log(1/y-1)</span></span><br><span class="line">data=np.array(y)</span><br><span class="line">data_2d = data.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line">kmeans.fit(data_2d)</span><br><span class="line">cluster_centers = kmeans.cluster_centers_</span><br><span class="line"><span class="built_in">print</span>(cluster_centers)</span><br></pre></td></tr></table></figure>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f:\a\envs\env\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The<span class="built_in"> default </span>value of `n_init` will change <span class="keyword">from</span> 10 <span class="keyword">to</span> <span class="string">&#x27;auto&#x27;</span> <span class="keyword">in</span> 1.4. <span class="built_in">Set</span> the value of `n_init` explicitly <span class="keyword">to</span> suppress the <span class="built_in">warning</span></span><br><span class="line">  warnings.warn(</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[0.56840101]</span></span><br><span class="line"><span class="string"> [0.44612593]</span></span><br><span class="line"><span class="string"> [0.50701183]]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="建立聚类中心到风险的映射字典"><a class="markdownIt-Anchor" href="#建立聚类中心到风险的映射字典">#</a> 建立聚类中心到风险的映射字典</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">temp = np.array(cluster_centers)</span><br><span class="line">indices= np.argsort(temp,axis=<span class="number">0</span>)</span><br><span class="line">dic=&#123;&#125;</span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">0</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;低风险&#x27;</span></span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">1</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;中风险&#x27;</span></span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">2</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;高风险&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="示例"><a class="markdownIt-Anchor" href="#示例">#</a> 示例</h4>
<p>data= [0.55,0.99,0.51,0.42]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data= [<span class="number">0.55</span>,<span class="number">0.99</span>,<span class="number">0.51</span>,<span class="number">0.42</span>]</span><br><span class="line"><span class="built_in">print</span>(predict_cluster(kmeans,data))</span><br></pre></td></tr></table></figure>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[0 0 2 1]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="基于风险预警的预测模型"><a class="markdownIt-Anchor" href="#基于风险预警的预测模型">#</a> 基于风险预警的预测模型</h3>
<h4 id="模型建立-mymodel"><a class="markdownIt-Anchor" href="#模型建立-mymodel">#</a> 模型建立 MyModel</h4>
<pre><code>内核    ：某一个概率预测模型与kmeans聚类模型
predict : 预测输入的X对应的y的风险类别
score   : 利用预测成功的比例衡量得分
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model,kmeans</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.model = model</span><br><span class="line">        self.kmeans = kmeans</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X_test</span>) -&gt; np.ndarray:</span><br><span class="line">        y_pred=self.model.predict(X_test)</span><br><span class="line">        y_pred=np.array(y_pred)</span><br><span class="line">        y_pred=predict_cluster(kmeans,y_pred)</span><br><span class="line">        y_pred=np.array(y_pred)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self,X_test,y_test</span>):</span><br><span class="line">        y_pred=self.predict(X_test)</span><br><span class="line">        y_test = np.array(y_test)</span><br><span class="line">        y_true=predict_cluster(kmeans,y_test)</span><br><span class="line">        correct_predictions = np.<span class="built_in">sum</span>(y_pred == y_true)</span><br><span class="line">        overlap = correct_predictions / y_pred.size</span><br><span class="line">        <span class="keyword">return</span> overlap</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="数据读入-2"><a class="markdownIt-Anchor" href="#数据读入-2">#</a> 数据读入</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data=train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h4 id="模型训练"><a class="markdownIt-Anchor" href="#模型训练">#</a> 模型训练</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">models = [<span class="string">&#x27;linear.pkl&#x27;</span>,<span class="string">&#x27;gb_tree.pkl&#x27;</span>,<span class="string">&#x27;ju_tree.pkl&#x27;</span>,<span class="string">&#x27;rf_forest.pkl&#x27;</span>]</span><br><span class="line">path = <span class="string">&#x27;../Model&#x27;</span></span><br><span class="line">m_path=<span class="string">&#x27;../Model/3_means&#x27;</span></span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    model_name=model.replace(<span class="string">&#x27;.pkl&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;当前模型为<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    model_path=os.path.join(path,model)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    model = MyModel(model,kmeans)</span><br><span class="line">    <span class="comment"># 这里可以加入模型的预测过程</span></span><br><span class="line">    y_pred = model.predict(X_test)</span><br><span class="line">    <span class="built_in">print</span>(y_pred)</span><br><span class="line">    y_true=predict_cluster(kmeans,y_test)</span><br><span class="line">    mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">    score = model.score(X_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">    accuracy = cosine(y_true,y_pred)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;不同指标的权重为&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(model.model.coef_)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;不同指标的权重为&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(model.model.feature_importances_)</span><br><span class="line">    joblib.dump(model,m_path+<span class="string">&#x27;/&#x27;</span>+model_name+<span class="string">&#x27;.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">当前模型为linear.pkl</span><br><span class="line">[<span class="number">2</span> <span class="number">1</span> <span class="number">2</span> ... <span class="number">2</span> <span class="number">0</span> <span class="number">2</span>]</span><br><span class="line">Model score: <span class="number">0</span>.<span class="number">7317788427151134</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">5221944066948001</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">8803888726908916</span></span><br><span class="line">不同指标的权重为</span><br><span class="line">[<span class="number">0.00560656</span> <span class="number">0.00564613</span> <span class="number">0.00565985</span> <span class="number">0.00567684</span> <span class="number">0.00565284</span> <span class="number">0.0056578</span></span><br><span class="line"> <span class="number">0.00565561</span> <span class="number">0.00564293</span> <span class="number">0.0056437</span>  <span class="number">0.0056492</span>  <span class="number">0.00564238</span> <span class="number">0.0056413</span></span><br><span class="line"> <span class="number">0.005674</span>   <span class="number">0.00564575</span> <span class="number">0.0056467</span>  <span class="number">0.00562068</span> <span class="number">0.00568107</span> <span class="number">0.00563092</span></span><br><span class="line"> <span class="number">0.00561738</span> <span class="number">0.00564302</span>]</span><br><span class="line">当前模型为gb_tree.pkl</span><br><span class="line">[<span class="number">2</span> <span class="number">1</span> <span class="number">2</span> ... <span class="number">2</span> <span class="number">0</span> <span class="number">2</span>]</span><br><span class="line">Model score: <span class="number">0</span>.<span class="number">7343871444579548</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">5196004100803472</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">880265047613983</span></span><br><span class="line">不同指标的权重为</span><br><span class="line">[<span class="number">0.05053843</span> <span class="number">0.0513698</span>  <span class="number">0.05097438</span> <span class="number">0.04985333</span> <span class="number">0.04968169</span> <span class="number">0.0498542</span></span><br><span class="line"> <span class="number">0.05148326</span> <span class="number">0.05025949</span> <span class="number">0.04944183</span> <span class="number">0.04878379</span> <span class="number">0.04970291</span> <span class="number">0.04908077</span></span><br><span class="line"> <span class="number">0.0490136</span>  <span class="number">0.05042491</span> <span class="number">0.04939282</span> <span class="number">0.05113171</span> <span class="number">0.05085744</span> <span class="number">0.04953673</span></span><br><span class="line"> <span class="number">0.04897519</span> <span class="number">0.04964374</span>]</span><br><span class="line">当前模型为ju_tree.pkl</span><br><span class="line">[<span class="number">2</span> <span class="number">1</span> <span class="number">1</span> ... <span class="number">1</span> <span class="number">0</span> <span class="number">2</span>]</span><br><span class="line">Model score: <span class="number">0</span>.<span class="number">4960875473857378</span></span><br><span class="line">均方误差为: <span class="number">1</span>.<span class="number">077290608683213</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">7375760993349438</span></span><br><span class="line">不同指标的权重为</span><br><span class="line">[<span class="number">0.05072873</span> <span class="number">0.04679774</span> <span class="number">0.04822921</span> <span class="number">0.0498514</span>  <span class="number">0.05054892</span> <span class="number">0.05003494</span></span><br><span class="line"> <span class="number">0.04871661</span> <span class="number">0.0509244</span>  <span class="number">0.05185402</span> <span class="number">0.04976417</span> <span class="number">0.04994974</span> <span class="number">0.0515037</span></span><br><span class="line"> <span class="number">0.05054295</span> <span class="number">0.05088047</span> <span class="number">0.04947362</span> <span class="number">0.04914221</span> <span class="number">0.04920693</span> <span class="number">0.0502652</span></span><br><span class="line"> <span class="number">0.05116479</span> <span class="number">0.05042025</span>]</span><br><span class="line">当前模型为rf_forest.pkl</span><br><span class="line">[<span class="number">2</span> <span class="number">2</span> <span class="number">2</span> ... <span class="number">2</span> <span class="number">0</span> <span class="number">2</span>]</span><br><span class="line">Model score: <span class="number">0</span>.<span class="number">6358057363564839</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">825391602889636</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">8551008397005384</span></span><br><span class="line">不同指标的权重为</span><br><span class="line">[<span class="number">0.05020068</span> <span class="number">0.04813886</span> <span class="number">0.04897409</span> <span class="number">0.05041827</span> <span class="number">0.05079291</span> <span class="number">0.05009829</span></span><br><span class="line"> <span class="number">0.04924856</span> <span class="number">0.050444</span>   <span class="number">0.05074958</span> <span class="number">0.05022871</span> <span class="number">0.04958712</span> <span class="number">0.05085425</span></span><br><span class="line"> <span class="number">0.05060721</span> <span class="number">0.05060514</span> <span class="number">0.04969013</span> <span class="number">0.04885388</span> <span class="number">0.04925186</span> <span class="number">0.05013874</span></span><br><span class="line"> <span class="number">0.0504078</span>  <span class="number">0.05070993</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="模型灵敏度分析"><a class="markdownIt-Anchor" href="#模型灵敏度分析">#</a> 模型灵敏度分析</h3>
<pre><code>利用结果的熵值来衡量模型的灵敏度
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="设置熵的计算函数-calculate_entropy"><a class="markdownIt-Anchor" href="#设置熵的计算函数-calculate_entropy">#</a> 设置熵的计算函数 calculate_entropy</h4>
<pre><code>input: list
ouput :总熵
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_entropy</span>(<span class="params">lst</span>):</span><br><span class="line">    value_counts = np.unique(lst, return_counts=<span class="literal">True</span>)</span><br><span class="line">    values, counts = value_counts</span><br><span class="line">    total_count = <span class="built_in">len</span>(lst)</span><br><span class="line">    probabilities = counts / total_count</span><br><span class="line">    entropy = -np.<span class="built_in">sum</span>(probabilities * np.log2(probabilities))</span><br><span class="line">    <span class="keyword">return</span> entropy</span><br></pre></td></tr></table></figure>
<h4 id="设置基于属性变化率的计算函数-average_change_rate"><a class="markdownIt-Anchor" href="#设置基于属性变化率的计算函数-average_change_rate">#</a> 设置基于属性变化率的计算函数 average_change_rate</h4>
<pre><code>input:list
output: 平均相邻变化率
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">average_change_rate</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="comment"># 检查列表是否至少有两项</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    change_rates = [(lst[i+<span class="number">1</span>] - lst[i]) / lst[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst) - <span class="number">1</span>)]</span><br><span class="line">    avg_change_rate = <span class="built_in">sum</span>(change_rates) / <span class="built_in">len</span>(change_rates)</span><br><span class="line">    <span class="keyword">return</span> avg_change_rate</span><br></pre></td></tr></table></figure>
<h4 id="启动基于熵值的灵敏度计算"><a class="markdownIt-Anchor" href="#启动基于熵值的灵敏度计算">#</a> 启动基于熵值的灵敏度计算</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">models = [<span class="string">&#x27;linear.pkl&#x27;</span>,<span class="string">&#x27;gb_tree.pkl&#x27;</span>,<span class="string">&#x27;ju_tree.pkl&#x27;</span>,<span class="string">&#x27;rf_forest.pkl&#x27;</span>]</span><br><span class="line">path=<span class="string">&#x27;../Model&#x27;</span></span><br><span class="line">m_path=<span class="string">&#x27;../Model/3_means&#x27;</span></span><br><span class="line">entropy_list=[]</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    model_copy=model</span><br><span class="line">    train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">    model_name=model.replace(<span class="string">&#x27;.pkl&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;当前模型为<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 读入模型</span></span><br><span class="line">    model_path=os.path.join(path,model)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    av_list=[]</span><br><span class="line">    <span class="comment"># 计算不同模型的变化率</span></span><br><span class="line">    <span class="keyword">for</span> each_column <span class="keyword">in</span> X.columns: </span><br><span class="line">        temp_X=pd.DataFrame(columns=X.columns)</span><br><span class="line">        target=np.array(X[each_column])</span><br><span class="line">        <span class="built_in">min</span>=np.<span class="built_in">min</span>(target)</span><br><span class="line">        <span class="built_in">max</span>=np.<span class="built_in">max</span>(target)</span><br><span class="line">        column_list=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>,<span class="built_in">max</span>+<span class="number">1</span>):</span><br><span class="line">            temp_X_copy=X</span><br><span class="line">            temp_X_copy[each_column]=i</span><br><span class="line">            y_pred=model.predict(temp_X_copy)</span><br><span class="line">            column_list.append(y_pred.mean())</span><br><span class="line">        av_list.append(average_change_rate(column_list))</span><br><span class="line">    df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;属性&#x27;</span>: X.columns,</span><br><span class="line">    <span class="string">&#x27;变化率&#x27;</span>: av_list</span><br><span class="line">    &#125;)</span><br><span class="line">    df.plot(kind=<span class="string">&#x27;bar&#x27;</span>, x=<span class="string">&#x27;属性&#x27;</span>, y=<span class="string">&#x27;变化率&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>属性平均变化率&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;属性&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;变化率&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    model_path=os.path.join(m_path,model_copy)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    temp_X=X</span><br><span class="line">    y_pred=model.predict(X)</span><br><span class="line">    <span class="built_in">print</span>(y_pred)</span><br><span class="line">    temp_X[<span class="string">&#x27;洪水概率&#x27;</span>]=y_pred</span><br><span class="line">    temp_X[<span class="string">&#x27;id&#x27;</span>]=train_data[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):    </span><br><span class="line">        temp=temp_X[temp_X[<span class="string">&#x27;洪水概率&#x27;</span>]==i]</span><br><span class="line">        temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="string">f&#x27;[<span class="subst">&#123;i&#125;</span>]&#x27;</span>]</span><br><span class="line">        name=dic[<span class="string">f&#x27;[<span class="subst">&#123;i&#125;</span>]&#x27;</span>]</span><br><span class="line">        csv_path=<span class="string">&#x27;../Data/3_means/&#x27;</span></span><br><span class="line">        temp.to_csv(csv_path+<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>&#x27;</span>+<span class="string">&#x27;/&#x27;</span>+<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>.csv&#x27;</span>,index=<span class="literal">False</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    entropy_list.append(calculate_entropy(y_pred))</span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;模型&#x27;</span>: [<span class="string">&#x27;线性回归&#x27;</span>,<span class="string">&#x27;梯度提升树&#x27;</span>,<span class="string">&#x27;决策树&#x27;</span>,<span class="string">&#x27;随机森林&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;熵值&#x27;</span>: entropy_list</span><br><span class="line">&#125;)</span><br><span class="line">df.plot(kind=<span class="string">&#x27;bar&#x27;</span>, x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;熵值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">f&#x27;不同模型的灵敏度&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;熵值&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">当前模型为<span class="built_in">linear</span>.pkl</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2<span class="number"> 2 </span>2 ...<span class="number"> 2 </span>2 0]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\<span class="number">12780</span>\AppData\Local\Temp\ipykernel_28736\<span class="number">2860376030</span>.<span class="keyword">py</span>:<span class="number">54</span>: SettingWithCopyWarning: </span><br><span class="line">A value <span class="keyword">is</span> trying <span class="keyword">to</span> <span class="keyword">be</span> <span class="keyword">set</span> <span class="keyword">on</span> <span class="keyword">a</span> <span class="keyword">copy</span> of <span class="keyword">a</span> slice from <span class="keyword">a</span> DataFrame.</span><br><span class="line">Try using .<span class="keyword">loc</span>[row_indexer,col_indexer] = value instead</span><br><span class="line"></span><br><span class="line">See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-<span class="keyword">a</span>-<span class="keyword">view</span>-versus-<span class="keyword">a</span>-<span class="keyword">copy</span></span><br><span class="line">  temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="keyword">f</span><span class="string">&#x27;[&#123;i&#125;]&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">当前模型为gb_tree<span class="selector-class">.pkl</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[1<span class="number"> 1 </span>2 ...<span class="number"> 2 </span>2 0]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\<span class="number">12780</span>\AppData\Local\Temp\ipykernel_28736\<span class="number">2860376030</span>.<span class="keyword">py</span>:<span class="number">54</span>: SettingWithCopyWarning: </span><br><span class="line">A value <span class="keyword">is</span> trying <span class="keyword">to</span> <span class="keyword">be</span> <span class="keyword">set</span> <span class="keyword">on</span> <span class="keyword">a</span> <span class="keyword">copy</span> of <span class="keyword">a</span> slice from <span class="keyword">a</span> DataFrame.</span><br><span class="line">Try using .<span class="keyword">loc</span>[row_indexer,col_indexer] = value instead</span><br><span class="line"></span><br><span class="line">See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-<span class="keyword">a</span>-<span class="keyword">view</span>-versus-<span class="keyword">a</span>-<span class="keyword">copy</span></span><br><span class="line">  temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="keyword">f</span><span class="string">&#x27;[&#123;i&#125;]&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">当前模型为<span class="keyword">ju_tree.pkl</span></span><br><span class="line"><span class="keyword"></span></span><br></pre></td></tr></table></figure>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2<span class="number"> 1 </span>2 ...<span class="number"> 1 </span>1 2]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\<span class="number">12780</span>\AppData\Local\Temp\ipykernel_28736\<span class="number">2860376030</span>.<span class="keyword">py</span>:<span class="number">54</span>: SettingWithCopyWarning: </span><br><span class="line">A value <span class="keyword">is</span> trying <span class="keyword">to</span> <span class="keyword">be</span> <span class="keyword">set</span> <span class="keyword">on</span> <span class="keyword">a</span> <span class="keyword">copy</span> of <span class="keyword">a</span> slice from <span class="keyword">a</span> DataFrame.</span><br><span class="line">Try using .<span class="keyword">loc</span>[row_indexer,col_indexer] = value instead</span><br><span class="line"></span><br><span class="line">See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-<span class="keyword">a</span>-<span class="keyword">view</span>-versus-<span class="keyword">a</span>-<span class="keyword">copy</span></span><br><span class="line">  temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="keyword">f</span><span class="string">&#x27;[&#123;i&#125;]&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">当前模型为rf_forest<span class="selector-class">.pkl</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2<span class="number"> 1 </span>2 ...<span class="number"> 2 </span>1 2]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\<span class="number">12780</span>\AppData\Local\Temp\ipykernel_28736\<span class="number">2860376030</span>.<span class="keyword">py</span>:<span class="number">54</span>: SettingWithCopyWarning: </span><br><span class="line">A value <span class="keyword">is</span> trying <span class="keyword">to</span> <span class="keyword">be</span> <span class="keyword">set</span> <span class="keyword">on</span> <span class="keyword">a</span> <span class="keyword">copy</span> of <span class="keyword">a</span> slice from <span class="keyword">a</span> DataFrame.</span><br><span class="line">Try using .<span class="keyword">loc</span>[row_indexer,col_indexer] = value instead</span><br><span class="line"></span><br><span class="line">See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-<span class="keyword">a</span>-<span class="keyword">view</span>-versus-<span class="keyword">a</span>-<span class="keyword">copy</span></span><br><span class="line">  temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="keyword">f</span><span class="string">&#x27;[&#123;i&#125;]&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="problem-three-从不同指标集建立洪水的预测模型"><a class="markdownIt-Anchor" href="#problem-three-从不同指标集建立洪水的预测模型">#</a> Problem THREE 从不同指标集建立洪水的预测模型</h2>
<h3 id="利用半指标集重新训练模型"><a class="markdownIt-Anchor" href="#利用半指标集重新训练模型">#</a> 利用半指标集重新训练模型</h3>
<h4 id="数据读入与划分"><a class="markdownIt-Anchor" href="#数据读入与划分">#</a> 数据读入与划分</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">X=X[ten_columns]</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h4 id="多元线性回归"><a class="markdownIt-Anchor" href="#多元线性回归">#</a> 多元线性回归</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(model_line,<span class="string">&#x27;../Model/min20/linear.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">3797909073877743</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">0016121225286413457</span></span><br><span class="line">模型的系数为: [<span class="number">0.00502906</span> <span class="number">0.00505761</span> <span class="number">0.00500356</span> <span class="number">0.00496802</span> <span class="number">0.00499052</span> <span class="number">0.00504195</span></span><br><span class="line"> <span class="number">0.00501869</span> <span class="number">0.00496276</span> <span class="number">0.00495814</span> <span class="number">0.00499007</span>]</span><br><span class="line">模型的截距为: <span class="number">0</span>.<span class="number">2576458803465974</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9968581620856443</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="梯度提升树"><a class="markdownIt-Anchor" href="#梯度提升树">#</a> 梯度提升树</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">n_estimators = <span class="number">1000</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(gb_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证评分的平均值:&quot;</span>, np.mean(cv_scores))</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 计算每轮迭代的损失值</span></span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制损失曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances)), feature_importances, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">joblib.dump(gb_model,<span class="string">&#x27;../Model/min20/gb_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">每折交叉验证的评分: [<span class="number">0.38422655</span> <span class="number">0.38220555</span> <span class="number">0.38382033</span> <span class="number">0.38356502</span> <span class="number">0.38412738</span>]</span><br><span class="line">交叉验证评分的平均值: <span class="number">0</span>.<span class="number">38358896650341584</span></span><br><span class="line">Model Score : <span class="number">0</span>.<span class="number">38390663962200555</span></span><br><span class="line">特征重要性: [<span class="number">0.10205675</span> <span class="number">0.10034733</span> <span class="number">0.10139756</span> <span class="number">0.1018449</span>  <span class="number">0.10108517</span> <span class="number">0.10034581</span></span><br><span class="line"> <span class="number">0.10023741</span> <span class="number">0.0967709</span>  <span class="number">0.09875688</span> <span class="number">0.0971573</span> ]</span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9968790479654901</span></span><br><span class="line">均方误差为<span class="number">0</span>.<span class="number">0016014244193493427</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="决策树"><a class="markdownIt-Anchor" href="#决策树">#</a> 决策树</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(tree_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证评分的平均值:&quot;</span>, np.mean(cv_scores))</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(tree_model,<span class="string">&#x27;../Model/min20/ju_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">每折交叉验证的评分: [-<span class="number">0.38044123</span> -<span class="number">0.37039988</span> -<span class="number">0.37308455</span> -<span class="number">0.37506536</span> -<span class="number">0.37448948</span>]</span><br><span class="line">交叉验证评分的平均值: -<span class="number">0</span>.<span class="number">37469609875144927</span></span><br><span class="line">Model Score : -<span class="number">0</span>.<span class="number">3724991072858381</span></span><br><span class="line">特征重要性: [<span class="number">0.10005281</span> <span class="number">0.09983183</span> <span class="number">0.09977541</span> <span class="number">0.09885637</span> <span class="number">0.09927343</span> <span class="number">0.10018744</span></span><br><span class="line"> <span class="number">0.10027551</span> <span class="number">0.10119409</span> <span class="number">0.1001009</span>  <span class="number">0.1004522</span> ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">余弦相似度为0.9930576700128282</span><br><span class="line">均方误差为0.003567565773788236</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>随机森林</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>)  <span class="comment"># 使用100棵树</span></span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r2_score(y_test, y_pred))</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(rf,<span class="string">&#x27;../Model/min20/rf_forest.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">34325879744154253</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">001707081209777524</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">996672979089785</span></span><br><span class="line">准确率:</span><br><span class="line"><span class="number">0</span>.<span class="number">34325879744154253</span></span><br><span class="line">特征重要性: [<span class="number">0.09920083</span> <span class="number">0.09998751</span> <span class="number">0.09940968</span> <span class="number">0.09865654</span> <span class="number">0.09964584</span> <span class="number">0.10035755</span></span><br><span class="line"> <span class="number">0.09983987</span> <span class="number">0.10085278</span> <span class="number">0.1012155</span>  <span class="number">0.10083389</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="利用核心指标集重新训练模型"><a class="markdownIt-Anchor" href="#利用核心指标集重新训练模型">#</a> 利用核心指标集重新训练模型</h3>
<h4 id="数据读入-3"><a class="markdownIt-Anchor" href="#数据读入-3">#</a> 数据读入</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line"><span class="comment"># 在这里进行数据指标的选择</span></span><br><span class="line">X=X[five_columns]</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line"><span class="comment">#y=-np.log(1/y-1)</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h4 id="多元线性回归-2"><a class="markdownIt-Anchor" href="#多元线性回归-2">#</a> 多元线性回归</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(model_line,<span class="string">&#x27;../Model/5features/linear.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">1835669186041815</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">002122171666498279</span></span><br><span class="line">模型的系数为: [<span class="number">0.00485089</span> <span class="number">0.00484171</span> <span class="number">0.00476767</span> <span class="number">0.00471688</span> <span class="number">0.00477062</span>]</span><br><span class="line">模型的截距为: <span class="number">0</span>.<span class="number">3862570525392469</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9958620768117359</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="梯度提升树-2"><a class="markdownIt-Anchor" href="#梯度提升树-2">#</a> 梯度提升树</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># 设置迭代次数为100</span></span><br><span class="line">n_estimators = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 创建并训练梯度提升树回归模型</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 计算每轮迭代的损失值</span></span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制损失曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">joblib.dump(gb_model,<span class="string">&#x27;../Model/5features/gb_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Model Score : <span class="number">0</span>.<span class="number">18706274403216527</span></span><br><span class="line">特征重要性: [<span class="number">0.20230352</span> <span class="number">0.19922658</span> <span class="number">0.19952716</span> <span class="number">0.20019026</span> <span class="number">0.19875248</span>]</span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9958798307923142</span></span><br><span class="line">均方误差为<span class="number">0</span>.<span class="number">0021130848939956166</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="决策树-2"><a class="markdownIt-Anchor" href="#决策树-2">#</a> 决策树</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="comment"># 创建并训练决策树回归模型</span></span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># 执行 K 折交叉验证</span></span><br><span class="line">cv_scores = cross_val_score(tree_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 输出每折交叉验证的评分</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line"><span class="comment"># 输出交叉验证评分的平均值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证评分的平均值:&quot;</span>, np.mean(cv_scores))</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line"><span class="comment"># 输出特征重要性</span></span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 将特征重要性展平</span></span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(tree_model,<span class="string">&#x27;../Model/5features/ju_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">每折交叉验证的评分: [<span class="number">0.04361354</span> <span class="number">0.04034011</span> <span class="number">0.04317059</span> <span class="number">0.04289384</span> <span class="number">0.04444733</span>]</span><br><span class="line">交叉验证评分的平均值: <span class="number">0</span>.<span class="number">04289308234438856</span></span><br><span class="line">Model Score : <span class="number">0</span>.<span class="number">06096464073076868</span></span><br><span class="line">特征重要性: [<span class="number">0.19962294</span> <span class="number">0.19925044</span> <span class="number">0.20269697</span> <span class="number">0.19846155</span> <span class="number">0.1999681</span> ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">余弦相似度为0.9952401471395698</span><br><span class="line">均方误差为0.002440854343964364</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="随机森林"><a class="markdownIt-Anchor" href="#随机森林">#</a> 随机森林</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>)  <span class="comment"># 使用100棵树</span></span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(r2_score(y_test, y_pred))</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(rf,<span class="string">&#x27;../Model/5features/rf_forest.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Model score: <span class="number">0</span>.<span class="number">11505358895416717</span></span><br><span class="line">均方误差为: <span class="number">0</span>.<span class="number">002300259804122661</span></span><br><span class="line">余弦相似度为<span class="number">0</span>.<span class="number">9955143525656249</span></span><br><span class="line">准确率:</span><br><span class="line"><span class="number">0</span>.<span class="number">11505358895416717</span></span><br><span class="line">特征重要性: [<span class="number">0.19860426</span> <span class="number">0.1997008</span>  <span class="number">0.20150083</span> <span class="number">0.20023265</span> <span class="number">0.19996146</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="problem-four-预测洪水发生的概率"><a class="markdownIt-Anchor" href="#problem-four-预测洪水发生的概率">#</a> Problem FOUR 预测洪水发生的概率</h2>
<h4 id="利用准确率最高的梯度提升树模型进行预测"><a class="markdownIt-Anchor" href="#利用准确率最高的梯度提升树模型进行预测">#</a> 利用准确率最高的梯度提升树模型进行预测</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data_path = <span class="string">&#x27;../Data/test.csv&#x27;</span></span><br><span class="line">data=pd.read_csv(data_path)</span><br><span class="line">data=data.drop(columns=[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;洪水概率&#x27;</span>])</span><br><span class="line">model_path=<span class="string">&#x27;../Model/gb_tree.pkl&#x27;</span></span><br><span class="line">model=joblib.load(model_path)</span><br><span class="line">y_pred=model.predict(data)</span><br><span class="line">data_path=<span class="string">&#x27;../Data/submit.csv&#x27;</span></span><br><span class="line">df=pd.read_csv(data_path)</span><br><span class="line">df[<span class="string">&#x27;洪水概率&#x27;</span>]=y_pred</span><br><span class="line">df=df[[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;洪水概率&#x27;</span>]]</span><br><span class="line">df.to_csv(<span class="string">&#x27;../Data/submit.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="利用直方图与折线图可视化结果"><a class="markdownIt-Anchor" href="#利用直方图与折线图可视化结果">#</a> 利用直方图与折线图可视化结果</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">data=y_pred</span><br><span class="line">data=np.array(data)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个子图：直方图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.hist(data, bins=<span class="number">30</span>, alpha=<span class="number">0.5</span>, color=<span class="string">&#x27;blue&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个子图：折线图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(np.random.choice(data,<span class="built_in">int</span>(<span class="number">0.001</span>*<span class="built_in">len</span>(data))), color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Index&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图表</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="判别是否服从正态分布"><a class="markdownIt-Anchor" href="#判别是否服从正态分布">#</a> 判别是否服从正态分布</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line">normalized_data = (data - np.mean(data)) / np.std(data)</span><br><span class="line"></span><br><span class="line">ks_stat, ks_p = stats.kstest(normalized_data, <span class="string">&#x27;norm&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nKolmogorov-Smirnov Test:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Statistics:&quot;</span>, ks_stat)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p-value:&quot;</span>, ks_p)</span><br><span class="line"><span class="keyword">if</span> ks_p &lt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不服从正态分布).&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;服从正态分布&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attribute">Kolmogorov-Smirnov Test</span><span class="punctuation">:</span></span><br><span class="line"><span class="attribute">Statistics</span><span class="punctuation">:</span> <span class="string">0.05078130889692345</span></span><br><span class="line"><span class="attribute">p-value</span><span class="punctuation">:</span> <span class="string">0.0</span></span><br><span class="line">不服从正态分布).</span><br><span class="line"></span><br></pre></td></tr></table></figure>
      <div class="tags">
          <a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a>
          <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a>
          <a href="/tags/code/" rel="tag"><i class="ic i-tag"></i> code</a>
          <a href="/tags/recommendation/" rel="tag"><i class="ic i-tag"></i> recommendation</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2024-07-06 14:54:25" itemprop="dateModified" datetime="2024-07-06T14:54:25+08:00">2024-07-06</time>
  </span>
  <span id="bit/DATA_predose/" class="item leancloud_visitors" data-flag-title="亚太数模 —— 洪水" title="Views">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">Views</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">times</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> Donate</button>
  <p>Give me a cup of [coffee]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/wechatpay.png" alt="Jack Du WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div>
        <img data-src="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/alipay.png" alt="Jack Du Alipay">
        <p>Alipay</p>
      </div>
      
      <div>
        <img data-src="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/paypal.png" alt="Jack Du PayPal">
        <p>PayPal</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>Jack Du <i class="ic i-at"><em>@</em></i>Hexo
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="https://enjundu.github.io/bit/DATA_predose/" title="亚太数模 —— 洪水">https://enjundu.github.io/bit/DATA_predose/</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;ArOLs3qhENaXcUV.jpg" title="亚太数模——新能源汽车">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> BIT-study</span>
  <h3>亚太数模——新能源汽车</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%89/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;ArOLs3qhENaXcUV.jpg" title="数码管扫描点亮电路">
  <span class="type">Next Post</span>
  <span class="category"><i class="ic i-flag"></i> 数字逻辑实验</span>
  <h3>数码管扫描点亮电路</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#before-problem-%E6%95%B0%E6%8D%AE%E4%BC%A0%E5%85%A5%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.</span> <span class="toc-text"> Before Problem – 数据传入与预处理，全局函数设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93"><span class="toc-number">1.1.</span> <span class="toc-text"> 导入必要的库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5"><span class="toc-number">1.2.</span> <span class="toc-text"> 数据读入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8Etraincsv%E8%AF%BB%E5%85%A5train%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.1.</span> <span class="toc-text"> 从 train.csv 读入 train 数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text"> 数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%80%E8%A6%81%E5%88%86%E6%9E%90"><span class="toc-number">1.4.</span> <span class="toc-text"> 数据相关性简要分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E4%B8%89%E4%B8%AA%E6%B0%B4%E5%B9%B3%E7%9A%84%E6%8C%87%E6%A0%87%E9%9B%86"><span class="toc-number">1.5.</span> <span class="toc-text"> 建立三个水平的指标集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.6.</span> <span class="toc-text"> 全局函数设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%8E%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">1.7.</span> <span class="toc-text"> 划分训练集与测试集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-one-%E5%85%A8%E6%8C%87%E6%A0%87%E9%9B%86%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E4%B8%8E%E6%B1%82%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text"> Problem ONE – 全指标集数学模型建立与求解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">2.1.</span> <span class="toc-text"> 模型一 线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91"><span class="toc-number">2.2.</span> <span class="toc-text"> 模型二 梯度提升树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%89-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.3.</span> <span class="toc-text"> 模型三 决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%9B%9B-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.4.</span> <span class="toc-text"> 模型四 随机森林</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-two-%E9%A3%8E%E9%99%A9%E8%81%9A%E7%B1%BB"><span class="toc-number">3.</span> <span class="toc-text"> Problem TWO 风险聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">3.1.</span> <span class="toc-text"> 读入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95kmeans"><span class="toc-number">3.2.</span> <span class="toc-text"> 聚类算法：Kmeans</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text"> 聚类预测函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8Bkmeans%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.2.</span> <span class="toc-text"> 建立 Kmeans 模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E8%81%9A%E7%B1%BB%E4%B8%AD%E5%BF%83%E5%88%B0%E9%A3%8E%E9%99%A9%E7%9A%84%E6%98%A0%E5%B0%84%E5%AD%97%E5%85%B8"><span class="toc-number">3.2.3.</span> <span class="toc-text"> 建立聚类中心到风险的映射字典</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.2.4.</span> <span class="toc-text"> 示例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E9%A3%8E%E9%99%A9%E9%A2%84%E8%AD%A6%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.</span> <span class="toc-text"> 基于风险预警的预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B-mymodel"><span class="toc-number">3.3.1.</span> <span class="toc-text"> 模型建立 MyModel</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5-2"><span class="toc-number">3.4.</span> <span class="toc-text"> 数据读入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">3.4.1.</span> <span class="toc-text"> 模型训练</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">3.5.</span> <span class="toc-text"> 模型灵敏度分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E7%86%B5%E7%9A%84%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0-calculate_entropy"><span class="toc-number">3.5.1.</span> <span class="toc-text"> 设置熵的计算函数 calculate_entropy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%9F%BA%E4%BA%8E%E5%B1%9E%E6%80%A7%E5%8F%98%E5%8C%96%E7%8E%87%E7%9A%84%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0-average_change_rate"><span class="toc-number">3.5.2.</span> <span class="toc-text"> 设置基于属性变化率的计算函数 average_change_rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%9F%BA%E4%BA%8E%E7%86%B5%E5%80%BC%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">3.5.3.</span> <span class="toc-text"> 启动基于熵值的灵敏度计算</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-three-%E4%BB%8E%E4%B8%8D%E5%90%8C%E6%8C%87%E6%A0%87%E9%9B%86%E5%BB%BA%E7%AB%8B%E6%B4%AA%E6%B0%B4%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text"> Problem THREE 从不同指标集建立洪水的预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%8D%8A%E6%8C%87%E6%A0%87%E9%9B%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text"> 利用半指标集重新训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">4.1.1.</span> <span class="toc-text"> 数据读入与划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.1.2.</span> <span class="toc-text"> 多元线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91"><span class="toc-number">4.1.3.</span> <span class="toc-text"> 梯度提升树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">4.1.4.</span> <span class="toc-text"> 决策树</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E6%A0%B8%E5%BF%83%E6%8C%87%E6%A0%87%E9%9B%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text"> 利用核心指标集重新训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5-3"><span class="toc-number">4.2.1.</span> <span class="toc-text"> 数据读入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-2"><span class="toc-number">4.2.2.</span> <span class="toc-text"> 多元线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91-2"><span class="toc-number">4.2.3.</span> <span class="toc-text"> 梯度提升树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91-2"><span class="toc-number">4.2.4.</span> <span class="toc-text"> 决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">4.2.5.</span> <span class="toc-text"> 随机森林</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-four-%E9%A2%84%E6%B5%8B%E6%B4%AA%E6%B0%B4%E5%8F%91%E7%94%9F%E7%9A%84%E6%A6%82%E7%8E%87"><span class="toc-number">5.</span> <span class="toc-text"> Problem FOUR 预测洪水发生的概率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%87%86%E7%A1%AE%E7%8E%87%E6%9C%80%E9%AB%98%E7%9A%84%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">5.0.1.</span> <span class="toc-text"> 利用准确率最高的梯度提升树模型进行预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E7%9B%B4%E6%96%B9%E5%9B%BE%E4%B8%8E%E6%8A%98%E7%BA%BF%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="toc-number">5.0.2.</span> <span class="toc-text"> 利用直方图与折线图可视化结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A4%E5%88%AB%E6%98%AF%E5%90%A6%E6%9C%8D%E4%BB%8E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">5.0.3.</span> <span class="toc-text"> 判别是否服从正态分布</span></a></li></ol></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li><a href="/bit/%E7%BE%8E%E8%B5%9B%E2%80%94%E2%80%94%E4%B8%83%E9%B3%83%E9%B3%97/" rel="bookmark" title="美赛——七鳃鳗">美赛——七鳃鳗</a></li><li class="active"><a href="/bit/DATA_predose/" rel="bookmark" title="亚太数模——洪水">亚太数模——洪水</a></li><li><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" rel="bookmark" title="亚太数模——新能源汽车">亚太数模——新能源汽车</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Jack Du"
      data-src="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/images/avatar.jpg">
  <p class="name" itemprop="name">Jack Du</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">41</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">9</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">5</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>Home</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%89/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LLMstestoracle/" title="In LLM 的 test oracle 生成">LLM 的 test oracle 生成</a>
</div>

    <span><a href="/LLMstestoracle/7_ttach-master/" title="ttach">ttach</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LLMstestoracle/" title="In LLM 的 test oracle 生成">LLM 的 test oracle 生成</a>
</div>

    <span><a href="/LLMstestoracle/9_sumeval-master/" title="sumeval">sumeval</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/LLMstestoracle/" title="In LLM 的 test oracle 生成">LLM 的 test oracle 生成</a>
</div>

    <span><a href="/LLMstestoracle/5_giskard-main/" title="Giskard-AI&#x2F;giskard">Giskard-AI/giskard</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/bit/" title="In BIT-study">BIT-study</a>
</div>

    <span><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" title="亚太数模——新能源汽车">亚太数模——新能源汽车</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/IntroductiontoNetSecurityLab/" title="In 网安导论实验">网安导论实验</a>
</div>

    <span><a href="/IntroductiontoNetSecurityLab/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E5%AE%89%E5%85%A8_%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" title="人工智能的后门攻击">人工智能的后门攻击</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a>
</div>

    <span><a href="/misc/%E6%95%B0%E5%AD%97%E7%BB%8F%E6%B5%8E%EF%BC%9A%E7%A7%91%E6%8A%80%E5%88%9B%E6%96%B0%E5%92%8C%E4%BC%81%E4%B8%9A%E8%BD%AC%E5%9E%8B_%E9%80%9A%E8%AF%86%E7%BB%93%E8%AF%BE%E8%AE%BA%E6%96%87/" title="数字经济：科技创新和企业转型_通识结课论文">数字经济：科技创新和企业转型_通识结课论文</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/misc/%E5%AF%86%E7%A0%81%E5%B7%A5%E7%A8%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A/" title="Untitled">Untitled</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Sanfordcs231n/" title="In 斯坦福 CS231n 课程">斯坦福 CS231n 课程</a>
</div>

    <span><a href="/Sanfordcs231n/README_2_Linear%20Classification/" title="k-NN最近分类器">k-NN最近分类器</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/shudian/" title="In 数字逻辑实验">数字逻辑实验</a>
</div>

    <span><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%80/" title="组合逻辑基础模块">组合逻辑基础模块</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/recommendation/" title="In 推荐算法相关 search">推荐算法相关 search</a>
</div>

    <span><a href="/recommendation/README/" title="b_README">b_README</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天°</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="Symbols count total">546k words</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="Reading time total">8:16</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: 'bit/DATA_predose/',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="//cdn.jsdelivr.net/gh/EnjunDu/EnjunDu.github.io@latest/js/app.js?v=0.2.5"></script>




</body>
</html>
