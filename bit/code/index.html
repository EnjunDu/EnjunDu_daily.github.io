<!-- build time:Sun Jul 07 2024 13:12:14 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Hexo" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Hexo" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Hexo" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter,code,recommendation"><link rel="canonical" href="https://enjundu.github.io/bit/code/"><title>亚太数模——洪水 - BIT-study | 蓝天の网站 = Hexo</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">亚太数模——洪水</h1><div class="meta"><span class="item" title="Created: 2024-07-04 22:49:23"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-04T22:49:23+08:00">2024-07-04</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/04/crRxfhWIzOaUvSj.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/l29P4JN75BkxmQu.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/sTHU7wL5qkSiloC.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/d8I9raJDhEUebpV.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/2CIcORrG8hxpSnD.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/cI2aroK5AZfHs7U.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/bit/" itemprop="item" rel="index" title="In BIT-study"><span itemprop="name">BIT-study</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/bit/code/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hexo"></span><div class="body md" itemprop="articleBody"><h2 id="before-problem-数据传入与预处理全局函数设置"><a class="anchor" href="#before-problem-数据传入与预处理全局函数设置">#</a> Before Problem -- 数据传入与预处理，全局函数设置</h2><h3 id="导入必要的库"><a class="anchor" href="#导入必要的库">#</a> 导入必要的库</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">u&#x27;simHei&#x27;</span>]   <span class="comment"># 显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>      <span class="comment"># 解决负号问题</span></span><br></pre></td></tr></table></figure><p></p><h3 id="数据读入"><a class="anchor" href="#数据读入">#</a> 数据读入</h3><h4 id="从traincsv读入train数据"><a class="anchor" href="#从traincsv读入train数据">#</a> 从 train.csv 读入 train 数据</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br></pre></td></tr></table></figure><p></p><h3 id="数据预处理"><a class="anchor" href="#数据预处理">#</a> 数据预处理</h3><p>id 列对于数据分析没有用处，直接清洗掉这一列</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><p>经检验，原始数据中不存在缺失值与明显的离群点，因此在这里全部保留</p><p>将 ' 洪水概率 ' 设置为目标变量，将原始数据划分为 X，y</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br></pre></td></tr></table></figure><p></p><h3 id="数据相关性简要分析"><a class="anchor" href="#数据相关性简要分析">#</a> 数据相关性简要分析</h3><p>利用不同指标与洪水概率的相关系数来衡量这些指标与洪水概率的关系</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">&#x27;洪水概率&#x27;</span>]=y</span><br><span class="line">heat_corr = train_data.corr()[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">heat_corr_sorted=heat_corr.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">heat_corr=heat_corr[:-<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p></p><p>可视化相关系数图</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">heat_corr.plot(kind=<span class="string">&#x27;bar&#x27;</span>, color=<span class="string">&#x27;skyblue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;不同因素对洪水概率的影响&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;影响因素&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;corr&#x27;</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>​<br><img data-src="output_16_0.png" alt="png"><br>​</p><h3 id="建立三个水平的指标集"><a class="anchor" href="#建立三个水平的指标集">#</a> 建立三个水平的指标集</h3><pre><code>20： 全指标

10：半指标

5：核心指标

划分依据: 相关系数大小
</code></pre><h4 id="利用过滤法获取指标集"><a class="anchor" href="#利用过滤法获取指标集">#</a> 利用过滤法获取指标集</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line">X_skb = SelectKBest(k=<span class="number">10</span>).fit_transform(X, y)</span><br><span class="line">selected_features_indices = SelectKBest(k=<span class="number">10</span>).fit(X, y).get_support(indices=<span class="literal">True</span>)</span><br><span class="line">selected_features_ten = X.columns[selected_features_indices]</span><br><span class="line">X_skb = SelectKBest(k=<span class="number">5</span>).fit_transform(X, y)</span><br><span class="line">selected_features_indices = SelectKBest(k=<span class="number">5</span>).fit(X, y).get_support(indices=<span class="literal">True</span>)</span><br><span class="line">selected_features_five = X.columns[selected_features_indices]</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ten_columns=selected_features_ten</span><br><span class="line">five_columns=selected_features_five</span><br></pre></td></tr></table></figure><p></p><h3 id="全局函数设置"><a class="anchor" href="#全局函数设置">#</a> 全局函数设置</h3><p>建立余弦相似度的计算函数</p><pre><code>cosine(a,b)

input : 向量A，B

output : 两个向量的余弦相似度 0-1
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cosine</span>(<span class="params">a,b</span>):</span><br><span class="line">    dot_product = np.dot(a, b)</span><br><span class="line">    norm_a = np.linalg.norm(a)</span><br><span class="line">    norm_b = np.linalg.norm(b)</span><br><span class="line">    cosine_similarity = dot_product / (norm_a * norm_b) </span><br><span class="line">    <span class="keyword">return</span> cosine_similarity</span><br></pre></td></tr></table></figure><p></p><h3 id="划分训练集与测试集"><a class="anchor" href="#划分训练集与测试集">#</a> 划分训练集与测试集</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p></p><h2 id="problem-one-全指标集数学模型建立与求解"><a class="anchor" href="#problem-one-全指标集数学模型建立与求解">#</a> Problem ONE -- 全指标集数学模型建立与求解</h2><pre><code>利用多种数学模型拟合本问题，并得出不同指标的权重
多元线性回归
梯度提升树
决策树
随机森林模型
</code></pre><h3 id="模型一-线性回归"><a class="anchor" href="#模型一-线性回归">#</a> 模型一 线性回归</h3><pre><code>原理：利用标准方程法求解线性方程组
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(model_line,<span class="string">&#x27;../Model/linear.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.8444528508563269
均方误差为: 0.0004043169737229802
模型的系数为: [0.00560656 0.00564613 0.00565985 0.00567684 0.00565284 0.0056578
 0.00565561 0.00564293 0.0056437  0.0056492  0.00564238 0.0056413
 0.005674   0.00564575 0.0056467  0.00562068 0.00568107 0.00563092
 0.00561738 0.00564302]
模型的截距为: -0.053357024379501294
余弦相似度为0.9992129608069907





['../Model/linear.pkl']
</code></pre><h3 id="模型二-梯度提升树"><a class="anchor" href="#模型二-梯度提升树">#</a> 模型二 梯度提升树</h3><pre><code>原理：递归的决策树，能发现更深层的变量关系
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">n_estimators = <span class="number">1200</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(gb_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances)), feature_importances, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">joblib.dump(gb_model,<span class="string">&#x27;../Model/gb_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>每折交叉验证的评分: [0.84262125 0.84055718 0.84249464 0.84247138 0.84228929]
Model Score : 0.8414966684722095
特征重要性: [0.05053843 0.0513698  0.05097438 0.04985333 0.04968169 0.0498542
 0.05148326 0.05025949 0.04944183 0.04878379 0.04970291 0.04908077
 0.0490136  0.05042491 0.04939282 0.05113171 0.05085744 0.04953673
 0.04897519 0.04964374]
余弦相似度为0.9991979970651009
均方误差为0.00041200104072066957
</code></pre><p><img data-src="output_33_1.png" alt="png"></p><p><img data-src="output_33_2.png" alt="png"></p><pre><code>['../Model/gb_tree.pkl']
</code></pre><h3 id="模型三-决策树"><a class="anchor" href="#模型三-决策树">#</a> 模型三 决策树</h3><pre><code>原理：利用信息增益实现节点的划分
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">cv_scores = cross_val_score(tree_model, X_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每折交叉验证的评分:&quot;</span>, cv_scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证评分的平均值:&quot;</span>, np.mean(cv_scores))</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(tree_model,<span class="string">&#x27;../Model/ju_tree.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>每折交叉验证的评分: [0.04694866 0.04297524 0.0450139  0.04790429 0.04502323]
交叉验证评分的平均值: 0.045573064737767635
Model Score : 0.05301513744804842
特征重要性: [0.05072873 0.04679774 0.04822921 0.0498514  0.05054892 0.05003494
 0.04871661 0.0509244  0.05185402 0.04976417 0.04994974 0.0515037
 0.05054295 0.05088047 0.04947362 0.04914221 0.04920693 0.0502652
 0.05116479 0.05042025]
</code></pre><p><img data-src="output_36_1.png" alt="png"></p><pre><code>余弦相似度为0.9952026345820846
均方误差为0.0024615176549126197





['../Model/ju_tree.pkl']
</code></pre><h3 id="模型四-随机森林"><a class="anchor" href="#模型四-随机森林">#</a> 模型四 随机森林</h3><pre><code>原理： 抽样决策树并使用投票策略
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>) </span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(rf,<span class="string">&#x27;../Model/rf_forest.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.44680104709877044
均方误差为: 0.0014379416642162513
余弦相似度为0.9972000912425318
特征重要性: [0.04978576 0.04862332 0.04894115 0.05013728 0.05126306 0.04920341
 0.05073347 0.05091014 0.05058542 0.05072007 0.04952681 0.05108774
 0.05003957 0.05097466 0.04944974 0.04788824 0.04842014 0.05057201
 0.05047306 0.05066494]
</code></pre><p><img data-src="output_38_1.png" alt="png"></p><pre><code>['../Model/rf_forest.pkl']
</code></pre><h2 id="problem-two-风险聚类"><a class="anchor" href="#problem-two-风险聚类">#</a> Problem TWO 风险聚类</h2><h3 id="读入数据"><a class="anchor" href="#读入数据">#</a> 读入数据</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br></pre></td></tr></table></figure><p></p><h3 id="聚类算法kmeans"><a class="anchor" href="#聚类算法kmeans">#</a> 聚类算法：Kmeans</h3><pre><code>原理: 利用n维空间距离对初始聚类中心进行学习，得到最终聚类中心
</code></pre><h4 id="聚类预测函数"><a class="anchor" href="#聚类预测函数">#</a> 聚类预测函数</h4><pre><code>predict_cluster(kmeans,points)
input: kmeans模型 points需要预测的点集
output: 点集的预测结果
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_cluster</span>(<span class="params">kmeans, points</span>):</span><br><span class="line">    points = np.array(points)</span><br><span class="line">    points = points.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    cluster_label = kmeans.predict(points)</span><br><span class="line">    <span class="keyword">return</span> cluster_label</span><br></pre></td></tr></table></figure><p></p><h4 id="建立kmeans模型"><a class="anchor" href="#建立kmeans模型">#</a> 建立 Kmeans 模型</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line"><span class="comment">#y=-np.log(1/y-1)</span></span><br><span class="line">data=np.array(y)</span><br><span class="line">data_2d = data.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line">kmeans.fit(data_2d)</span><br><span class="line">cluster_centers = kmeans.cluster_centers_</span><br><span class="line"><span class="built_in">print</span>(cluster_centers)</span><br></pre></td></tr></table></figure><p></p><pre><code>F:\a\envs\env\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(


[[0.56086881]
 [0.49744545]
 [0.43834819]]
</code></pre><h4 id="建立聚类中心到风险的映射字典"><a class="anchor" href="#建立聚类中心到风险的映射字典">#</a> 建立聚类中心到风险的映射字典</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">temp = np.array(cluster_centers)</span><br><span class="line">indices= np.argsort(temp,axis=<span class="number">0</span>)</span><br><span class="line">dic=&#123;&#125;</span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">0</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;低风险&#x27;</span></span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">1</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;中风险&#x27;</span></span><br><span class="line">dic[<span class="string">f&#x27;<span class="subst">&#123;indices[<span class="number">2</span>]&#125;</span>&#x27;</span>]=<span class="string">&#x27;高风险&#x27;</span></span><br></pre></td></tr></table></figure><p></p><h4 id="示例"><a class="anchor" href="#示例">#</a> 示例</h4><p>data= [0.55,0.99,0.51,0.42]</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data= [<span class="number">0.55</span>,<span class="number">0.99</span>,<span class="number">0.51</span>,<span class="number">0.42</span>]</span><br><span class="line"><span class="built_in">print</span>(predict_cluster(kmeans,data))</span><br></pre></td></tr></table></figure><p></p><pre><code>[0 0 1 2]
</code></pre><h3 id="基于风险预警的预测模型"><a class="anchor" href="#基于风险预警的预测模型">#</a> 基于风险预警的预测模型</h3><h4 id="模型建立-mymodel"><a class="anchor" href="#模型建立-mymodel">#</a> 模型建立 MyModel</h4><pre><code>内核    ：某一个概率预测模型与kmeans聚类模型
predict : 预测输入的X对应的y的风险类别
score   : 利用预测成功的比例衡量得分
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model,kmeans</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.model = model</span><br><span class="line">        self.kmeans = kmeans</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X_test</span>) -&gt; np.ndarray:</span><br><span class="line">        y_pred=self.model.predict(X_test)</span><br><span class="line">        y_pred=np.array(y_pred)</span><br><span class="line">        y_pred=predict_cluster(kmeans,y_pred)</span><br><span class="line">        y_pred=np.array(y_pred)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self,X_test,y_test</span>):</span><br><span class="line">        y_pred=self.predict(X_test)</span><br><span class="line">        y_test = np.array(y_test)</span><br><span class="line">        y_true=predict_cluster(kmeans,y_test)</span><br><span class="line">        correct_predictions = np.<span class="built_in">sum</span>(y_pred == y_true)</span><br><span class="line">        overlap = correct_predictions / y_pred.size</span><br><span class="line">        <span class="keyword">return</span> overlap</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h3 id="数据读入-2"><a class="anchor" href="#数据读入-2">#</a> 数据读入</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data=train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p></p><h4 id="利用先前模型构建自定义的分类模型"><a class="anchor" href="#利用先前模型构建自定义的分类模型">#</a> 利用先前模型构建自定义的分类模型</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">models = [<span class="string">&#x27;linear.pkl&#x27;</span>,<span class="string">&#x27;gb_tree.pkl&#x27;</span>,<span class="string">&#x27;ju_tree.pkl&#x27;</span>,<span class="string">&#x27;rf_forest.pkl&#x27;</span>]</span><br><span class="line">path = <span class="string">&#x27;../Model&#x27;</span></span><br><span class="line">m_path=<span class="string">&#x27;../Model/3_means&#x27;</span></span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    model_name=model.replace(<span class="string">&#x27;.pkl&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;当前模型为<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    model_path=os.path.join(path,model)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    model = MyModel(model,kmeans)</span><br><span class="line">    <span class="comment"># 这里可以加入模型的预测过程</span></span><br><span class="line">    y_pred = model.predict(X_test)</span><br><span class="line">    y_true=predict_cluster(kmeans,y_test)</span><br><span class="line">    mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">    score = model.score(X_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">    accuracy = cosine(y_true,y_pred)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> model_name == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;不同指标的权重为&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(model.model.coef_)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;不同指标的权重为&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(model.model.feature_importances_)</span><br><span class="line">    joblib.dump(model,m_path+<span class="string">&#x27;/&#x27;</span>+model_name+<span class="string">&#x27;.pkl&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><pre><code>当前模型为linear.pkl
Model score: 0.7781989843358844
均方误差为: 0.22194406694800087
余弦相似度为0.9187018667799725
不同指标的权重为
[0.00560656 0.00564613 0.00565985 0.00567684 0.00565284 0.0056578
 0.00565561 0.00564293 0.0056437  0.0056492  0.00564238 0.0056413
 0.005674   0.00564575 0.0056467  0.00562068 0.00568107 0.00563092
 0.00561738 0.00564302]
当前模型为gb_tree.pkl
Model score: 0.7747514483942494
均方误差为: 0.22533438237608183
余弦相似度为0.9162199935714694
不同指标的权重为
[0.05053843 0.0513698  0.05097438 0.04985333 0.04968169 0.0498542
 0.05148326 0.05025949 0.04944183 0.04878379 0.04970291 0.04908077
 0.0490136  0.05042491 0.04939282 0.05113171 0.05085744 0.04953673
 0.04897519 0.04964374]
当前模型为ju_tree.pkl
Model score: 0.5127911689674082
均方误差为: 0.6426340509739408
余弦相似度为0.7688175337381278
不同指标的权重为
[0.05072873 0.04679774 0.04822921 0.0498514  0.05054892 0.05003494
 0.04871661 0.0509244  0.05185402 0.04976417 0.04994974 0.0515037
 0.05054295 0.05088047 0.04947362 0.04914221 0.04920693 0.0502652
 0.05116479 0.05042025]
当前模型为rf_forest.pkl
Model score: 0.5881935007033354
均方误差为: 0.44972939465465034
余弦相似度为0.8300231371488734
不同指标的权重为
[0.04978576 0.04862332 0.04894115 0.05013728 0.05126306 0.04920341
 0.05073347 0.05091014 0.05058542 0.05072007 0.04952681 0.05108774
 0.05003957 0.05097466 0.04944974 0.04788824 0.04842014 0.05057201
 0.05047306 0.05066494]
</code></pre><h4 id="逻辑回归"><a class="anchor" href="#逻辑回归">#</a> 逻辑回归</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data=train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line">y=predict_cluster(kmeans,y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y_true=y_test</span><br><span class="line">mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">score = model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_true,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">joblib.dump(model,<span class="string">&#x27;../Model/3_means/logistic.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.7634599337195718
均方误差为: 0.6804282001764299
余弦相似度为0.833248724763824





['../Model/3_means/logistic.pkl']
</code></pre><h3 id="模型灵敏度分析"><a class="anchor" href="#模型灵敏度分析">#</a> 模型灵敏度分析</h3><pre><code>利用结果的熵值来衡量模型的灵敏度
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><h4 id="设置熵的计算函数-calculate_entropy"><a class="anchor" href="#设置熵的计算函数-calculate_entropy">#</a> 设置熵的计算函数 calculate_entropy</h4><pre><code>input: list
ouput :总熵
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_entropy</span>(<span class="params">lst</span>):</span><br><span class="line">    value_counts = np.unique(lst, return_counts=<span class="literal">True</span>)</span><br><span class="line">    values, counts = value_counts</span><br><span class="line">    total_count = <span class="built_in">len</span>(lst)</span><br><span class="line">    probabilities = counts / total_count</span><br><span class="line">    entropy = -np.<span class="built_in">sum</span>(probabilities * np.log2(probabilities))</span><br><span class="line">    <span class="keyword">return</span> entropy</span><br></pre></td></tr></table></figure><p></p><h4 id="设置基于属性变化率的计算函数-average_change_rate"><a class="anchor" href="#设置基于属性变化率的计算函数-average_change_rate">#</a> 设置基于属性变化率的计算函数 average_change_rate</h4><pre><code>input:list
output: 平均相邻变化率
</code></pre><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">average_change_rate</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="comment"># 检查列表是否至少有两项</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    change_rates = [(lst[i+<span class="number">1</span>] - lst[i]) / lst[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst) - <span class="number">1</span>)]</span><br><span class="line">    avg_change_rate = <span class="built_in">sum</span>(change_rates) / <span class="built_in">len</span>(change_rates)</span><br><span class="line">    <span class="keyword">return</span> avg_change_rate</span><br></pre></td></tr></table></figure><p></p><h4 id="启动基于属性对概率变化率的灵敏度计算"><a class="anchor" href="#启动基于属性对概率变化率的灵敏度计算">#</a> 启动基于属性对概率变化率的灵敏度计算</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">models = [<span class="string">&#x27;linear.pkl&#x27;</span>,<span class="string">&#x27;gb_tree.pkl&#x27;</span>,<span class="string">&#x27;ju_tree.pkl&#x27;</span>,<span class="string">&#x27;rf_forest.pkl&#x27;</span>]</span><br><span class="line">path=<span class="string">&#x27;../Model&#x27;</span></span><br><span class="line">m_path=<span class="string">&#x27;../Model/3_means&#x27;</span></span><br><span class="line">entropy_list=[]</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    model_copy=model</span><br><span class="line">    train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">    model_name=model.replace(<span class="string">&#x27;.pkl&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;当前模型为<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 读入模型</span></span><br><span class="line">    model_path=os.path.join(path,model)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    av_list=[]</span><br><span class="line">    <span class="comment"># 计算不同模型的变化率</span></span><br><span class="line">    <span class="keyword">for</span> each_column <span class="keyword">in</span> X.columns: </span><br><span class="line">        temp_X=pd.DataFrame(columns=X.columns)</span><br><span class="line">        target=np.array(X[each_column])</span><br><span class="line">        <span class="built_in">min</span>=np.<span class="built_in">min</span>(target)</span><br><span class="line">        <span class="built_in">max</span>=np.<span class="built_in">max</span>(target)</span><br><span class="line">        column_list=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>,<span class="built_in">max</span>+<span class="number">1</span>):</span><br><span class="line">            temp_X_copy=X</span><br><span class="line">            temp_X_copy[each_column]=i</span><br><span class="line">            y_pred=model.predict(temp_X_copy)</span><br><span class="line">            column_list.append(y_pred.mean())</span><br><span class="line">        av_list.append(average_change_rate(column_list))</span><br><span class="line">    df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;属性&#x27;</span>: X.columns,</span><br><span class="line">    <span class="string">&#x27;变化率&#x27;</span>: av_list</span><br><span class="line">    &#125;)</span><br><span class="line">    df.plot(kind=<span class="string">&#x27;bar&#x27;</span>, x=<span class="string">&#x27;属性&#x27;</span>, y=<span class="string">&#x27;变化率&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>属性平均变化率&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;属性&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;变化率&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p></p><pre><code>当前模型为linear.pkl
</code></pre><p><img data-src="output_70_1.png" alt="png"></p><pre><code>当前模型为gb_tree.pkl
</code></pre><p><img data-src="output_70_3.png" alt="png"></p><pre><code>当前模型为ju_tree.pkl
</code></pre><p><img data-src="output_70_5.png" alt="png"></p><pre><code>当前模型为rf_forest.pkl
</code></pre><p><img data-src="output_70_7.png" alt="png"></p><h4 id="启动基于预测结果的熵值的灵敏度计算"><a class="anchor" href="#启动基于预测结果的熵值的灵敏度计算">#</a> 启动基于预测结果的熵值的灵敏度计算</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">models = [<span class="string">&#x27;linear.pkl&#x27;</span>,<span class="string">&#x27;gb_tree.pkl&#x27;</span>,<span class="string">&#x27;ju_tree.pkl&#x27;</span>,<span class="string">&#x27;rf_forest.pkl&#x27;</span>,<span class="string">&#x27;logistic.pkl&#x27;</span>]</span><br><span class="line">path=<span class="string">&#x27;../Model&#x27;</span></span><br><span class="line">m_path=<span class="string">&#x27;../Model/3_means&#x27;</span></span><br><span class="line">entropy_list=[]</span><br><span class="line"><span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">    model_copy=model</span><br><span class="line">    train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">    model_name=model.replace(<span class="string">&#x27;.pkl&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;当前模型为<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    model_path=os.path.join(m_path,model_copy)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">    train_data = pd.read_csv(train_data_path)</span><br><span class="line">    temp_X=X</span><br><span class="line">    y_pred=model.predict(X)</span><br><span class="line">    <span class="built_in">print</span>(y_pred)</span><br><span class="line">    temp_X[<span class="string">&#x27;洪水概率&#x27;</span>]=y_pred</span><br><span class="line">    temp_X[<span class="string">&#x27;id&#x27;</span>]=train_data[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):    </span><br><span class="line">        temp=temp_X[temp_X[<span class="string">&#x27;洪水概率&#x27;</span>]==i]</span><br><span class="line">        temp[<span class="string">&#x27;洪水概率&#x27;</span>]=dic[<span class="string">f&#x27;[<span class="subst">&#123;i&#125;</span>]&#x27;</span>]</span><br><span class="line">        name=dic[<span class="string">f&#x27;[<span class="subst">&#123;i&#125;</span>]&#x27;</span>]</span><br><span class="line">        csv_path=<span class="string">&#x27;../Data/3_means/&#x27;</span></span><br><span class="line">        temp.to_csv(csv_path+<span class="string">f&#x27;<span class="subst">&#123;model_name&#125;</span>&#x27;</span>+<span class="string">&#x27;/&#x27;</span>+<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>.csv&#x27;</span>,index=<span class="literal">False</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    entropy_list.append(calculate_entropy(y_pred))</span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;模型&#x27;</span>: [<span class="string">&#x27;线性回归&#x27;</span>,<span class="string">&#x27;梯度提升树&#x27;</span>,<span class="string">&#x27;决策树&#x27;</span>,<span class="string">&#x27;随机森林&#x27;</span>,<span class="string">&#x27;逻辑回归&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;熵值&#x27;</span>: entropy_list</span><br><span class="line">&#125;)</span><br><span class="line">df.plot(kind=<span class="string">&#x27;bar&#x27;</span>, x=<span class="string">&#x27;模型&#x27;</span>, y=<span class="string">&#x27;熵值&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">f&#x27;不同模型的灵敏度&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;模型&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;熵值&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><pre><code>当前模型为linear.pkl
[2 2 2 ... 2 2 1]


C:\Users\12780\AppData\Local\Temp\ipykernel_30044\4235761800.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  temp['洪水概率']=dic[f'[&#123;i&#125;]']


当前模型为gb_tree.pkl
[2 2 2 ... 2 2 1]


C:\Users\12780\AppData\Local\Temp\ipykernel_30044\4235761800.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  temp['洪水概率']=dic[f'[&#123;i&#125;]']


当前模型为ju_tree.pkl
[2 0 2 ... 2 0 1]


C:\Users\12780\AppData\Local\Temp\ipykernel_30044\4235761800.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  temp['洪水概率']=dic[f'[&#123;i&#125;]']


当前模型为rf_forest.pkl
[2 0 2 ... 0 0 2]


C:\Users\12780\AppData\Local\Temp\ipykernel_30044\4235761800.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  temp['洪水概率']=dic[f'[&#123;i&#125;]']


当前模型为logistic.pkl
[2 2 2 ... 2 2 1]


C:\Users\12780\AppData\Local\Temp\ipykernel_30044\4235761800.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  temp['洪水概率']=dic[f'[&#123;i&#125;]']
</code></pre><p><img data-src="output_72_10.png" alt="png"></p><h2 id="problem-three-从不同指标集建立洪水的预测模型"><a class="anchor" href="#problem-three-从不同指标集建立洪水的预测模型">#</a> Problem THREE 从不同指标集建立洪水的预测模型</h2><h3 id="利用半指标集重新训练模型"><a class="anchor" href="#利用半指标集重新训练模型">#</a> 利用半指标集重新训练模型</h3><h4 id="数据读入与划分"><a class="anchor" href="#数据读入与划分">#</a> 数据读入与划分</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line">X=X[ten_columns]</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p></p><h4 id="多元线性回归"><a class="anchor" href="#多元线性回归">#</a> 多元线性回归</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.3784994742361012
均方误差为: 0.0016154793779730408
模型的系数为: [0.00505567 0.00496704 0.00500715 0.00496954 0.00500404 0.00502968
 0.00496992 0.00502803 0.00500999 0.00495857]
模型的截距为: 0.25771755494783694
余弦相似度为0.9968516261349822
</code></pre><h4 id="梯度提升树"><a class="anchor" href="#梯度提升树">#</a> 梯度提升树</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">n_estimators = <span class="number">1200</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 计算每轮迭代的损失值</span></span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制损失曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances)), feature_importances, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><pre><code>Model Score : 0.3824856460268581
特征重要性: [0.10102888 0.10200613 0.10115558 0.09723603 0.10126572 0.099669
 0.09905089 0.10173171 0.0999321  0.09692395]
余弦相似度为0.9968718544406769
均方误差为0.001605118037864582
</code></pre><p><img data-src="output_80_1.png" alt="png"></p><p><img data-src="output_80_2.png" alt="png"></p><h4 id="决策树"><a class="anchor" href="#决策树">#</a> 决策树</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model Score : -0.374990821871241
特征重要性: [0.1000415  0.09823199 0.10070063 0.10061585 0.10017652 0.10010876
 0.10082496 0.10043421 0.09926113 0.09960446]
</code></pre><p><img data-src="output_82_1.png" alt="png"></p><pre><code>余弦相似度为0.9930461306478898
均方误差为0.0035740425398755465
</code></pre><h4 id="随机森林"><a class="anchor" href="#随机森林">#</a> 随机森林</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>)  <span class="comment"># 使用100棵树</span></span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.20128404918507747
均方误差为: 0.002076119156638994
余弦相似度为0.995952481321254
特征重要性: [0.09941711 0.09822213 0.09985066 0.10101741 0.10049458 0.10042171
 0.10182472 0.09817133 0.09894364 0.10163671]
</code></pre><p><img data-src="output_84_1.png" alt="png"></p><h3 id="利用核心指标集重新训练模型"><a class="anchor" href="#利用核心指标集重新训练模型">#</a> 利用核心指标集重新训练模型</h3><h4 id="数据读入-3"><a class="anchor" href="#数据读入-3">#</a> 数据读入</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_data_path=<span class="string">&#x27;../Data/train.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(train_data_path)</span><br><span class="line">train_data = train_data.drop(columns=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">X=train_data.drop(columns=<span class="string">&#x27;洪水概率&#x27;</span>)</span><br><span class="line"><span class="comment"># 在这里进行数据指标的选择</span></span><br><span class="line">X=X[five_columns]</span><br><span class="line">y=train_data[<span class="string">&#x27;洪水概率&#x27;</span>]</span><br><span class="line">y=np.array(y)</span><br><span class="line"><span class="comment">#y=-np.log(1/y-1)</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p></p><h4 id="多元线性回归-2"><a class="anchor" href="#多元线性回归-2">#</a> 多元线性回归</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">model_line=LinearRegression()</span><br><span class="line">model_line.fit(X_train,y_train)</span><br><span class="line">y_pred = model_line.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = model_line.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数为: <span class="subst">&#123;model_line.coef_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距为: <span class="subst">&#123;model_line.intercept_&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.18377552727859114
均方误差为: 0.0021216294255867996
模型的系数为: [0.00484612 0.00472107 0.00476777 0.00478113 0.00485277]
模型的截距为: 0.38629614715941074
余弦相似度为0.9958631584222024
</code></pre><h4 id="梯度提升树-2"><a class="anchor" href="#梯度提升树-2">#</a> 梯度提升树</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># 设置迭代次数为100</span></span><br><span class="line">n_estimators = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 创建并训练梯度提升树回归模型</span></span><br><span class="line">gb_model = GradientBoostingRegressor(n_estimators=n_estimators, random_state=<span class="number">42</span>)</span><br><span class="line">gb_model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">gb_score  = gb_model.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model Score : <span class="subst">&#123;gb_score&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = gb_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 计算每轮迭代的损失值</span></span><br><span class="line">train_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_train)):</span><br><span class="line">    train_loss[i] = mean_squared_error(y_train, y_pred)</span><br><span class="line"></span><br><span class="line">test_loss = np.zeros((gb_model.n_estimators,), dtype=np.float64)</span><br><span class="line"><span class="keyword">for</span> i, y_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(gb_model.staged_predict(X_test)):</span><br><span class="line">    test_loss[i] = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = gb_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制损失曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), train_loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, gb_model.n_estimators + <span class="number">1</span>), test_loss, label=<span class="string">&#x27;Test Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Mean Squared Error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Test Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><pre><code>Model Score : 0.1869662372495572
特征重要性: [0.19886279 0.20055476 0.19955611 0.19646798 0.20455835]
余弦相似度为0.9958793642766769
均方误差为0.002113335746103821
</code></pre><p><img data-src="output_91_1.png" alt="png"></p><h4 id="决策树-2"><a class="anchor" href="#决策树-2">#</a> 决策树</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="comment"># 创建并训练决策树回归模型</span></span><br><span class="line">tree_model = DecisionTreeRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line">tree_score = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model Score :&quot;</span>, tree_score)</span><br><span class="line"><span class="comment"># 输出特征重要性</span></span><br><span class="line">feature_importances = tree_model.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line"><span class="comment"># 将特征重要性展平</span></span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = tree_model.predict(X_test)</span><br><span class="line">theta = cosine(y_pred,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;theta&#125;</span>&#x27;</span>)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;均方误差为<span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Model Score : 0.06299371070798276
特征重要性: [0.19883327 0.20094005 0.20195499 0.19803891 0.20023278]
</code></pre><p><img data-src="output_93_1.png" alt="png"></p><pre><code>余弦相似度为0.9952506949628717
均方误差为0.002435580139729984
</code></pre><h4 id="随机森林-2"><a class="anchor" href="#随机森林-2">#</a> 随机森林</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">200</span>, random_state=<span class="number">42</span>) </span><br><span class="line">rf.fit(X_train, y_train)</span><br><span class="line">y_pred = rf.predict(X_test)</span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line">score = rf.score(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Model score: <span class="subst">&#123;score&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;均方误差为: <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line">accuracy = cosine(y_test,y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;余弦相似度为<span class="subst">&#123;accuracy&#125;</span>&#x27;</span>)</span><br><span class="line">feature_importances = rf.feature_importances_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征重要性:&quot;</span>, feature_importances)</span><br><span class="line">feature_importances_flat = np.ravel(feature_importances)</span><br><span class="line"><span class="comment"># 可视化特征重要性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">18</span>))</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(feature_importances_flat)), feature_importances_flat, tick_label=[<span class="string">f&#x27;<span class="subst">&#123;X_train.columns[i]&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(feature_importances_flat))])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Importance&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><pre><code>Model score: 0.09576091089289085
均方误差为: 0.002350407667659151
余弦相似度为0.9954166830354778
特征重要性: [0.19933654 0.19994322 0.20209151 0.19903125 0.19959747]
</code></pre><p><img data-src="output_95_1.png" alt="png"></p><h2 id="problem-four-预测洪水发生的概率"><a class="anchor" href="#problem-four-预测洪水发生的概率">#</a> Problem FOUR 预测洪水发生的概率</h2><h4 id="利用准确率最高的梯度提升树模型进行预测"><a class="anchor" href="#利用准确率最高的梯度提升树模型进行预测">#</a> 利用准确率最高的梯度提升树模型进行预测</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data_path = <span class="string">&#x27;../Data/test.csv&#x27;</span></span><br><span class="line">data=pd.read_csv(data_path)</span><br><span class="line">data=data.drop(columns=[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;洪水概率&#x27;</span>])</span><br><span class="line">model_path=<span class="string">&#x27;../Model/gb_tree.pkl&#x27;</span></span><br><span class="line">model=joblib.load(model_path)</span><br><span class="line">y_pred=model.predict(data)</span><br><span class="line">data_path=<span class="string">&#x27;../Data/submit.csv&#x27;</span></span><br><span class="line">df=pd.read_csv(data_path)</span><br><span class="line">df[<span class="string">&#x27;洪水概率&#x27;</span>]=y_pred</span><br><span class="line">df=df[[<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;洪水概率&#x27;</span>]]</span><br><span class="line">df.to_csv(<span class="string">&#x27;../Data/submit.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p></p><h4 id="利用直方图与折线图可视化结果"><a class="anchor" href="#利用直方图与折线图可视化结果">#</a> 利用直方图与折线图可视化结果</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">data=y_pred</span><br><span class="line">data=np.array(data)</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个子图：直方图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.hist(data, bins=<span class="number">30</span>, alpha=<span class="number">0.5</span>, color=<span class="string">&#x27;blue&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个子图：折线图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(np.random.choice(data,<span class="built_in">int</span>(<span class="number">0.001</span>*<span class="built_in">len</span>(data))), color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Index&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图表</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>​<br><img data-src="output_100_0.png" alt="png"><br>​</p><h4 id="判别是否服从正态分布"><a class="anchor" href="#判别是否服从正态分布">#</a> 判别是否服从正态分布</h4><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> stats</span><br><span class="line">normalized_data = (data - np.mean(data)) / np.std(data)</span><br><span class="line"></span><br><span class="line">ks_stat, ks_p = stats.kstest(normalized_data, <span class="string">&#x27;norm&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nKolmogorov-Smirnov Test:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Statistics:&quot;</span>, ks_stat)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;p-value:&quot;</span>, ks_p)</span><br><span class="line"><span class="keyword">if</span> ks_p &lt; <span class="number">0.05</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;不服从正态分布).&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;服从正态分布&quot;</span>)</span><br></pre></td></tr></table></figure><p></p><pre><code>Kolmogorov-Smirnov Test:
Statistics: 0.05078130889692345
p-value: 0.0
不服从正态分布).
</code></pre><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a> <a href="/tags/code/" rel="tag"><i class="ic i-tag"></i> code</a> <a href="/tags/recommendation/" rel="tag"><i class="ic i-tag"></i> recommendation</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-07-06 21:10:04" itemprop="dateModified" datetime="2024-07-06T21:10:04+08:00">2024-07-06</time> </span><span id="bit/code/" class="item leancloud_visitors" data-flag-title="亚太数模——洪水" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Hexo</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/bit/code/" title="亚太数模——洪水">https://enjundu.github.io/bit/code/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;n89zJmuTd1cqNrW.jpg" title="亚太数模——新能源汽车"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> BIT-study</span><h3>亚太数模——新能源汽车</h3></a></div><div class="item right"><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%89/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;flquHABaRmV2onx.jpg" title="数码管扫描点亮电路"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> 数字逻辑实验</span><h3>数码管扫描点亮电路</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#before-problem-%E6%95%B0%E6%8D%AE%E4%BC%A0%E5%85%A5%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.</span> <span class="toc-text">Before Problem -- 数据传入与预处理，全局函数设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93"><span class="toc-number">1.1.</span> <span class="toc-text">导入必要的库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5"><span class="toc-number">1.2.</span> <span class="toc-text">数据读入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8Etraincsv%E8%AF%BB%E5%85%A5train%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.1.</span> <span class="toc-text">从 train.csv 读入 train 数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%80%E8%A6%81%E5%88%86%E6%9E%90"><span class="toc-number">1.4.</span> <span class="toc-text">数据相关性简要分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E4%B8%89%E4%B8%AA%E6%B0%B4%E5%B9%B3%E7%9A%84%E6%8C%87%E6%A0%87%E9%9B%86"><span class="toc-number">1.5.</span> <span class="toc-text">建立三个水平的指标集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E8%BF%87%E6%BB%A4%E6%B3%95%E8%8E%B7%E5%8F%96%E6%8C%87%E6%A0%87%E9%9B%86"><span class="toc-number">1.5.1.</span> <span class="toc-text">利用过滤法获取指标集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.6.</span> <span class="toc-text">全局函数设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%8E%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">1.7.</span> <span class="toc-text">划分训练集与测试集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-one-%E5%85%A8%E6%8C%87%E6%A0%87%E9%9B%86%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E4%B8%8E%E6%B1%82%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text">Problem ONE -- 全指标集数学模型建立与求解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">2.1.</span> <span class="toc-text">模型一 线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91"><span class="toc-number">2.2.</span> <span class="toc-text">模型二 梯度提升树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%89-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.3.</span> <span class="toc-text">模型三 决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%9B%9B-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.4.</span> <span class="toc-text">模型四 随机森林</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-two-%E9%A3%8E%E9%99%A9%E8%81%9A%E7%B1%BB"><span class="toc-number">3.</span> <span class="toc-text">Problem TWO 风险聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">3.1.</span> <span class="toc-text">读入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95kmeans"><span class="toc-number">3.2.</span> <span class="toc-text">聚类算法：Kmeans</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">聚类预测函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8Bkmeans%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.2.</span> <span class="toc-text">建立 Kmeans 模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E8%81%9A%E7%B1%BB%E4%B8%AD%E5%BF%83%E5%88%B0%E9%A3%8E%E9%99%A9%E7%9A%84%E6%98%A0%E5%B0%84%E5%AD%97%E5%85%B8"><span class="toc-number">3.2.3.</span> <span class="toc-text">建立聚类中心到风险的映射字典</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.2.4.</span> <span class="toc-text">示例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E9%A3%8E%E9%99%A9%E9%A2%84%E8%AD%A6%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.</span> <span class="toc-text">基于风险预警的预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B-mymodel"><span class="toc-number">3.3.1.</span> <span class="toc-text">模型建立 MyModel</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5-2"><span class="toc-number">3.4.</span> <span class="toc-text">数据读入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%85%88%E5%89%8D%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.4.1.</span> <span class="toc-text">利用先前模型构建自定义的分类模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">3.4.2.</span> <span class="toc-text">逻辑回归</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%81%B5%E6%95%8F%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">3.5.</span> <span class="toc-text">模型灵敏度分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E7%86%B5%E7%9A%84%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0-calculate_entropy"><span class="toc-number">3.5.1.</span> <span class="toc-text">设置熵的计算函数 calculate_entropy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%9F%BA%E4%BA%8E%E5%B1%9E%E6%80%A7%E5%8F%98%E5%8C%96%E7%8E%87%E7%9A%84%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0-average_change_rate"><span class="toc-number">3.5.2.</span> <span class="toc-text">设置基于属性变化率的计算函数 average_change_rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%9F%BA%E4%BA%8E%E5%B1%9E%E6%80%A7%E5%AF%B9%E6%A6%82%E7%8E%87%E5%8F%98%E5%8C%96%E7%8E%87%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">3.5.3.</span> <span class="toc-text">启动基于属性对概率变化率的灵敏度计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%9F%BA%E4%BA%8E%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E7%86%B5%E5%80%BC%E7%9A%84%E7%81%B5%E6%95%8F%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">3.5.4.</span> <span class="toc-text">启动基于预测结果的熵值的灵敏度计算</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-three-%E4%BB%8E%E4%B8%8D%E5%90%8C%E6%8C%87%E6%A0%87%E9%9B%86%E5%BB%BA%E7%AB%8B%E6%B4%AA%E6%B0%B4%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">Problem THREE 从不同指标集建立洪水的预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%8D%8A%E6%8C%87%E6%A0%87%E9%9B%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">利用半指标集重新训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">4.1.1.</span> <span class="toc-text">数据读入与划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.1.2.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91"><span class="toc-number">4.1.3.</span> <span class="toc-text">梯度提升树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">4.1.4.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">4.1.5.</span> <span class="toc-text">随机森林</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E6%A0%B8%E5%BF%83%E6%8C%87%E6%A0%87%E9%9B%86%E9%87%8D%E6%96%B0%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">利用核心指标集重新训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5-3"><span class="toc-number">4.2.1.</span> <span class="toc-text">数据读入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-2"><span class="toc-number">4.2.2.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91-2"><span class="toc-number">4.2.3.</span> <span class="toc-text">梯度提升树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91-2"><span class="toc-number">4.2.4.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-2"><span class="toc-number">4.2.5.</span> <span class="toc-text">随机森林</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-four-%E9%A2%84%E6%B5%8B%E6%B4%AA%E6%B0%B4%E5%8F%91%E7%94%9F%E7%9A%84%E6%A6%82%E7%8E%87"><span class="toc-number">5.</span> <span class="toc-text">Problem FOUR 预测洪水发生的概率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%87%86%E7%A1%AE%E7%8E%87%E6%9C%80%E9%AB%98%E7%9A%84%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">5.0.1.</span> <span class="toc-text">利用准确率最高的梯度提升树模型进行预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E7%9B%B4%E6%96%B9%E5%9B%BE%E4%B8%8E%E6%8A%98%E7%BA%BF%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="toc-number">5.0.2.</span> <span class="toc-text">利用直方图与折线图可视化结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A4%E5%88%AB%E6%98%AF%E5%90%A6%E6%9C%8D%E4%BB%8E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">5.0.3.</span> <span class="toc-text">判别是否服从正态分布</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/bit/%E7%BE%8E%E8%B5%9B%E2%80%94%E2%80%94%E4%B8%83%E9%B3%83%E9%B3%97/" rel="bookmark" title="美赛——七鳃鳗">美赛——七鳃鳗</a></li><li class="active"><a href="/bit/code/" rel="bookmark" title="亚太数模——洪水">亚太数模——洪水</a></li><li><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" rel="bookmark" title="亚太数模——新能源汽车">亚太数模——新能源汽车</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">42</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">9</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">5</span> <span class="name">tags</span></a></div></nav><div class="social"></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/shudian/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C%E4%B8%89/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/bit/" title="In BIT-study">BIT-study</a></div><span><a href="/bit/%E7%BE%8E%E8%B5%9B%E2%80%94%E2%80%94%E4%B8%83%E9%B3%83%E9%B3%97/" title="美赛——七鳃鳗">美赛——七鳃鳗</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/8_pytorch-lr-finder-master/" title="pytorch-lr-finder">pytorch-lr-finder</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEA/" title="In 单片机小学期ECEA">单片机小学期ECEA</a></div><span><a href="/ECEA/1%E7%82%B9%E4%BA%AE%E7%81%AF/" title="LED lighting program">LED lighting program</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E9%AA%8C/" title="数据结构实验">数据结构实验</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/3_robotframework-webservice-master/" title="robotframework-webservice">robotframework-webservice</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/7_ttach-master/" title="ttach">ttach</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/redis-dict.c%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="DICT.C源码阅读报告">DICT.C源码阅读报告</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/recommendation/" title="In 推荐算法相关search">推荐算法相关search</a></div><span><a href="/recommendation/README/" title="b_README">b_README</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E5%93%88%E4%BD%9B%E5%A4%A7%E4%BD%9C%E4%B8%9A/" title="哈佛数据库大作业">哈佛数据库大作业</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E6%95%B0%E5%AD%97%E7%BB%8F%E6%B5%8E%EF%BC%9A%E7%A7%91%E6%8A%80%E5%88%9B%E6%96%B0%E5%92%8C%E4%BC%81%E4%B8%9A%E8%BD%AC%E5%9E%8B_%E9%80%9A%E8%AF%86%E7%BB%93%E8%AF%BE%E8%AE%BA%E6%96%87/" title="数字经济：科技创新和企业转型_通识结课论文">数字经济：科技创新和企业转型_通识结课论文</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"bit/code/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->