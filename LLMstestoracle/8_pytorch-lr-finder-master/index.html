<!-- build time:Sat Aug 03 2024 22:56:28 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Hexo" href="https://enjundu.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Hexo" href="https://enjundu.github.io/atom.xml"><link rel="alternate" type="application/json" title="Hexo" href="https://enjundu.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Hexo,Front Matter"><link rel="canonical" href="https://enjundu.github.io/LLMstestoracle/8_pytorch-lr-finder-master/"><title>pytorch-lr-finder - LLM的test oracle生成 | 蓝天の网站 = Hexo</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">pytorch-lr-finder</h1><div class="meta"><span class="item" title="Created: 2024-07-03 02:08:35"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-07-03T02:08:35+08:00">2024-07-03</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">蓝天の网站</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2024/07/03/sTHU7wL5qkSiloC.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/NDKVsh3T5XY8lnp.gif"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/cI2aroK5AZfHs7U.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/8ONjfHLDzZ4YiCJ.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/04/l29P4JN75BkxmQu.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2024/07/03/qk7VYGUEtZ2oeyB.gif"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/LLMstestoracle/" itemprop="item" rel="index" title="In LLM的test oracle生成"><span itemprop="name">LLM的test oracle生成</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://enjundu.github.io/LLMstestoracle/8_pytorch-lr-finder-master/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jack Du"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hexo"></span><div class="body md" itemprop="articleBody"><h1 id="pytorch-lr-finder"><a class="anchor" href="#pytorch-lr-finder">#</a> <strong><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RhdmlkdHZzL3B5dG9yY2gtbHItZmluZGVy">pytorch-lr-finder</span></strong></h1><h2 id="简介"><a class="anchor" href="#简介">#</a> 简介</h2><ul><li><p>该项目为 PyTorch 学习率查找器</p></li><li><p>学习率范围测试是一种提供有关最佳学习率的宝贵信息的测试。在预训练运行期间，学习率在两个边界之间线性或指数增加。较低的初始学习率允许网络开始收敛，随着学习率的增加，它最终会变得太大，网络会发散。</p></li><li><p>来自 fastai 的调整版本：以指数方式增加学习率并计算每个学习率的训练损失。 <code>lr_finder.plot()</code> 绘制训练损失与对数学习率的关系。</p></li><li><p>Leslie Smith 的方法：线性增加学习率并计算每个学习率的评估损失。 <code>lr_finder.plot()</code> 绘制评估损失与学习率的关系图。这种方法通常会产生更精确的曲线，因为评估损失更容易发散，但执行测试所需的时间会更长，尤其是在评估数据集很大的情况下。</p><h2 id="test_lr_finderpy代码分析"><a class="anchor" href="#test_lr_finderpy代码分析">#</a> test_lr_finder.py 代码分析</h2><h3 id="该test原代码"><a class="anchor" href="#该test原代码">#</a> 该 test 原代码</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder <span class="keyword">import</span> LRFinder</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder.lr_finder <span class="keyword">import</span> (</span><br><span class="line">    DataLoaderIter, TrainDataLoaderIter, ValDataLoaderIter</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> task <span class="keyword">as</span> mod_task</span><br><span class="line"><span class="keyword">import</span> dataset <span class="keyword">as</span> mod_dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check available backends for mixed precision training</span></span><br><span class="line">AVAILABLE_AMP_BACKENDS = []</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> apex.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;apex&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> torch.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collect_task_classes</span>():</span><br><span class="line">    names = [v <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">dir</span>(mod_task) <span class="keyword">if</span> v.endswith(<span class="string">&quot;Task&quot;</span>) <span class="keyword">and</span> v != <span class="string">&quot;BaseTask&quot;</span>]</span><br><span class="line">    attrs = [<span class="built_in">getattr</span>(mod_task, v) <span class="keyword">for</span> v <span class="keyword">in</span> names]</span><br><span class="line">    classes = [v <span class="keyword">for</span> v <span class="keyword">in</span> attrs <span class="keyword">if</span> <span class="built_in">issubclass</span>(v, mod_task.BaseTask)]</span><br><span class="line">    <span class="keyword">return</span> classes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_lr_finder</span>(<span class="params">task, **kwargs</span>):</span><br><span class="line">    model = task.model</span><br><span class="line">    optimizer = task.optimizer</span><br><span class="line">    criterion = task.criterion</span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">&quot;device&quot;</span>: kwargs.get(<span class="string">&quot;device&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;memory_cache&quot;</span>: kwargs.get(<span class="string">&quot;memory_cache&quot;</span>, <span class="literal">True</span>),</span><br><span class="line">        <span class="string">&quot;cache_dir&quot;</span>: kwargs.get(<span class="string">&quot;cache_dir&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_backend&quot;</span>: kwargs.get(<span class="string">&quot;amp_backend&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_config&quot;</span>: kwargs.get(<span class="string">&quot;amp_config&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;grad_scaler&quot;</span>: kwargs.get(<span class="string">&quot;grad_scaler&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    &#125;</span><br><span class="line">    lr_finder = LRFinder(model, optimizer, criterion, **config)</span><br><span class="line">    <span class="keyword">return</span> lr_finder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_optim_lr</span>(<span class="params">optimizer</span>):</span><br><span class="line">    <span class="keyword">return</span> [grp[<span class="string">&quot;lr&quot;</span>] <span class="keyword">for</span> grp <span class="keyword">in</span> optimizer.param_groups]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_loader_iter</span>(<span class="params">loader_iter, desired_runs=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run a `DataLoaderIter` object for specific times.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        loader_iter (torch_lr_finder.DataLoaderIter): the iterator to test.</span></span><br><span class="line"><span class="string">        desired_runs (int, optional): times that iterator should be iterated.</span></span><br><span class="line"><span class="string">            If it&#x27;s not given, `len(loader_iter.data_loader)` will be used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        is_achieved (bool): False if `loader_iter` cannot be iterated specific</span></span><br><span class="line"><span class="string">            times. It usually means `loader_iter` has raised `StopIteration`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(loader_iter, DataLoaderIter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> desired_runs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        desired_runs = <span class="built_in">len</span>(loader_iter.data_loader)</span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(desired_runs):</span><br><span class="line">            <span class="built_in">next</span>(loader_iter)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> desired_runs == count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestRangeTest</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check whether lr is actually changed</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">max</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt;= init_lrs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check whether lr is actually changed</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">max</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt;= init_lrs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check whether lr is actually changed</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">max</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt;= init_lrs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check whether lr is actually changed</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">max</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt;= init_lrs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestReset</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;cls_task&quot;</span>, [mod_task.XORTask, mod_task.DiscriminativeLearningRateTask],</span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_reset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line">        lr_finder.reset()</span><br><span class="line"></span><br><span class="line">        restored_lrs = get_optim_lr(task.optimizer)</span><br><span class="line">        <span class="keyword">assert</span> init_lrs == restored_lrs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestLRHistory</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_linear_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;linear&quot;</span>, end_lr=<span class="number">5e-5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) == <span class="number">5</span></span><br><span class="line">        <span class="keyword">assert</span> lr_finder.history[<span class="string">&quot;lr&quot;</span>] == pytest.approx([<span class="number">1e-5</span>, <span class="number">2e-5</span>, <span class="number">3e-5</span>, <span class="number">4e-5</span>, <span class="number">5e-5</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_exponential_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;exp&quot;</span>, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) == <span class="number">5</span></span><br><span class="line">        <span class="keyword">assert</span> lr_finder.history[<span class="string">&quot;lr&quot;</span>] == pytest.approx([<span class="number">1e-5</span>, <span class="number">1e-4</span>, <span class="number">1e-3</span>, <span class="number">1e-2</span>, <span class="number">0.1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestGradientAccumulation</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        spy = mocker.spy(lr_finder, <span class="string">&quot;criterion&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> We are using smaller batch size to simulate a large batch.</span></span><br><span class="line">        <span class="comment"># So that the actual times of model/criterion called should be</span></span><br><span class="line">        <span class="comment"># `(desired_bs/real_bs) * num_iter` == `accum_steps * num_iter`</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == accum_steps * num_iter</span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`apex` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_apex_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == accum_steps * num_iter</span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;torch&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`torch.amp` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_torch_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Config for `torch.amp`. Though `torch.amp.autocast` supports various</span></span><br><span class="line">        <span class="comment"># device types, we test it with CUDA only.</span></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == accum_steps * num_iter</span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    reason=<span class="string">&quot;`apex` module and gpu is required to run these tests.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestMixedPrecision</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_apex</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">hasattr</span>(task.optimizer, <span class="string">&quot;_amp_stash&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Here we did not perform gradient accumulation, so that call count</span></span><br><span class="line">        <span class="comment"># of `amp.scale_loss` should equal to `num_iter`.</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_torch</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Here we did not perform gradient accumulation, so that call count</span></span><br><span class="line">        <span class="comment"># of `amp.scale_loss` should equal to `num_iter`.</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestDataLoaderIter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_traindataloaderiter</span>(<span class="params">self</span>):</span><br><span class="line">        batch_size, data_length = <span class="number">32</span>, <span class="number">256</span></span><br><span class="line">        dataset = mod_dataset.RandomDataset(data_length)</span><br><span class="line">        dataloader = DataLoader(dataset, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        loader_iter = TrainDataLoaderIter(dataloader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> run_loader_iter(loader_iter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># `TrainDataLoaderIter` can reset itself, so that it&#x27;s ok to reuse it</span></span><br><span class="line">        <span class="comment"># directly and iterate it more than `len(dataloader)` times.</span></span><br><span class="line">        <span class="keyword">assert</span> run_loader_iter(loader_iter, desired_runs=<span class="built_in">len</span>(dataloader) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_valdataloaderiter</span>(<span class="params">self</span>):</span><br><span class="line">        batch_size, data_length = <span class="number">32</span>, <span class="number">256</span></span><br><span class="line">        dataset = mod_dataset.RandomDataset(data_length)</span><br><span class="line">        dataloader = DataLoader(dataset, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        loader_iter = ValDataLoaderIter(dataloader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> run_loader_iter(loader_iter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># `ValDataLoaderIter` can&#x27;t reset itself, so this should be False if</span></span><br><span class="line">        <span class="comment"># we re-run it without resetting it.</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> run_loader_iter(loader_iter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Reset it by `iter()`</span></span><br><span class="line">        loader_iter = <span class="built_in">iter</span>(loader_iter)</span><br><span class="line">        <span class="keyword">assert</span> run_loader_iter(loader_iter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># `ValDataLoaderIter` can&#x27;t be iterated more than `len(dataloader)` times</span></span><br><span class="line">        loader_iter = ValDataLoaderIter(dataloader)</span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> run_loader_iter(loader_iter, desired_runs=<span class="built_in">len</span>(dataloader) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_traindataloaderiter</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        spy = mocker.spy(loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(loader_iter, num_iter=num_iter)</span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_valdataloaderiter</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        task = mod_task.XORTask(validate=<span class="literal">True</span>)</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        train_loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        val_loader_iter = ValDataLoaderIter(task.val_loader)</span><br><span class="line">        spy_train = mocker.spy(train_loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line">        spy_val = mocker.spy(val_loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            train_loader_iter, val_loader=val_loader_iter, num_iter=num_iter</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">assert</span> spy_train.call_count == num_iter</span><br><span class="line">        <span class="keyword">assert</span> spy_val.call_count == num_iter * <span class="built_in">len</span>(task.val_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_trainloaderiter_without_subclassing</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        loader_iter = CustomLoaderIter(task.train_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;`train_loader` has unsupported type&quot;</span>):</span><br><span class="line">            lr_finder.range_test(loader_iter, num_iter=num_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_valloaderiter_without_subclassing</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask(validate=<span class="literal">True</span>)</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        train_loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        val_loader_iter = CustomLoaderIter(task.val_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;`val_loader` has unsupported type&quot;</span>):</span><br><span class="line">            lr_finder.range_test(</span><br><span class="line">                train_loader_iter, val_loader=val_loader_iter, num_iter=num_iter</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomLoaderIter</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;This class does not inherit from `DataLoaderIter`, should be used to</span></span><br><span class="line"><span class="string">    trigger exceptions related to type checking.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, loader</span>):</span><br><span class="line">        self.loader = loader</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(self.loader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;num_iter&quot;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;scheduler&quot;</span>, [<span class="string">&quot;exp&quot;</span>, <span class="string">&quot;linear&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_scheduler_and_num_iter</span>(<span class="params">num_iter, scheduler</span>):</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line">    <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;num_iter&quot;</span>):</span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, step_mode=scheduler, end_lr=<span class="number">5e-5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;suggest_lr&quot;</span>, [<span class="literal">False</span>, <span class="literal">True</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;skip_start&quot;</span>, [<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;skip_end&quot;</span>, [<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_plot_with_skip_and_suggest_lr</span>(<span class="params">suggest_lr, skip_start, skip_end</span>):</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    num_iter = <span class="number">11</span></span><br><span class="line">    <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line">    lr_finder.range_test(</span><br><span class="line">        task.train_loader, num_iter=num_iter, step_mode=<span class="string">&quot;exp&quot;</span>, end_lr=<span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    results = lr_finder.plot(</span><br><span class="line">        skip_start=skip_start, skip_end=skip_end, suggest_lr=suggest_lr, ax=ax</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_iter - skip_start - skip_end &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># handle data with one or zero lr</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.lines) == <span class="number">1</span></span><br><span class="line">        <span class="keyword">assert</span> results <span class="keyword">is</span> ax</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># handle different suggest_lr</span></span><br><span class="line">        <span class="comment"># for &#x27;steepest&#x27;: the point with steepest gradient (minimal gradient)</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.lines) == <span class="number">1</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.collections) == <span class="built_in">int</span>(suggest_lr)</span><br><span class="line">        <span class="keyword">if</span> results <span class="keyword">is</span> <span class="keyword">not</span> ax:</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(results) == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_suggest_lr</span>():</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line"></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">10</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">16</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss with minimal gradient is the first element in history</span></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss with minimal gradient is the last element in history</span></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) - <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p><h3 id="删除assert和必要提示后上传llm的代码"><a class="anchor" href="#删除assert和必要提示后上传llm的代码">#</a> 删除 assert 和必要提示后上传 LLM 的代码</h3><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder <span class="keyword">import</span> LRFinder</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder.lr_finder <span class="keyword">import</span> (</span><br><span class="line">    DataLoaderIter, TrainDataLoaderIter, ValDataLoaderIter</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> task <span class="keyword">as</span> mod_task</span><br><span class="line"><span class="keyword">import</span> dataset <span class="keyword">as</span> mod_dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check available backends for mixed precision training</span></span><br><span class="line">AVAILABLE_AMP_BACKENDS = []</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> apex.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;apex&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> torch.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collect_task_classes</span>():</span><br><span class="line">    names = [v <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">dir</span>(mod_task) <span class="keyword">if</span> v.endswith(<span class="string">&quot;Task&quot;</span>) <span class="keyword">and</span> v != <span class="string">&quot;BaseTask&quot;</span>]</span><br><span class="line">    attrs = [<span class="built_in">getattr</span>(mod_task, v) <span class="keyword">for</span> v <span class="keyword">in</span> names]</span><br><span class="line">    classes = [v <span class="keyword">for</span> v <span class="keyword">in</span> attrs <span class="keyword">if</span> <span class="built_in">issubclass</span>(v, mod_task.BaseTask)]</span><br><span class="line">    <span class="keyword">return</span> classes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_lr_finder</span>(<span class="params">task, **kwargs</span>):</span><br><span class="line">    model = task.model</span><br><span class="line">    optimizer = task.optimizer</span><br><span class="line">    criterion = task.criterion</span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">&quot;device&quot;</span>: kwargs.get(<span class="string">&quot;device&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;memory_cache&quot;</span>: kwargs.get(<span class="string">&quot;memory_cache&quot;</span>, <span class="literal">True</span>),</span><br><span class="line">        <span class="string">&quot;cache_dir&quot;</span>: kwargs.get(<span class="string">&quot;cache_dir&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_backend&quot;</span>: kwargs.get(<span class="string">&quot;amp_backend&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_config&quot;</span>: kwargs.get(<span class="string">&quot;amp_config&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;grad_scaler&quot;</span>: kwargs.get(<span class="string">&quot;grad_scaler&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    &#125;</span><br><span class="line">    lr_finder = LRFinder(model, optimizer, criterion, **config)</span><br><span class="line">    <span class="keyword">return</span> lr_finder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_optim_lr</span>(<span class="params">optimizer</span>):</span><br><span class="line">    <span class="keyword">return</span> [grp[<span class="string">&quot;lr&quot;</span>] <span class="keyword">for</span> grp <span class="keyword">in</span> optimizer.param_groups]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_loader_iter</span>(<span class="params">loader_iter, desired_runs=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> desired_runs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        desired_runs = <span class="built_in">len</span>(loader_iter.data_loader)</span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(desired_runs):</span><br><span class="line">            <span class="built_in">next</span>(loader_iter)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> desired_runs == count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestRangeTest</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestReset</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;cls_task&quot;</span>, [mod_task.XORTask, mod_task.DiscriminativeLearningRateTask],</span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_reset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line">        lr_finder.reset()</span><br><span class="line"></span><br><span class="line">        restored_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestLRHistory</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_linear_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;linear&quot;</span>, end_lr=<span class="number">5e-5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_exponential_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;exp&quot;</span>, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestGradientAccumulation</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        spy = mocker.spy(lr_finder, <span class="string">&quot;criterion&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`apex` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_apex_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;torch&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`torch.amp` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_torch_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Config for `torch.amp`. Though `torch.amp.autocast` supports various</span></span><br><span class="line">        <span class="comment"># device types, we test it with CUDA only.</span></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    reason=<span class="string">&quot;`apex` module and gpu is required to run these tests.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestMixedPrecision</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_apex</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Here we did not perform gradient accumulation, so that call count</span></span><br><span class="line">        <span class="comment"># of `amp.scale_loss` should equal to `num_iter`.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_torch</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestDataLoaderIter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_traindataloaderiter</span>(<span class="params">self</span>):</span><br><span class="line">        batch_size, data_length = <span class="number">32</span>, <span class="number">256</span></span><br><span class="line">        dataset = mod_dataset.RandomDataset(data_length)</span><br><span class="line">        dataloader = DataLoader(dataset, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        loader_iter = TrainDataLoaderIter(dataloader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_valdataloaderiter</span>(<span class="params">self</span>):</span><br><span class="line">        batch_size, data_length = <span class="number">32</span>, <span class="number">256</span></span><br><span class="line">        dataset = mod_dataset.RandomDataset(data_length)</span><br><span class="line">        dataloader = DataLoader(dataset, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        loader_iter = ValDataLoaderIter(dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_traindataloaderiter</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        spy = mocker.spy(loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(loader_iter, num_iter=num_iter)</span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_valdataloaderiter</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        task = mod_task.XORTask(validate=<span class="literal">True</span>)</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        train_loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        val_loader_iter = ValDataLoaderIter(task.val_loader)</span><br><span class="line">        spy_train = mocker.spy(train_loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line">        spy_val = mocker.spy(val_loader_iter, <span class="string">&quot;inputs_labels_from_batch&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            train_loader_iter, val_loader=val_loader_iter, num_iter=num_iter</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">assert</span> spy_train.call_count == num_iter</span><br><span class="line">        <span class="keyword">assert</span> spy_val.call_count == num_iter * <span class="built_in">len</span>(task.val_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_trainloaderiter_without_subclassing</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        loader_iter = CustomLoaderIter(task.train_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;`train_loader` has unsupported type&quot;</span>):</span><br><span class="line">            lr_finder.range_test(loader_iter, num_iter=num_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_range_test_with_valloaderiter_without_subclassing</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask(validate=<span class="literal">True</span>)</span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        num_iter = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        train_loader_iter = TrainDataLoaderIter(task.train_loader)</span><br><span class="line">        val_loader_iter = CustomLoaderIter(task.val_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;`val_loader` has unsupported type&quot;</span>):</span><br><span class="line">            lr_finder.range_test(</span><br><span class="line">                train_loader_iter, val_loader=val_loader_iter, num_iter=num_iter</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomLoaderIter</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;This class does not inherit from `DataLoaderIter`, should be used to</span></span><br><span class="line"><span class="string">    trigger exceptions related to type checking.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, loader</span>):</span><br><span class="line">        self.loader = loader</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(self.loader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;num_iter&quot;</span>, [<span class="number">0</span>, <span class="number">1</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;scheduler&quot;</span>, [<span class="string">&quot;exp&quot;</span>, <span class="string">&quot;linear&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_scheduler_and_num_iter</span>(<span class="params">num_iter, scheduler</span>):</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line">    <span class="keyword">with</span> pytest.raises(ValueError, <span class="keyword">match</span>=<span class="string">&quot;num_iter&quot;</span>):</span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, step_mode=scheduler, end_lr=<span class="number">5e-5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;suggest_lr&quot;</span>, [<span class="literal">False</span>, <span class="literal">True</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;skip_start&quot;</span>, [<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>]</span>)</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;skip_end&quot;</span>, [<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_plot_with_skip_and_suggest_lr</span>(<span class="params">suggest_lr, skip_start, skip_end</span>):</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    num_iter = <span class="number">11</span></span><br><span class="line">    <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line">    lr_finder.range_test(</span><br><span class="line">        task.train_loader, num_iter=num_iter, step_mode=<span class="string">&quot;exp&quot;</span>, end_lr=<span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    results = lr_finder.plot(</span><br><span class="line">        skip_start=skip_start, skip_end=skip_end, suggest_lr=suggest_lr, ax=ax</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_iter - skip_start - skip_end &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># handle data with one or zero lr</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.lines) == <span class="number">1</span></span><br><span class="line">        <span class="keyword">assert</span> results <span class="keyword">is</span> ax</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># handle different suggest_lr</span></span><br><span class="line">        <span class="comment"># for &#x27;steepest&#x27;: the point with steepest gradient (minimal gradient)</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.lines) == <span class="number">1</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(ax.collections) == <span class="built_in">int</span>(suggest_lr)</span><br><span class="line">        <span class="keyword">if</span> results <span class="keyword">is</span> <span class="keyword">not</span> ax:</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(results) == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_suggest_lr</span>():</span><br><span class="line">    task = mod_task.XORTask()</span><br><span class="line">    lr_finder = prepare_lr_finder(task)</span><br><span class="line"></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">10</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">16</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss with minimal gradient is the first element in history</span></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss with minimal gradient is the last element in history</span></span><br><span class="line">    lr_finder.history[<span class="string">&quot;loss&quot;</span>] = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>]</span><br><span class="line">    lr_finder.history[<span class="string">&quot;lr&quot;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax, lr = lr_finder.plot(skip_start=<span class="number">0</span>, skip_end=<span class="number">0</span>, suggest_lr=<span class="literal">True</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> lr == <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) - <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p><h3 id="llm自动填充assert后的代码"><a class="anchor" href="#llm自动填充assert后的代码">#</a> LLM 自动填充 assert 后的代码</h3><p>**base prompt 为：** 该 tests case 缺少 assert 断言 请你自动填充它</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder <span class="keyword">import</span> LRFinder</span><br><span class="line"><span class="keyword">from</span> torch_lr_finder.lr_finder <span class="keyword">import</span> (</span><br><span class="line">    DataLoaderIter, TrainDataLoaderIter, ValDataLoaderIter</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> task <span class="keyword">as</span> mod_task</span><br><span class="line"><span class="keyword">import</span> dataset <span class="keyword">as</span> mod_dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check available backends for mixed precision training</span></span><br><span class="line">AVAILABLE_AMP_BACKENDS = []</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> apex.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;apex&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> torch.amp</span><br><span class="line">    AVAILABLE_AMP_BACKENDS.append(<span class="string">&quot;torch&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collect_task_classes</span>():</span><br><span class="line">    names = [v <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">dir</span>(mod_task) <span class="keyword">if</span> v.endswith(<span class="string">&quot;Task&quot;</span>) <span class="keyword">and</span> v != <span class="string">&quot;BaseTask&quot;</span>]</span><br><span class="line">    attrs = [<span class="built_in">getattr</span>(mod_task, v) <span class="keyword">for</span> v <span class="keyword">in</span> names]</span><br><span class="line">    classes = [v <span class="keyword">for</span> v <span class="keyword">in</span> attrs <span class="keyword">if</span> <span class="built_in">issubclass</span>(v, mod_task.BaseTask)]</span><br><span class="line">    <span class="keyword">return</span> classes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_lr_finder</span>(<span class="params">task, **kwargs</span>):</span><br><span class="line">    model = task.model</span><br><span class="line">    optimizer = task.optimizer</span><br><span class="line">    criterion = task.criterion</span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">&quot;device&quot;</span>: kwargs.get(<span class="string">&quot;device&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;memory_cache&quot;</span>: kwargs.get(<span class="string">&quot;memory_cache&quot;</span>, <span class="literal">True</span>),</span><br><span class="line">        <span class="string">&quot;cache_dir&quot;</span>: kwargs.get(<span class="string">&quot;cache_dir&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_backend&quot;</span>: kwargs.get(<span class="string">&quot;amp_backend&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;amp_config&quot;</span>: kwargs.get(<span class="string">&quot;amp_config&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">        <span class="string">&quot;grad_scaler&quot;</span>: kwargs.get(<span class="string">&quot;grad_scaler&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    &#125;</span><br><span class="line">    lr_finder = LRFinder(model, optimizer, criterion, **config)</span><br><span class="line">    <span class="keyword">return</span> lr_finder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_optim_lr</span>(<span class="params">optimizer</span>):</span><br><span class="line">    <span class="keyword">return</span> [grp[<span class="string">&quot;lr&quot;</span>] <span class="keyword">for</span> grp <span class="keyword">in</span> optimizer.param_groups]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_loader_iter</span>(<span class="params">loader_iter, desired_runs=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> desired_runs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        desired_runs = <span class="built_in">len</span>(loader_iter.data_loader)</span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(desired_runs):</span><br><span class="line">            <span class="built_in">next</span>(loader_iter)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> desired_runs == count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestRangeTest</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, collect_task_classes(<span class="params"></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;cls_task&quot;</span>, [mod_task.SimplePOSTaggerTask]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_run_non_tensor_dataset_with_val_loader</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task(validate=<span class="literal">True</span>)</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestReset</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;cls_task&quot;</span>, [mod_task.XORTask, mod_task.DiscriminativeLearningRateTask],</span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_reset</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, end_lr=<span class="number">0.1</span>)</span><br><span class="line">        lr_finder.reset()</span><br><span class="line"></span><br><span class="line">        restored_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> restored_lrs == init_lrs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestLRHistory</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_linear_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;linear&quot;</span>, end_lr=<span class="number">5e-5</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_exponential_lr_history</span>(<span class="params">self</span>):</span><br><span class="line">        task = mod_task.XORTask()</span><br><span class="line">        <span class="comment"># prepare_lr_finder sets the starting lr to 1e-5</span></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=<span class="number">5</span>, step_mode=<span class="string">&quot;exp&quot;</span>, end_lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestGradientAccumulation</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        spy = mocker.spy(lr_finder, <span class="string">&quot;criterion&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`apex` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_apex_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;torch&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        reason=<span class="string">&quot;`torch.amp` module and gpu is required to run this test.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_gradient_accumulation_with_torch_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        desired_bs, accum_steps = <span class="number">32</span>, <span class="number">4</span></span><br><span class="line">        real_bs = desired_bs // accum_steps</span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=real_bs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Config for `torch.amp`. Though `torch.amp.autocast` supports various</span></span><br><span class="line">        <span class="comment"># device types, we test it with CUDA only.</span></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, num_iter=num_iter, accumulation_steps=accum_steps</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == num_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;apex&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    reason=<span class="string">&quot;`apex` module and gpu is required to run these tests.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestMixedPrecision</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_apex</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Wrap model and optimizer by `amp.initialize`. Beside, `amp` requires</span></span><br><span class="line">        <span class="comment"># CUDA GPU. So we have to move model to GPU first.</span></span><br><span class="line">        model, optimizer, device = task.model, task.optimizer, task.device</span><br><span class="line">        model = model.to(device)</span><br><span class="line">        task.model, task.optimizer = apex.amp.initialize(model, optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task, amp_backend=<span class="string">&quot;apex&quot;</span>)</span><br><span class="line">        spy = mocker.spy(apex.amp, <span class="string">&quot;scale_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Here we did not perform gradient accumulation, so that call count</span></span><br><span class="line">        <span class="comment"># of `amp` could be only one in any situation.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skipif(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="keyword">not</span> (<span class="params">(<span class="params"><span class="string">&quot;torch&quot;</span> <span class="keyword">in</span> AVAILABLE_AMP_BACKENDS</span>) <span class="keyword">and</span> mod_task.use_cuda(<span class="params"></span>)</span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    reason=<span class="string">&quot;`torch.amp` module and gpu is required to run these tests.&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestMixedPrecisionWithTorchAMP</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mixed_precision_torch_amp</span>(<span class="params">self, mocker</span>):</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        num_iter = <span class="number">10</span></span><br><span class="line">        task = mod_task.XORTask(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Config for `torch.amp`. Though `torch.amp.autocast` supports various</span></span><br><span class="line">        <span class="comment"># device types, we test it with CUDA only.</span></span><br><span class="line">        amp_config = &#123;</span><br><span class="line">            <span class="string">&quot;device_type&quot;</span>: <span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dtype&quot;</span>: torch.float16,</span><br><span class="line">        &#125;</span><br><span class="line">        grad_scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(</span><br><span class="line">            task, amp_backend=<span class="string">&quot;torch&quot;</span>, amp_config=amp_config, grad_scaler=grad_scaler</span><br><span class="line">        )</span><br><span class="line">        spy = mocker.spy(grad_scaler, <span class="string">&quot;scale&quot;</span>)</span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(task.train_loader, num_iter=num_iter)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Here we did not perform gradient accumulation, so that call count</span></span><br><span class="line">        <span class="comment"># of `amp` could be only one in any situation.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> spy.call_count == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skipif(<span class="params"><span class="keyword">not</span> mod_task.use_cuda(<span class="params"></span>), reason=<span class="string">&quot;CUDA GPU is required to run these tests.&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestMultiPhase</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;cls_task&quot;</span>, [mod_task.XORTask, mod_task.DiscriminativeLearningRateTask],</span></span></span><br><span class="line"><span class="params"><span class="meta">    </span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_multi_phase</span>(<span class="params">self, cls_task</span>):</span><br><span class="line">        task = cls_task()</span><br><span class="line">        init_lrs = get_optim_lr(task.optimizer)</span><br><span class="line"></span><br><span class="line">        lr_finder = prepare_lr_finder(task)</span><br><span class="line">        lr_finder.range_test(task.train_loader, val_loader=task.val_loader, num_iter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Simulate a change in LR and perform another phase of LR range test</span></span><br><span class="line">        <span class="keyword">for</span> param_group <span class="keyword">in</span> task.optimizer.param_groups:</span><br><span class="line">            param_group[<span class="string">&quot;lr&quot;</span>] *= <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        lr_finder.range_test(</span><br><span class="line">            task.train_loader, val_loader=task.val_loader, num_iter=<span class="number">10</span>, reset_lr=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assert statements</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;lr&quot;</span>]) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(lr_finder.history[<span class="string">&quot;loss&quot;</span>]) &gt; <span class="number">0</span></span><br></pre></td></tr></table></figure><p></p></li></ul><div class="tags"><a href="/tags/Hexo/" rel="tag"><i class="ic i-tag"></i> Hexo</a> <a href="/tags/Front-Matter/" rel="tag"><i class="ic i-tag"></i> Front Matter</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-07-03 16:57:37" itemprop="dateModified" datetime="2024-07-03T16:57:37+08:00">2024-07-03</time> </span><span id="LLMstestoracle/8_pytorch-lr-finder-master/" class="item leancloud_visitors" data-flag-title="pytorch-lr-finder" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Jack Du WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Jack Du Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Jack Du PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Jack Du <i class="ic i-at"><em>@</em></i>Hexo</li><li class="link"><strong>Post link: </strong><a href="https://enjundu.github.io/LLMstestoracle/8_pytorch-lr-finder-master/" title="pytorch-lr-finder">https://enjundu.github.io/LLMstestoracle/8_pytorch-lr-finder-master/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/LLMstestoracle/X_artificial-adversary-master/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;03&#x2F;PwEoecqCVMZg6kp.jpg" title="artificial-adversary"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> LLM的test oracle生成</span><h3>artificial-adversary</h3></a></div><div class="item right"><a href="/LLMstestoracle/3_robotframework-webservice-master/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;07&#x2F;04&#x2F;OLqrN6bKDJHW5ek.jpg" title="robotframework-webservice"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> LLM的test oracle生成</span><h3>robotframework-webservice</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch-lr-finder"><span class="toc-number">1.</span> <span class="toc-text">pytorch-lr-finder</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#test_lr_finderpy%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">test_lr_finder.py 代码分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A5test%E5%8E%9F%E4%BB%A3%E7%A0%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">该 test 原代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A0%E9%99%A4assert%E5%92%8C%E5%BF%85%E8%A6%81%E6%8F%90%E7%A4%BA%E5%90%8E%E4%B8%8A%E4%BC%A0llm%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-number">1.2.2.</span> <span class="toc-text">删除 assert 和必要提示后上传 LLM 的代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#llm%E8%87%AA%E5%8A%A8%E5%A1%AB%E5%85%85assert%E5%90%8E%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="toc-number">1.2.3.</span> <span class="toc-text">LLM 自动填充 assert 后的代码</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/LLMstestoracle/1/" rel="bookmark" title="研究方法">研究方法</a></li><li><a href="/LLMstestoracle/00_spring_boot/" rel="bookmark" title="01_spring_boot">01_spring_boot</a></li><li><a href="/LLMstestoracle/1_PythonProjectTemplate-master/" rel="bookmark" title="PythonProjectTemplate-master">PythonProjectTemplate-master</a></li><li><a href="/LLMstestoracle/2_cronex-master/" rel="bookmark" title="cronex">cronex</a></li><li><a href="/LLMstestoracle/4_oj-master/" rel="bookmark" title="online-judge-tools/oj">online-judge-tools/oj</a></li><li><a href="/LLMstestoracle/5_giskard-main/" rel="bookmark" title="Giskard-AI/giskard">Giskard-AI/giskard</a></li><li><a href="/LLMstestoracle/7_ttach-master/" rel="bookmark" title="ttach">ttach</a></li><li><a href="/LLMstestoracle/9_sumeval-master/" rel="bookmark" title="sumeval">sumeval</a></li><li><a href="/LLMstestoracle/3_robotframework-webservice-master/" rel="bookmark" title="robotframework-webservice">robotframework-webservice</a></li><li class="active"><a href="/LLMstestoracle/8_pytorch-lr-finder-master/" rel="bookmark" title="pytorch-lr-finder">pytorch-lr-finder</a></li><li><a href="/LLMstestoracle/X_artificial-adversary-master/" rel="bookmark" title="artificial-adversary">artificial-adversary</a></li><li><a href="/LLMstestoracle/%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C/" rel="bookmark" title="a_统计结果">a_统计结果</a></li><li><a href="/LLMstestoracle/1_spring-boot-main_Java/" rel="bookmark" title="1_Java_spring-boot-main">1_Java_spring-boot-main</a></li><li><a href="/LLMstestoracle/00_Java_basic_knowledge/" rel="bookmark" title="0_Java_basic_knowledge">0_Java_basic_knowledge</a></li><li><a href="/LLMstestoracle/01_conductor-main/" rel="bookmark" title="01_conductor">01_conductor</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Jack Du" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Jack Du</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">70</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">11</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">10</span> <span class="name">tags</span></a></div></nav><div class="social"></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/LLMstestoracle/X_artificial-adversary-master/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/LLMstestoracle/3_robotframework-webservice-master/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/bit/%E9%9B%85%E6%80%9D%E8%AF%8D%E6%B1%87/" title="Untitled">Untitled</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="In 闲来无事赚丶米">闲来无事赚丶米</a></div><span><a href="/misc/%E5%BF%83%E7%90%86%E5%81%A5%E5%BA%B7%E5%88%86%E6%9E%90/" title="心理健康分析">心理健康分析</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/bit/" title="In BIT-study">BIT-study</a></div><span><a href="/bit/%E4%BA%9A%E5%A4%AA%E6%95%B0%E6%A8%A1%E2%80%94%E2%80%94%E6%96%B0%E8%83%BD%E6%BA%90%E6%B1%BD%E8%BD%A6/" title="亚太数模——新能源汽车">亚太数模——新能源汽车</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ECEBC/" title="In 嵩天的爱-ECE-BC">嵩天的爱-ECE-BC</a></div><span><a href="/ECEBC/%E5%9B%BE%E5%83%8F%E9%9A%90%E5%86%99/" title="图像隐写">图像隐写</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/deep-learning/" title="In deep-learning">deep-learning</a></div><span><a href="/deep-learning/README_3_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络_Sanfordcs231n">神经网络_Sanfordcs231n</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/recommendation/" title="In 推荐算法相关search">推荐算法相关search</a></div><span><a href="/recommendation/README/" title="b_README">b_README</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/README/" title="蓝天の留言">蓝天の留言</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/1_PythonProjectTemplate-master/" title="PythonProjectTemplate-master">PythonProjectTemplate-master</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/X_artificial-adversary-master/" title="artificial-adversary">artificial-adversary</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/LLMstestoracle/" title="In LLM的test oracle生成">LLM的test oracle生成</a></div><span><a href="/LLMstestoracle/01_conductor-main/" title="01_conductor">01_conductor</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Jack Du @ 蓝天の网站</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"LLMstestoracle/8_pytorch-lr-finder-master/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->